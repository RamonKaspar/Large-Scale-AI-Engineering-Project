[sbatch-master] running on nid006602
[sbatch-master] SLURM_NODELIST: nid[006602-006605]
[sbatch-master] SLURM_NNODES: 4
[sbatch-master] SLURM_NODEID: 0
[Master] Master node: nid006602
[Master] World size: 16
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
[srun] rank=0 host=nid006602 noderank=0 localrank=0
W0519 08:45:58.559000 155372 torch/distributed/run.py:792] 
W0519 08:45:58.559000 155372 torch/distributed/run.py:792] *****************************************
W0519 08:45:58.559000 155372 torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0519 08:45:58.559000 155372 torch/distributed/run.py:792] *****************************************
[srun] rank=3 host=nid006605 noderank=3 localrank=0
[srun] rank=2 host=nid006604 noderank=2 localrank=0
[srun] rank=1 host=nid006603 noderank=1 localrank=0
W0519 08:46:02.402000 138374 torch/distributed/run.py:792] 
W0519 08:46:02.402000 138374 torch/distributed/run.py:792] *****************************************
W0519 08:46:02.402000 138374 torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0519 08:46:02.402000 138374 torch/distributed/run.py:792] *****************************************
W0519 08:46:02.503000 159276 torch/distributed/run.py:792] 
W0519 08:46:02.503000 159276 torch/distributed/run.py:792] *****************************************
W0519 08:46:02.503000 159276 torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0519 08:46:02.503000 159276 torch/distributed/run.py:792] *****************************************
W0519 08:46:02.865000 115905 torch/distributed/run.py:792] 
W0519 08:46:02.865000 115905 torch/distributed/run.py:792] *****************************************
W0519 08:46:02.865000 115905 torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0519 08:46:02.865000 115905 torch/distributed/run.py:792] *****************************************
2025-05-19 08:46:14,759 - root - INFO - [Distributed Init] Rank 4 initialized on node 1 on GPU 0.
2025-05-19 08:46:14,781 - root - INFO - [Distributed Init] Rank 12 initialized on node 3 on GPU 0.
2025-05-19 08:46:14,919 - root - INFO - [Distributed Init] Rank 0 initialized on node 0 on GPU 0.
[rank12]:[W519 08:46:15.782707117 ProcessGroupNCCL.cpp:4454] [PG ID 0 PG GUID 0 Rank 12]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank4]:[W519 08:46:15.227065447 ProcessGroupNCCL.cpp:4454] [PG ID 0 PG GUID 0 Rank 4]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
2025-05-19 08:46:15,270 - root - INFO - [Distributed Init] Rank 13 initialized on node 3 on GPU 1.
[rank13]:[W519 08:46:15.842324155 ProcessGroupNCCL.cpp:4454] [PG ID 0 PG GUID 0 Rank 13]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
2025-05-19 08:46:15,321 - root - INFO - [Distributed Init] Rank 6 initialized on node 1 on GPU 2.
[rank6]:[W519 08:46:15.332414775 ProcessGroupNCCL.cpp:4454] [PG ID 0 PG GUID 0 Rank 6]  using GPU 2 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
2025-05-19 08:46:15,341 - root - INFO - [Distributed Init] Rank 14 initialized on node 3 on GPU 2.
[rank14]:[W519 08:46:15.913857624 ProcessGroupNCCL.cpp:4454] [PG ID 0 PG GUID 0 Rank 14]  using GPU 2 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
2025-05-19 08:46:15,380 - root - INFO - [Distributed Init] Rank 15 initialized on node 3 on GPU 3.
[rank15]:[W519 08:46:15.952240092 ProcessGroupNCCL.cpp:4454] [PG ID 0 PG GUID 0 Rank 15]  using GPU 3 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
2025-05-19 08:46:15,381 - root - INFO - [Distributed Init] Rank 5 initialized on node 1 on GPU 1.
[rank5]:[W519 08:46:15.392650146 ProcessGroupNCCL.cpp:4454] [PG ID 0 PG GUID 0 Rank 5]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
2025-05-19 08:46:15,391 - root - INFO - [Distributed Init] Rank 7 initialized on node 1 on GPU 3.
[rank7]:[W519 08:46:15.402368478 ProcessGroupNCCL.cpp:4454] [PG ID 0 PG GUID 0 Rank 7]  using GPU 3 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank0]:[W519 08:46:15.159628125 ProcessGroupNCCL.cpp:4454] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
2025-05-19 08:46:15,535 - root - INFO - [Distributed Init] Rank 8 initialized on node 2 on GPU 0.
2025-05-19 08:46:15,591 - root - INFO - [Distributed Init] Rank 1 initialized on node 0 on GPU 1.
[rank1]:[W519 08:46:15.343720772 ProcessGroupNCCL.cpp:4454] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
2025-05-19 08:46:15,593 - root - INFO - [Distributed Init] Rank 2 initialized on node 0 on GPU 2.
2025-05-19 08:46:15,594 - root - INFO - [Distributed Init] Rank 3 initialized on node 0 on GPU 3.
[rank2]:[W519 08:46:15.346058502 ProcessGroupNCCL.cpp:4454] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank3]:[W519 08:46:15.347422018 ProcessGroupNCCL.cpp:4454] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank8]:[W519 08:46:15.655781749 ProcessGroupNCCL.cpp:4454] [PG ID 0 PG GUID 0 Rank 8]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
2025-05-19 08:46:16,050 - root - INFO - [Distributed Init] Rank 10 initialized on node 2 on GPU 2.
[rank10]:[W519 08:46:16.732529955 ProcessGroupNCCL.cpp:4454] [PG ID 0 PG GUID 0 Rank 10]  using GPU 2 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
2025-05-19 08:46:16,110 - root - INFO - [Distributed Init] Rank 11 initialized on node 2 on GPU 3.
[rank11]:[W519 08:46:16.792826521 ProcessGroupNCCL.cpp:4454] [PG ID 0 PG GUID 0 Rank 11]  using GPU 3 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
2025-05-19 08:46:21,071 - root - INFO - [Distributed Init] Rank 9 initialized on node 2 on GPU 1.
[rank9]:[W519 08:46:21.753985126 ProcessGroupNCCL.cpp:4454] [PG ID 0 PG GUID 0 Rank 9]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
2025-05-19 08:46:24,228 - root - INFO - [Rank 0] All ranks ready!
2025-05-19 08:46:24,229 - root - INFO - Distributed training enabled: 16 processes
2025-05-19 08:46:24,229 - root - INFO - Master process: 0 on cuda:0
2025-05-19 08:46:24,229 - root - INFO - Experiment args: Namespace(dataset='/capstor/scratch/cscs/kasparr/project/train_data.parquet', dataset_type='padded', pretokenized=False, tokenizer_name_or_path='unsloth/Mistral-Nemo-Base-2407-bnb-4bit', sequence_length=2048, batch_size=8, fused_optimizer=False, learning_rate=5e-05, lr_warmup_steps=100, training_steps=1000, logging_frequency=10, profile=False, profile_step_start=10, profile_step_end=10, grad_max_norm=1, model_dtype='bf16', compile=False, distributed=True, backend='nccl', find_unused_parameters=False)
2025-05-19 08:46:24,229 - root - INFO - Setting up Tokenizer...
2025-05-19 08:46:26,042 - root - INFO - Setting up DataLoaders...
2025-05-19 08:46:26,042 - root - INFO - Using padded ParquetDataset with on-the-fly tokenization
2025-05-19 08:46:30,877 - root - INFO - Setting up Model...
2025-05-19 08:46:43,185 - root - INFO - Model wrapped with DistributedDataParallel
2025-05-19 08:46:43,186 - root - INFO - Global batch size: 128 (local: 8 × 16 processes)
2025-05-19 08:46:43,186 - root - INFO - Starting training!
/iopsstor/scratch/cscs/kasparr/project/src/train.py:236: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  num_items_tensor = torch.tensor(num_items_in_batch, device=device)
/iopsstor/scratch/cscs/kasparr/project/src/train.py:236: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  num_items_tensor = torch.tensor(num_items_in_batch, device=device)
/iopsstor/scratch/cscs/kasparr/project/src/train.py:236: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  num_items_tensor = torch.tensor(num_items_in_batch, device=device)
/iopsstor/scratch/cscs/kasparr/project/src/train.py:236: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  num_items_tensor = torch.tensor(num_items_in_batch, device=device)
/iopsstor/scratch/cscs/kasparr/project/src/train.py:236: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  num_items_tensor = torch.tensor(num_items_in_batch, device=device)
/iopsstor/scratch/cscs/kasparr/project/src/train.py:236: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  num_items_tensor = torch.tensor(num_items_in_batch, device=device)
/iopsstor/scratch/cscs/kasparr/project/src/train.py:236: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  num_items_tensor = torch.tensor(num_items_in_batch, device=device)
/iopsstor/scratch/cscs/kasparr/project/src/train.py:236: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  num_items_tensor = torch.tensor(num_items_in_batch, device=device)
/iopsstor/scratch/cscs/kasparr/project/src/train.py:236: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  num_items_tensor = torch.tensor(num_items_in_batch, device=device)
/iopsstor/scratch/cscs/kasparr/project/src/train.py:236: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  num_items_tensor = torch.tensor(num_items_in_batch, device=device)
/iopsstor/scratch/cscs/kasparr/project/src/train.py:236: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  num_items_tensor = torch.tensor(num_items_in_batch, device=device)
/iopsstor/scratch/cscs/kasparr/project/src/train.py:236: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  num_items_tensor = torch.tensor(num_items_in_batch, device=device)
/iopsstor/scratch/cscs/kasparr/project/src/train.py:236: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  num_items_tensor = torch.tensor(num_items_in_batch, device=device)
/iopsstor/scratch/cscs/kasparr/project/src/train.py:236: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  num_items_tensor = torch.tensor(num_items_in_batch, device=device)
/iopsstor/scratch/cscs/kasparr/project/src/train.py:236: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  num_items_tensor = torch.tensor(num_items_in_batch, device=device)
/iopsstor/scratch/cscs/kasparr/project/src/train.py:236: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  num_items_tensor = torch.tensor(num_items_in_batch, device=device)
2025-05-19 08:46:44,835 - root - INFO - Step: 1 | Loss: 11.96 | Tokens per second: 9941.96 | Training tokens per second (%): 1.30 | MFU (%): 9.31 | TFLOPs: 92.08 | Global batch size: 128 | Global tokens/sec: 159071.41 | Global MFU (%): 9.31 | Global TFLOPs: 1473.23 | 
2025-05-19 08:46:49,331 - root - INFO - Step: 10 | Loss: 11.92 | Tokens per second: 32800.04 | Training tokens per second (%): 2.05 | MFU (%): 30.72 | TFLOPs: 303.78 | Global batch size: 128 | Global tokens/sec: 524800.66 | Global MFU (%): 30.72 | Global TFLOPs: 4860.40 | 
2025-05-19 08:46:53,631 - root - INFO - Step: 20 | Loss: 11.67 | Tokens per second: 38107.61 | Training tokens per second (%): 2.45 | MFU (%): 35.69 | TFLOPs: 352.93 | Global batch size: 128 | Global tokens/sec: 609721.74 | Global MFU (%): 35.69 | Global TFLOPs: 5646.89 | 
2025-05-19 08:46:57,911 - root - INFO - Step: 30 | Loss: 11.04 | Tokens per second: 38285.00 | Training tokens per second (%): 2.58 | MFU (%): 35.85 | TFLOPs: 354.57 | Global batch size: 128 | Global tokens/sec: 612560.02 | Global MFU (%): 35.85 | Global TFLOPs: 5673.18 | 
2025-05-19 08:47:02,535 - root - INFO - Step: 40 | Loss: 10.06 | Tokens per second: 35436.99 | Training tokens per second (%): 2.23 | MFU (%): 33.18 | TFLOPs: 328.20 | Global batch size: 128 | Global tokens/sec: 566991.83 | Global MFU (%): 33.18 | Global TFLOPs: 5251.15 | 
2025-05-19 08:47:06,830 - root - INFO - Step: 50 | Loss: 9.39 | Tokens per second: 38161.16 | Training tokens per second (%): 2.26 | MFU (%): 35.74 | TFLOPs: 353.43 | Global batch size: 128 | Global tokens/sec: 610578.63 | Global MFU (%): 35.74 | Global TFLOPs: 5654.83 | 
2025-05-19 08:47:11,415 - root - INFO - Step: 60 | Loss: 8.80 | Tokens per second: 35738.75 | Training tokens per second (%): 2.07 | MFU (%): 33.47 | TFLOPs: 330.99 | Global batch size: 128 | Global tokens/sec: 571820.07 | Global MFU (%): 33.47 | Global TFLOPs: 5295.87 | 
2025-05-19 08:47:15,517 - root - INFO - Step: 70 | Loss: 8.31 | Tokens per second: 39943.28 | Training tokens per second (%): 2.12 | MFU (%): 37.40 | TFLOPs: 369.93 | Global batch size: 128 | Global tokens/sec: 639092.50 | Global MFU (%): 37.40 | Global TFLOPs: 5918.91 | 
2025-05-19 08:47:19,932 - root - INFO - Step: 80 | Loss: 7.83 | Tokens per second: 37117.85 | Training tokens per second (%): 2.25 | MFU (%): 34.76 | TFLOPs: 343.76 | Global batch size: 128 | Global tokens/sec: 593885.53 | Global MFU (%): 34.76 | Global TFLOPs: 5500.23 | 
2025-05-19 08:47:24,318 - root - INFO - Step: 90 | Loss: 7.58 | Tokens per second: 37358.97 | Training tokens per second (%): 2.28 | MFU (%): 34.98 | TFLOPs: 346.00 | Global batch size: 128 | Global tokens/sec: 597743.47 | Global MFU (%): 34.98 | Global TFLOPs: 5535.96 | 
2025-05-19 08:47:28,886 - root - INFO - Step: 100 | Loss: 7.38 | Tokens per second: 35877.81 | Training tokens per second (%): 2.39 | MFU (%): 33.60 | TFLOPs: 332.28 | Global batch size: 128 | Global tokens/sec: 574044.97 | Global MFU (%): 33.60 | Global TFLOPs: 5316.48 | 
2025-05-19 08:47:33,323 - root - INFO - Step: 110 | Loss: 7.27 | Tokens per second: 36927.29 | Training tokens per second (%): 2.05 | MFU (%): 34.58 | TFLOPs: 342.00 | Global batch size: 128 | Global tokens/sec: 590836.71 | Global MFU (%): 34.58 | Global TFLOPs: 5471.99 | 
2025-05-19 08:47:37,619 - root - INFO - Step: 120 | Loss: 7.15 | Tokens per second: 38143.77 | Training tokens per second (%): 2.27 | MFU (%): 35.72 | TFLOPs: 353.27 | Global batch size: 128 | Global tokens/sec: 610300.28 | Global MFU (%): 35.72 | Global TFLOPs: 5652.25 | 
2025-05-19 08:47:41,749 - root - INFO - Step: 130 | Loss: 7.04 | Tokens per second: 39677.45 | Training tokens per second (%): 2.69 | MFU (%): 37.16 | TFLOPs: 367.47 | Global batch size: 128 | Global tokens/sec: 634839.17 | Global MFU (%): 37.16 | Global TFLOPs: 5879.52 | 
2025-05-19 08:47:46,204 - root - INFO - Step: 140 | Loss: 7.06 | Tokens per second: 36782.54 | Training tokens per second (%): 2.76 | MFU (%): 34.44 | TFLOPs: 340.66 | Global batch size: 128 | Global tokens/sec: 588520.65 | Global MFU (%): 34.44 | Global TFLOPs: 5450.54 | 
2025-05-19 08:47:50,525 - root - INFO - Step: 150 | Loss: 6.97 | Tokens per second: 37926.59 | Training tokens per second (%): 2.60 | MFU (%): 35.52 | TFLOPs: 351.25 | Global batch size: 128 | Global tokens/sec: 606825.38 | Global MFU (%): 35.52 | Global TFLOPs: 5620.07 | 
2025-05-19 08:47:55,042 - root - INFO - Step: 160 | Loss: 6.90 | Tokens per second: 36278.81 | Training tokens per second (%): 2.45 | MFU (%): 33.97 | TFLOPs: 335.99 | Global batch size: 128 | Global tokens/sec: 580460.96 | Global MFU (%): 33.97 | Global TFLOPs: 5375.90 | 
2025-05-19 08:47:59,422 - root - INFO - Step: 170 | Loss: 6.83 | Tokens per second: 37409.91 | Training tokens per second (%): 2.44 | MFU (%): 35.03 | TFLOPs: 346.47 | Global batch size: 128 | Global tokens/sec: 598558.62 | Global MFU (%): 35.03 | Global TFLOPs: 5543.51 | 
2025-05-19 08:48:03,674 - root - INFO - Step: 180 | Loss: 6.84 | Tokens per second: 38534.89 | Training tokens per second (%): 2.36 | MFU (%): 36.09 | TFLOPs: 356.89 | Global batch size: 128 | Global tokens/sec: 616558.27 | Global MFU (%): 36.09 | Global TFLOPs: 5710.21 | 
2025-05-19 08:48:07,849 - root - INFO - Step: 190 | Loss: 6.73 | Tokens per second: 39256.33 | Training tokens per second (%): 2.02 | MFU (%): 36.76 | TFLOPs: 363.57 | Global batch size: 128 | Global tokens/sec: 628101.23 | Global MFU (%): 36.76 | Global TFLOPs: 5817.11 | 
2025-05-19 08:48:12,290 - root - INFO - Step: 200 | Loss: 6.60 | Tokens per second: 36896.96 | Training tokens per second (%): 2.37 | MFU (%): 34.55 | TFLOPs: 341.72 | Global batch size: 128 | Global tokens/sec: 590351.37 | Global MFU (%): 34.55 | Global TFLOPs: 5467.50 | 
2025-05-19 08:48:16,650 - root - INFO - Step: 210 | Loss: 6.61 | Tokens per second: 37586.95 | Training tokens per second (%): 2.13 | MFU (%): 35.20 | TFLOPs: 348.11 | Global batch size: 128 | Global tokens/sec: 601391.13 | Global MFU (%): 35.20 | Global TFLOPs: 5569.74 | 
2025-05-19 08:48:20,959 - root - INFO - Step: 220 | Loss: 6.52 | Tokens per second: 38028.68 | Training tokens per second (%): 2.40 | MFU (%): 35.61 | TFLOPs: 352.20 | Global batch size: 128 | Global tokens/sec: 608458.80 | Global MFU (%): 35.61 | Global TFLOPs: 5635.20 | 
2025-05-19 08:48:25,263 - root - INFO - Step: 230 | Loss: 6.48 | Tokens per second: 38079.56 | Training tokens per second (%): 2.13 | MFU (%): 35.66 | TFLOPs: 352.67 | Global batch size: 128 | Global tokens/sec: 609272.92 | Global MFU (%): 35.66 | Global TFLOPs: 5642.74 | 
2025-05-19 08:48:29,788 - root - INFO - Step: 240 | Loss: 6.47 | Tokens per second: 36214.07 | Training tokens per second (%): 2.20 | MFU (%): 33.91 | TFLOPs: 335.39 | Global batch size: 128 | Global tokens/sec: 579425.16 | Global MFU (%): 33.91 | Global TFLOPs: 5366.30 | 
2025-05-19 08:48:34,146 - root - INFO - Step: 250 | Loss: 6.44 | Tokens per second: 37597.19 | Training tokens per second (%): 2.59 | MFU (%): 35.21 | TFLOPs: 348.20 | Global batch size: 128 | Global tokens/sec: 601555.09 | Global MFU (%): 35.21 | Global TFLOPs: 5571.26 | 
2025-05-19 08:48:38,347 - root - INFO - Step: 260 | Loss: 6.35 | Tokens per second: 39008.97 | Training tokens per second (%): 2.27 | MFU (%): 36.53 | TFLOPs: 361.28 | Global batch size: 128 | Global tokens/sec: 624143.55 | Global MFU (%): 36.53 | Global TFLOPs: 5780.46 | 
2025-05-19 08:48:42,765 - root - INFO - Step: 270 | Loss: 6.40 | Tokens per second: 37093.31 | Training tokens per second (%): 2.16 | MFU (%): 34.74 | TFLOPs: 343.54 | Global batch size: 128 | Global tokens/sec: 593492.97 | Global MFU (%): 34.74 | Global TFLOPs: 5496.59 | 
2025-05-19 08:48:47,167 - root - INFO - Step: 280 | Loss: 6.36 | Tokens per second: 37226.34 | Training tokens per second (%): 2.38 | MFU (%): 34.86 | TFLOPs: 344.77 | Global batch size: 128 | Global tokens/sec: 595621.40 | Global MFU (%): 34.86 | Global TFLOPs: 5516.31 | 
2025-05-19 08:48:51,465 - root - INFO - Step: 290 | Loss: 6.29 | Tokens per second: 38123.71 | Training tokens per second (%): 2.45 | MFU (%): 35.70 | TFLOPs: 353.08 | Global batch size: 128 | Global tokens/sec: 609979.33 | Global MFU (%): 35.70 | Global TFLOPs: 5649.28 | 
2025-05-19 08:48:55,746 - root - INFO - Step: 300 | Loss: 6.21 | Tokens per second: 38274.49 | Training tokens per second (%): 2.47 | MFU (%): 35.84 | TFLOPs: 354.48 | Global batch size: 128 | Global tokens/sec: 612391.92 | Global MFU (%): 35.84 | Global TFLOPs: 5671.62 | 
2025-05-19 08:49:00,164 - root - INFO - Step: 310 | Loss: 6.29 | Tokens per second: 37090.40 | Training tokens per second (%): 2.54 | MFU (%): 34.73 | TFLOPs: 343.51 | Global batch size: 128 | Global tokens/sec: 593446.38 | Global MFU (%): 34.73 | Global TFLOPs: 5496.16 | 
2025-05-19 08:49:04,474 - root - INFO - Step: 320 | Loss: 6.19 | Tokens per second: 38023.26 | Training tokens per second (%): 2.10 | MFU (%): 35.61 | TFLOPs: 352.15 | Global batch size: 128 | Global tokens/sec: 608372.21 | Global MFU (%): 35.61 | Global TFLOPs: 5634.40 | 
2025-05-19 08:49:09,017 - root - INFO - Step: 330 | Loss: 6.14 | Tokens per second: 36071.65 | Training tokens per second (%): 2.39 | MFU (%): 33.78 | TFLOPs: 334.07 | Global batch size: 128 | Global tokens/sec: 577146.32 | Global MFU (%): 33.78 | Global TFLOPs: 5345.20 | 
2025-05-19 08:49:13,400 - root - INFO - Step: 340 | Loss: 6.05 | Tokens per second: 37388.88 | Training tokens per second (%): 2.47 | MFU (%): 35.01 | TFLOPs: 346.27 | Global batch size: 128 | Global tokens/sec: 598222.02 | Global MFU (%): 35.01 | Global TFLOPs: 5540.39 | 
2025-05-19 08:49:17,885 - root - INFO - Step: 350 | Loss: 6.12 | Tokens per second: 36528.70 | Training tokens per second (%): 2.31 | MFU (%): 34.21 | TFLOPs: 338.31 | Global batch size: 128 | Global tokens/sec: 584459.18 | Global MFU (%): 34.21 | Global TFLOPs: 5412.93 | 
2025-05-19 08:49:22,179 - root - INFO - Step: 360 | Loss: 6.11 | Tokens per second: 38165.37 | Training tokens per second (%): 2.33 | MFU (%): 35.74 | TFLOPs: 353.47 | Global batch size: 128 | Global tokens/sec: 610645.93 | Global MFU (%): 35.74 | Global TFLOPs: 5655.45 | 
2025-05-19 08:49:26,509 - root - INFO - Step: 370 | Loss: 6.11 | Tokens per second: 37845.85 | Training tokens per second (%): 2.37 | MFU (%): 35.44 | TFLOPs: 350.51 | Global batch size: 128 | Global tokens/sec: 605533.63 | Global MFU (%): 35.44 | Global TFLOPs: 5608.11 | 
2025-05-19 08:49:30,675 - root - INFO - Step: 380 | Loss: 6.00 | Tokens per second: 39334.27 | Training tokens per second (%): 2.14 | MFU (%): 36.83 | TFLOPs: 364.29 | Global batch size: 128 | Global tokens/sec: 629348.25 | Global MFU (%): 36.83 | Global TFLOPs: 5828.66 | 
2025-05-19 08:49:34,985 - root - INFO - Step: 390 | Loss: 5.93 | Tokens per second: 38023.27 | Training tokens per second (%): 2.23 | MFU (%): 35.61 | TFLOPs: 352.15 | Global batch size: 128 | Global tokens/sec: 608372.27 | Global MFU (%): 35.61 | Global TFLOPs: 5634.40 | 
2025-05-19 08:49:39,498 - root - INFO - Step: 400 | Loss: 6.00 | Tokens per second: 36309.04 | Training tokens per second (%): 2.28 | MFU (%): 34.00 | TFLOPs: 336.27 | Global batch size: 128 | Global tokens/sec: 580944.66 | Global MFU (%): 34.00 | Global TFLOPs: 5380.38 | 
2025-05-19 08:49:43,862 - root - INFO - Step: 410 | Loss: 6.00 | Tokens per second: 37546.81 | Training tokens per second (%): 2.35 | MFU (%): 35.16 | TFLOPs: 347.74 | Global batch size: 128 | Global tokens/sec: 600749.04 | Global MFU (%): 35.16 | Global TFLOPs: 5563.79 | 
2025-05-19 08:49:48,237 - root - INFO - Step: 420 | Loss: 5.89 | Tokens per second: 37457.45 | Training tokens per second (%): 2.50 | MFU (%): 35.08 | TFLOPs: 346.91 | Global batch size: 128 | Global tokens/sec: 599319.21 | Global MFU (%): 35.08 | Global TFLOPs: 5550.55 | 
2025-05-19 08:49:52,612 - root - INFO - Step: 430 | Loss: 6.02 | Tokens per second: 37454.13 | Training tokens per second (%): 2.85 | MFU (%): 35.07 | TFLOPs: 346.88 | Global batch size: 128 | Global tokens/sec: 599266.06 | Global MFU (%): 35.07 | Global TFLOPs: 5550.06 | 
2025-05-19 08:49:57,058 - root - INFO - Step: 440 | Loss: 5.97 | Tokens per second: 36854.22 | Training tokens per second (%): 2.20 | MFU (%): 34.51 | TFLOPs: 341.32 | Global batch size: 128 | Global tokens/sec: 589667.50 | Global MFU (%): 34.51 | Global TFLOPs: 5461.16 | 
2025-05-19 08:50:01,402 - root - INFO - Step: 450 | Loss: 5.77 | Tokens per second: 37723.14 | Training tokens per second (%): 2.40 | MFU (%): 35.33 | TFLOPs: 349.37 | Global batch size: 128 | Global tokens/sec: 603570.18 | Global MFU (%): 35.33 | Global TFLOPs: 5589.92 | 
2025-05-19 08:50:05,726 - root - INFO - Step: 460 | Loss: 5.87 | Tokens per second: 37897.30 | Training tokens per second (%): 2.40 | MFU (%): 35.49 | TFLOPs: 350.98 | Global batch size: 128 | Global tokens/sec: 606356.85 | Global MFU (%): 35.49 | Global TFLOPs: 5615.73 | 
2025-05-19 08:50:10,154 - root - INFO - Step: 470 | Loss: 5.87 | Tokens per second: 37007.60 | Training tokens per second (%): 2.06 | MFU (%): 34.66 | TFLOPs: 342.74 | Global batch size: 128 | Global tokens/sec: 592121.59 | Global MFU (%): 34.66 | Global TFLOPs: 5483.89 | 
2025-05-19 08:50:14,520 - root - INFO - Step: 480 | Loss: 5.80 | Tokens per second: 37532.85 | Training tokens per second (%): 2.29 | MFU (%): 35.15 | TFLOPs: 347.61 | Global batch size: 128 | Global tokens/sec: 600525.56 | Global MFU (%): 35.15 | Global TFLOPs: 5561.72 | 
2025-05-19 08:50:18,916 - root - INFO - Step: 490 | Loss: 5.84 | Tokens per second: 37280.36 | Training tokens per second (%): 2.45 | MFU (%): 34.91 | TFLOPs: 345.27 | Global batch size: 128 | Global tokens/sec: 596485.78 | Global MFU (%): 34.91 | Global TFLOPs: 5524.31 | 
2025-05-19 08:50:23,324 - root - INFO - Step: 500 | Loss: 5.76 | Tokens per second: 37175.45 | Training tokens per second (%): 2.70 | MFU (%): 34.81 | TFLOPs: 344.30 | Global batch size: 128 | Global tokens/sec: 594807.13 | Global MFU (%): 34.81 | Global TFLOPs: 5508.76 | 
2025-05-19 08:50:27,478 - root - INFO - Step: 510 | Loss: 5.72 | Tokens per second: 39444.44 | Training tokens per second (%): 1.92 | MFU (%): 36.94 | TFLOPs: 365.31 | Global batch size: 128 | Global tokens/sec: 631111.02 | Global MFU (%): 36.94 | Global TFLOPs: 5844.99 | 
2025-05-19 08:50:31,949 - root - INFO - Step: 520 | Loss: 5.79 | Tokens per second: 36656.28 | Training tokens per second (%): 2.42 | MFU (%): 34.33 | TFLOPs: 339.49 | Global batch size: 128 | Global tokens/sec: 586500.52 | Global MFU (%): 34.33 | Global TFLOPs: 5431.83 | 
2025-05-19 08:50:36,299 - root - INFO - Step: 530 | Loss: 5.75 | Tokens per second: 37664.85 | Training tokens per second (%): 2.74 | MFU (%): 35.27 | TFLOPs: 348.83 | Global batch size: 128 | Global tokens/sec: 602637.64 | Global MFU (%): 35.27 | Global TFLOPs: 5581.29 | 
2025-05-19 08:50:40,666 - root - INFO - Step: 540 | Loss: 5.64 | Tokens per second: 37523.55 | Training tokens per second (%): 2.32 | MFU (%): 35.14 | TFLOPs: 347.52 | Global batch size: 128 | Global tokens/sec: 600376.86 | Global MFU (%): 35.14 | Global TFLOPs: 5560.35 | 
2025-05-19 08:50:44,996 - root - INFO - Step: 550 | Loss: 5.67 | Tokens per second: 37848.21 | Training tokens per second (%): 2.45 | MFU (%): 35.44 | TFLOPs: 350.53 | Global batch size: 128 | Global tokens/sec: 605571.28 | Global MFU (%): 35.44 | Global TFLOPs: 5608.46 | 
2025-05-19 08:50:49,386 - root - INFO - Step: 560 | Loss: 5.68 | Tokens per second: 37327.62 | Training tokens per second (%): 2.81 | MFU (%): 34.96 | TFLOPs: 345.71 | Global batch size: 128 | Global tokens/sec: 597241.98 | Global MFU (%): 34.96 | Global TFLOPs: 5531.31 | 
2025-05-19 08:50:53,731 - root - INFO - Step: 570 | Loss: 5.62 | Tokens per second: 37715.78 | Training tokens per second (%): 2.41 | MFU (%): 35.32 | TFLOPs: 349.30 | Global batch size: 128 | Global tokens/sec: 603452.44 | Global MFU (%): 35.32 | Global TFLOPs: 5588.83 | 
2025-05-19 08:50:58,077 - root - INFO - Step: 580 | Loss: 6.11 | Tokens per second: 37702.86 | Training tokens per second (%): 2.54 | MFU (%): 35.31 | TFLOPs: 349.18 | Global batch size: 128 | Global tokens/sec: 603245.75 | Global MFU (%): 35.31 | Global TFLOPs: 5586.92 | 
2025-05-19 08:51:02,625 - root - INFO - Step: 590 | Loss: 5.82 | Tokens per second: 36029.58 | Training tokens per second (%): 1.93 | MFU (%): 33.74 | TFLOPs: 333.69 | Global batch size: 128 | Global tokens/sec: 576473.27 | Global MFU (%): 33.74 | Global TFLOPs: 5338.97 | 
2025-05-19 08:51:07,017 - root - INFO - Step: 600 | Loss: 5.75 | Tokens per second: 37311.49 | Training tokens per second (%): 2.30 | MFU (%): 34.94 | TFLOPs: 345.56 | Global batch size: 128 | Global tokens/sec: 596983.76 | Global MFU (%): 34.94 | Global TFLOPs: 5528.92 | 
2025-05-19 08:51:11,319 - root - INFO - Step: 610 | Loss: 5.70 | Tokens per second: 38089.90 | Training tokens per second (%): 2.43 | MFU (%): 35.67 | TFLOPs: 352.77 | Global batch size: 128 | Global tokens/sec: 609438.48 | Global MFU (%): 35.67 | Global TFLOPs: 5644.27 | 
2025-05-19 08:51:15,658 - root - INFO - Step: 620 | Loss: 5.66 | Tokens per second: 37769.75 | Training tokens per second (%): 2.32 | MFU (%): 35.37 | TFLOPs: 349.80 | Global batch size: 128 | Global tokens/sec: 604315.93 | Global MFU (%): 35.37 | Global TFLOPs: 5596.83 | 
2025-05-19 08:51:19,925 - root - INFO - Step: 630 | Loss: 5.72 | Tokens per second: 38398.36 | Training tokens per second (%): 2.11 | MFU (%): 35.96 | TFLOPs: 355.62 | Global batch size: 128 | Global tokens/sec: 614373.83 | Global MFU (%): 35.96 | Global TFLOPs: 5689.98 | 
2025-05-19 08:51:24,294 - root - INFO - Step: 640 | Loss: 5.66 | Tokens per second: 37511.92 | Training tokens per second (%): 2.71 | MFU (%): 35.13 | TFLOPs: 347.41 | Global batch size: 128 | Global tokens/sec: 600190.66 | Global MFU (%): 35.13 | Global TFLOPs: 5558.62 | 
2025-05-19 08:51:28,621 - root - INFO - Step: 650 | Loss: 5.59 | Tokens per second: 37873.68 | Training tokens per second (%): 1.98 | MFU (%): 35.47 | TFLOPs: 350.76 | Global batch size: 128 | Global tokens/sec: 605978.91 | Global MFU (%): 35.47 | Global TFLOPs: 5612.23 | 
2025-05-19 08:51:33,006 - root - INFO - Step: 660 | Loss: 5.60 | Tokens per second: 37363.44 | Training tokens per second (%): 2.09 | MFU (%): 34.99 | TFLOPs: 346.04 | Global batch size: 128 | Global tokens/sec: 597814.98 | Global MFU (%): 34.99 | Global TFLOPs: 5536.62 | 
2025-05-19 08:51:37,443 - root - INFO - Step: 670 | Loss: 5.58 | Tokens per second: 36936.64 | Training tokens per second (%): 2.11 | MFU (%): 34.59 | TFLOPs: 342.09 | Global batch size: 128 | Global tokens/sec: 590986.23 | Global MFU (%): 34.59 | Global TFLOPs: 5473.38 | 
2025-05-19 08:51:42,038 - root - INFO - Step: 680 | Loss: 5.56 | Tokens per second: 35657.41 | Training tokens per second (%): 2.15 | MFU (%): 33.39 | TFLOPs: 330.24 | Global batch size: 128 | Global tokens/sec: 570518.62 | Global MFU (%): 33.39 | Global TFLOPs: 5283.82 | 
2025-05-19 08:51:46,328 - root - INFO - Step: 690 | Loss: 5.65 | Tokens per second: 38203.96 | Training tokens per second (%): 2.58 | MFU (%): 35.78 | TFLOPs: 353.82 | Global batch size: 128 | Global tokens/sec: 611263.33 | Global MFU (%): 35.78 | Global TFLOPs: 5661.17 | 
2025-05-19 08:51:50,520 - root - INFO - Step: 700 | Loss: 5.48 | Tokens per second: 39091.13 | Training tokens per second (%): 2.33 | MFU (%): 36.61 | TFLOPs: 362.04 | Global batch size: 128 | Global tokens/sec: 625458.06 | Global MFU (%): 36.61 | Global TFLOPs: 5792.64 | 
2025-05-19 08:51:54,990 - root - INFO - Step: 710 | Loss: 5.51 | Tokens per second: 36654.55 | Training tokens per second (%): 2.42 | MFU (%): 34.32 | TFLOPs: 339.47 | Global batch size: 128 | Global tokens/sec: 586472.80 | Global MFU (%): 34.32 | Global TFLOPs: 5431.58 | 
2025-05-19 08:51:59,538 - root - INFO - Step: 720 | Loss: 5.50 | Tokens per second: 36031.55 | Training tokens per second (%): 2.56 | MFU (%): 33.74 | TFLOPs: 333.70 | Global batch size: 128 | Global tokens/sec: 576504.81 | Global MFU (%): 33.74 | Global TFLOPs: 5339.26 | 
2025-05-19 08:52:03,824 - root - INFO - Step: 730 | Loss: 5.47 | Tokens per second: 38234.00 | Training tokens per second (%): 2.38 | MFU (%): 35.80 | TFLOPs: 354.10 | Global batch size: 128 | Global tokens/sec: 611744.07 | Global MFU (%): 35.80 | Global TFLOPs: 5665.62 | 
2025-05-19 08:52:08,211 - root - INFO - Step: 740 | Loss: 5.47 | Tokens per second: 37359.04 | Training tokens per second (%): 2.53 | MFU (%): 34.98 | TFLOPs: 346.00 | Global batch size: 128 | Global tokens/sec: 597744.64 | Global MFU (%): 34.98 | Global TFLOPs: 5535.97 | 
2025-05-19 08:52:12,737 - root - INFO - Step: 750 | Loss: 5.38 | Tokens per second: 36201.79 | Training tokens per second (%): 2.69 | MFU (%): 33.90 | TFLOPs: 335.28 | Global batch size: 128 | Global tokens/sec: 579228.66 | Global MFU (%): 33.90 | Global TFLOPs: 5364.48 | 
2025-05-19 08:52:16,892 - root - INFO - Step: 760 | Loss: 5.46 | Tokens per second: 39439.16 | Training tokens per second (%): 2.35 | MFU (%): 36.93 | TFLOPs: 365.26 | Global batch size: 128 | Global tokens/sec: 631026.64 | Global MFU (%): 36.93 | Global TFLOPs: 5844.21 | 
2025-05-19 08:52:21,530 - root - INFO - Step: 770 | Loss: 5.37 | Tokens per second: 35332.09 | Training tokens per second (%): 2.64 | MFU (%): 33.09 | TFLOPs: 327.23 | Global batch size: 128 | Global tokens/sec: 565313.47 | Global MFU (%): 33.09 | Global TFLOPs: 5235.61 | 
2025-05-19 08:52:25,840 - root - INFO - Step: 780 | Loss: 5.43 | Tokens per second: 38022.86 | Training tokens per second (%): 2.71 | MFU (%): 35.61 | TFLOPs: 352.15 | Global batch size: 128 | Global tokens/sec: 608365.75 | Global MFU (%): 35.61 | Global TFLOPs: 5634.34 | 
2025-05-19 08:52:30,164 - root - INFO - Step: 790 | Loss: 5.41 | Tokens per second: 37900.42 | Training tokens per second (%): 2.63 | MFU (%): 35.49 | TFLOPs: 351.01 | Global batch size: 128 | Global tokens/sec: 606406.72 | Global MFU (%): 35.49 | Global TFLOPs: 5616.19 | 
2025-05-19 08:52:34,517 - root - INFO - Step: 800 | Loss: 5.49 | Tokens per second: 37637.10 | Training tokens per second (%): 2.54 | MFU (%): 35.25 | TFLOPs: 348.57 | Global batch size: 128 | Global tokens/sec: 602193.60 | Global MFU (%): 35.25 | Global TFLOPs: 5577.17 | 
2025-05-19 08:52:38,981 - root - INFO - Step: 810 | Loss: 5.44 | Tokens per second: 36714.17 | Training tokens per second (%): 2.39 | MFU (%): 34.38 | TFLOPs: 340.03 | Global batch size: 128 | Global tokens/sec: 587426.72 | Global MFU (%): 34.38 | Global TFLOPs: 5440.41 | 
2025-05-19 08:52:43,174 - root - INFO - Step: 820 | Loss: 5.35 | Tokens per second: 39082.55 | Training tokens per second (%): 2.38 | MFU (%): 36.60 | TFLOPs: 361.96 | Global batch size: 128 | Global tokens/sec: 625320.77 | Global MFU (%): 36.60 | Global TFLOPs: 5791.36 | 
2025-05-19 08:52:47,522 - root - INFO - Step: 830 | Loss: 5.34 | Tokens per second: 37689.19 | Training tokens per second (%): 2.19 | MFU (%): 35.29 | TFLOPs: 349.06 | Global batch size: 128 | Global tokens/sec: 603027.07 | Global MFU (%): 35.29 | Global TFLOPs: 5584.89 | 
2025-05-19 08:52:52,171 - root - INFO - Step: 840 | Loss: 5.37 | Tokens per second: 35242.74 | Training tokens per second (%): 1.95 | MFU (%): 33.00 | TFLOPs: 326.40 | Global batch size: 128 | Global tokens/sec: 563883.85 | Global MFU (%): 33.00 | Global TFLOPs: 5222.37 | 
2025-05-19 08:52:56,576 - root - INFO - Step: 850 | Loss: 5.33 | Tokens per second: 37201.26 | Training tokens per second (%): 2.60 | MFU (%): 34.84 | TFLOPs: 344.54 | Global batch size: 128 | Global tokens/sec: 595220.19 | Global MFU (%): 34.84 | Global TFLOPs: 5512.59 | 
2025-05-19 08:53:01,036 - root - INFO - Step: 860 | Loss: 5.35 | Tokens per second: 36739.41 | Training tokens per second (%): 2.39 | MFU (%): 34.40 | TFLOPs: 340.26 | Global batch size: 128 | Global tokens/sec: 587830.61 | Global MFU (%): 34.40 | Global TFLOPs: 5444.15 | 
2025-05-19 08:53:05,402 - root - INFO - Step: 870 | Loss: 5.35 | Tokens per second: 37534.60 | Training tokens per second (%): 2.21 | MFU (%): 35.15 | TFLOPs: 347.62 | Global batch size: 128 | Global tokens/sec: 600553.67 | Global MFU (%): 35.15 | Global TFLOPs: 5561.99 | 
2025-05-19 08:53:09,726 - root - INFO - Step: 880 | Loss: 5.39 | Tokens per second: 37902.12 | Training tokens per second (%): 2.14 | MFU (%): 35.49 | TFLOPs: 351.03 | Global batch size: 128 | Global tokens/sec: 606433.90 | Global MFU (%): 35.49 | Global TFLOPs: 5616.44 | 
2025-05-19 08:53:13,856 - root - INFO - Step: 890 | Loss: 5.29 | Tokens per second: 39677.94 | Training tokens per second (%): 2.39 | MFU (%): 37.16 | TFLOPs: 367.47 | Global batch size: 128 | Global tokens/sec: 634847.07 | Global MFU (%): 37.16 | Global TFLOPs: 5879.59 | 
2025-05-19 08:53:18,313 - root - INFO - Step: 900 | Loss: 5.32 | Tokens per second: 36762.83 | Training tokens per second (%): 2.21 | MFU (%): 34.43 | TFLOPs: 340.48 | Global batch size: 128 | Global tokens/sec: 588205.23 | Global MFU (%): 34.43 | Global TFLOPs: 5447.62 | 
2025-05-19 08:53:22,604 - root - INFO - Step: 910 | Loss: 5.17 | Tokens per second: 38191.95 | Training tokens per second (%): 2.26 | MFU (%): 35.76 | TFLOPs: 353.71 | Global batch size: 128 | Global tokens/sec: 611071.21 | Global MFU (%): 35.76 | Global TFLOPs: 5659.39 | 
2025-05-19 08:53:26,970 - root - INFO - Step: 920 | Loss: 5.25 | Tokens per second: 37528.34 | Training tokens per second (%): 2.29 | MFU (%): 35.14 | TFLOPs: 347.57 | Global batch size: 128 | Global tokens/sec: 600453.41 | Global MFU (%): 35.14 | Global TFLOPs: 5561.06 | 
2025-05-19 08:53:31,505 - root - INFO - Step: 930 | Loss: 5.23 | Tokens per second: 36136.24 | Training tokens per second (%): 2.40 | MFU (%): 33.84 | TFLOPs: 334.67 | Global batch size: 128 | Global tokens/sec: 578179.81 | Global MFU (%): 33.84 | Global TFLOPs: 5354.77 | 
2025-05-19 08:53:35,827 - root - INFO - Step: 940 | Loss: 5.31 | Tokens per second: 37912.06 | Training tokens per second (%): 2.50 | MFU (%): 35.50 | TFLOPs: 351.12 | Global batch size: 128 | Global tokens/sec: 606592.94 | Global MFU (%): 35.50 | Global TFLOPs: 5617.92 | 
2025-05-19 08:53:40,203 - root - INFO - Step: 950 | Loss: 5.17 | Tokens per second: 37450.71 | Training tokens per second (%): 2.43 | MFU (%): 35.07 | TFLOPs: 346.85 | Global batch size: 128 | Global tokens/sec: 599211.40 | Global MFU (%): 35.07 | Global TFLOPs: 5549.55 | 
2025-05-19 08:53:44,576 - root - INFO - Step: 960 | Loss: 5.17 | Tokens per second: 37474.37 | Training tokens per second (%): 2.39 | MFU (%): 35.09 | TFLOPs: 347.07 | Global batch size: 128 | Global tokens/sec: 599589.92 | Global MFU (%): 35.09 | Global TFLOPs: 5553.06 | 
2025-05-19 08:53:49,147 - root - INFO - Step: 970 | Loss: 5.21 | Tokens per second: 35851.78 | Training tokens per second (%): 1.83 | MFU (%): 33.57 | TFLOPs: 332.04 | Global batch size: 128 | Global tokens/sec: 573628.55 | Global MFU (%): 33.57 | Global TFLOPs: 5312.62 | 
2025-05-19 08:53:53,516 - root - INFO - Step: 980 | Loss: 5.13 | Tokens per second: 37506.08 | Training tokens per second (%): 2.71 | MFU (%): 35.12 | TFLOPs: 347.36 | Global batch size: 128 | Global tokens/sec: 600097.23 | Global MFU (%): 35.12 | Global TFLOPs: 5557.76 | 
2025-05-19 08:53:57,900 - root - INFO - Step: 990 | Loss: 5.19 | Tokens per second: 37380.99 | Training tokens per second (%): 2.52 | MFU (%): 35.01 | TFLOPs: 346.20 | Global batch size: 128 | Global tokens/sec: 598095.83 | Global MFU (%): 35.01 | Global TFLOPs: 5539.22 | 
2025-05-19 08:54:02,301 - root - INFO - Step: 1000 | Loss: 5.13 | Tokens per second: 37228.01 | Training tokens per second (%): 2.09 | MFU (%): 34.86 | TFLOPs: 344.78 | Global batch size: 128 | Global tokens/sec: 595648.11 | Global MFU (%): 34.86 | Global TFLOPs: 5516.55 | 
2025-05-19 08:54:02,301 - root - INFO - Training completed
[sbatch-master] task finished

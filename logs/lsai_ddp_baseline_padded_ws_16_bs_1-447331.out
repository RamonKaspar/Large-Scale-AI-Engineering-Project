[sbatch-master] running on nid006645
[sbatch-master] SLURM_NODELIST: nid[006645-006646,006673-006674]
[sbatch-master] SLURM_NNODES: 4
[sbatch-master] SLURM_NODEID: 0
[Master] Master node: nid006645
[Master] World size: 16
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
[srun] rank=0 host=nid006645 noderank=0 localrank=0
W0518 21:07:31.681000 74039 torch/distributed/run.py:792] 
W0518 21:07:31.681000 74039 torch/distributed/run.py:792] *****************************************
W0518 21:07:31.681000 74039 torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0518 21:07:31.681000 74039 torch/distributed/run.py:792] *****************************************
[srun] rank=3 host=nid006674 noderank=3 localrank=0
[srun] rank=2 host=nid006673 noderank=2 localrank=0
[srun] rank=1 host=nid006646 noderank=1 localrank=0
W0518 21:07:35.150000 79733 torch/distributed/run.py:792] 
W0518 21:07:35.150000 79733 torch/distributed/run.py:792] *****************************************
W0518 21:07:35.150000 79733 torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0518 21:07:35.150000 79733 torch/distributed/run.py:792] *****************************************
W0518 21:07:35.150000 159590 torch/distributed/run.py:792] 
W0518 21:07:35.150000 159590 torch/distributed/run.py:792] *****************************************
W0518 21:07:35.150000 159590 torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0518 21:07:35.150000 159590 torch/distributed/run.py:792] *****************************************
W0518 21:07:35.175000 71184 torch/distributed/run.py:792] 
W0518 21:07:35.175000 71184 torch/distributed/run.py:792] *****************************************
W0518 21:07:35.175000 71184 torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0518 21:07:35.175000 71184 torch/distributed/run.py:792] *****************************************
2025-05-18 21:07:47,794 - root - INFO - [Distributed Init] Rank 12 initialized on node 3 on GPU 0.
2025-05-18 21:07:47,880 - root - INFO - [Distributed Init] Rank 0 initialized on node 0 on GPU 0.
2025-05-18 21:07:47,901 - root - INFO - [Distributed Init] Rank 8 initialized on node 2 on GPU 0.
2025-05-18 21:07:47,922 - root - INFO - [Distributed Init] Rank 4 initialized on node 1 on GPU 0.
[rank12]:[W518 21:07:48.771713439 ProcessGroupNCCL.cpp:4454] [PG ID 0 PG GUID 0 Rank 12]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank0]:[W518 21:07:48.835213382 ProcessGroupNCCL.cpp:4454] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank8]:[W518 21:07:48.753866739 ProcessGroupNCCL.cpp:4454] [PG ID 0 PG GUID 0 Rank 8]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank4]:[W518 21:07:48.467478007 ProcessGroupNCCL.cpp:4454] [PG ID 0 PG GUID 0 Rank 4]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
2025-05-18 21:07:48,378 - root - INFO - [Distributed Init] Rank 11 initialized on node 2 on GPU 3.
[rank11]:[W518 21:07:48.802349313 ProcessGroupNCCL.cpp:4454] [PG ID 0 PG GUID 0 Rank 11]  using GPU 3 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
2025-05-18 21:07:48,393 - root - INFO - [Distributed Init] Rank 1 initialized on node 0 on GPU 1.
[rank1]:[W518 21:07:48.912250403 ProcessGroupNCCL.cpp:4454] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
2025-05-18 21:07:48,434 - root - INFO - [Distributed Init] Rank 3 initialized on node 0 on GPU 3.
2025-05-18 21:07:48,434 - root - INFO - [Distributed Init] Rank 2 initialized on node 0 on GPU 2.
[rank3]:[W518 21:07:48.953053136 ProcessGroupNCCL.cpp:4454] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank2]:[W518 21:07:48.953053072 ProcessGroupNCCL.cpp:4454] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
2025-05-18 21:07:48,439 - root - INFO - [Distributed Init] Rank 5 initialized on node 1 on GPU 1.
2025-05-18 21:07:48,439 - root - INFO - [Distributed Init] Rank 7 initialized on node 1 on GPU 3.
[rank7]:[W518 21:07:48.573086544 ProcessGroupNCCL.cpp:4454] [PG ID 0 PG GUID 0 Rank 7]  using GPU 3 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank5]:[W518 21:07:48.573086224 ProcessGroupNCCL.cpp:4454] [PG ID 0 PG GUID 0 Rank 5]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
2025-05-18 21:07:48,449 - root - INFO - [Distributed Init] Rank 6 initialized on node 1 on GPU 2.
2025-05-18 21:07:48,449 - root - INFO - [Distributed Init] Rank 13 initialized on node 3 on GPU 1.
2025-05-18 21:07:48,449 - root - INFO - [Distributed Init] Rank 9 initialized on node 2 on GPU 1.
2025-05-18 21:07:48,449 - root - INFO - [Distributed Init] Rank 14 initialized on node 3 on GPU 2.
[rank13]:[W518 21:07:48.953677029 ProcessGroupNCCL.cpp:4454] [PG ID 0 PG GUID 0 Rank 13]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank14]:[W518 21:07:48.954216181 ProcessGroupNCCL.cpp:4454] [PG ID 0 PG GUID 0 Rank 14]  using GPU 2 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank6]:[W518 21:07:48.584207538 ProcessGroupNCCL.cpp:4454] [PG ID 0 PG GUID 0 Rank 6]  using GPU 2 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank9]:[W518 21:07:48.878988535 ProcessGroupNCCL.cpp:4454] [PG ID 0 PG GUID 0 Rank 9]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
2025-05-18 21:07:48,457 - root - INFO - [Distributed Init] Rank 15 initialized on node 3 on GPU 3.
[rank15]:[W518 21:07:48.963285517 ProcessGroupNCCL.cpp:4454] [PG ID 0 PG GUID 0 Rank 15]  using GPU 3 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
2025-05-18 21:07:48,498 - root - INFO - [Distributed Init] Rank 10 initialized on node 2 on GPU 2.
[rank10]:[W518 21:07:48.922055958 ProcessGroupNCCL.cpp:4454] [PG ID 0 PG GUID 0 Rank 10]  using GPU 2 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
2025-05-18 21:07:53,435 - root - INFO - [Rank 0] All ranks ready!
2025-05-18 21:07:53,435 - root - INFO - Distributed training enabled: 16 processes
2025-05-18 21:07:53,435 - root - INFO - Master process: 0 on cuda:0
2025-05-18 21:07:53,436 - root - INFO - Experiment args: Namespace(dataset='/capstor/scratch/cscs/kasparr/project/train_data.parquet', dataset_type='padded', pretokenized=False, tokenizer_name_or_path='unsloth/Mistral-Nemo-Base-2407-bnb-4bit', sequence_length=2048, batch_size=1, fused_optimizer=False, learning_rate=5e-05, lr_warmup_steps=100, training_steps=1000, logging_frequency=10, profile=False, profile_step_start=10, profile_step_end=10, grad_max_norm=1, model_dtype='bf16', compile=False, distributed=True, backend='nccl', find_unused_parameters=False)
2025-05-18 21:07:53,436 - root - INFO - Setting up Tokenizer...
2025-05-18 21:07:53,997 - root - INFO - Setting up DataLoaders...
2025-05-18 21:07:53,997 - root - INFO - Using padded ParquetDataset with on-the-fly tokenization
2025-05-18 21:08:05,599 - root - INFO - Setting up Model...
2025-05-18 21:08:41,740 - root - INFO - Model wrapped with DistributedDataParallel
2025-05-18 21:08:41,742 - root - INFO - Global batch size: 16 (local: 1 Ã— 16 processes)
2025-05-18 21:08:41,743 - root - INFO - Starting training!
/iopsstor/scratch/cscs/kasparr/project/src/train.py:236: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  num_items_tensor = torch.tensor(num_items_in_batch, device=device)
/iopsstor/scratch/cscs/kasparr/project/src/train.py:236: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  num_items_tensor = torch.tensor(num_items_in_batch, device=device)
/iopsstor/scratch/cscs/kasparr/project/src/train.py:236: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  num_items_tensor = torch.tensor(num_items_in_batch, device=device)
/iopsstor/scratch/cscs/kasparr/project/src/train.py:236: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  num_items_tensor = torch.tensor(num_items_in_batch, device=device)
/iopsstor/scratch/cscs/kasparr/project/src/train.py:236: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  num_items_tensor = torch.tensor(num_items_in_batch, device=device)
/iopsstor/scratch/cscs/kasparr/project/src/train.py:236: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  num_items_tensor = torch.tensor(num_items_in_batch, device=device)
/iopsstor/scratch/cscs/kasparr/project/src/train.py:236: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  num_items_tensor = torch.tensor(num_items_in_batch, device=device)
/iopsstor/scratch/cscs/kasparr/project/src/train.py:236: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  num_items_tensor = torch.tensor(num_items_in_batch, device=device)
/iopsstor/scratch/cscs/kasparr/project/src/train.py:236: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  num_items_tensor = torch.tensor(num_items_in_batch, device=device)
/iopsstor/scratch/cscs/kasparr/project/src/train.py:236: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  num_items_tensor = torch.tensor(num_items_in_batch, device=device)
/iopsstor/scratch/cscs/kasparr/project/src/train.py:236: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  num_items_tensor = torch.tensor(num_items_in_batch, device=device)
/iopsstor/scratch/cscs/kasparr/project/src/train.py:236: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  num_items_tensor = torch.tensor(num_items_in_batch, device=device)
/iopsstor/scratch/cscs/kasparr/project/src/train.py:236: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  num_items_tensor = torch.tensor(num_items_in_batch, device=device)
/iopsstor/scratch/cscs/kasparr/project/src/train.py:236: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  num_items_tensor = torch.tensor(num_items_in_batch, device=device)
/iopsstor/scratch/cscs/kasparr/project/src/train.py:236: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  num_items_tensor = torch.tensor(num_items_in_batch, device=device)
/iopsstor/scratch/cscs/kasparr/project/src/train.py:236: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  num_items_tensor = torch.tensor(num_items_in_batch, device=device)
2025-05-18 21:08:43,554 - root - INFO - Step: 1 | Loss: 11.96 | Tokens per second: 1131.47 | Training tokens per second (%): 3.06 | MFU (%): 5.90 | TFLOPs: 58.32 | Global batch size: 16 | Global tokens/sec: 18103.46 | Global MFU (%): 5.90 | Global TFLOPs: 933.07 | 
2025-05-18 21:08:48,714 - root - INFO - Step: 10 | Loss: 11.69 | Tokens per second: 3572.57 | Training tokens per second (%): 4.18 | MFU (%): 18.62 | TFLOPs: 184.13 | Global batch size: 16 | Global tokens/sec: 57161.14 | Global MFU (%): 18.62 | Global TFLOPs: 2946.15 | 
2025-05-18 21:08:54,493 - root - INFO - Step: 20 | Loss: 10.55 | Tokens per second: 3544.14 | Training tokens per second (%): 2.04 | MFU (%): 18.47 | TFLOPs: 182.67 | Global batch size: 16 | Global tokens/sec: 56706.22 | Global MFU (%): 18.47 | Global TFLOPs: 2922.71 | 
2025-05-18 21:09:00,203 - root - INFO - Step: 30 | Loss: 9.56 | Tokens per second: 3587.40 | Training tokens per second (%): 2.90 | MFU (%): 18.70 | TFLOPs: 184.90 | Global batch size: 16 | Global tokens/sec: 57398.38 | Global MFU (%): 18.70 | Global TFLOPs: 2958.38 | 
2025-05-18 21:09:05,931 - root - INFO - Step: 40 | Loss: 8.92 | Tokens per second: 3576.19 | Training tokens per second (%): 2.05 | MFU (%): 18.64 | TFLOPs: 184.32 | Global batch size: 16 | Global tokens/sec: 57219.06 | Global MFU (%): 18.64 | Global TFLOPs: 2949.14 | 
2025-05-18 21:09:11,736 - root - INFO - Step: 50 | Loss: 8.46 | Tokens per second: 3528.54 | Training tokens per second (%): 2.23 | MFU (%): 18.39 | TFLOPs: 181.86 | Global batch size: 16 | Global tokens/sec: 56456.57 | Global MFU (%): 18.39 | Global TFLOPs: 2909.84 | 
2025-05-18 21:09:17,558 - root - INFO - Step: 60 | Loss: 7.94 | Tokens per second: 3518.41 | Training tokens per second (%): 2.25 | MFU (%): 18.34 | TFLOPs: 181.34 | Global batch size: 16 | Global tokens/sec: 56294.51 | Global MFU (%): 18.34 | Global TFLOPs: 2901.49 | 
2025-05-18 21:09:23,517 - root - INFO - Step: 70 | Loss: 7.47 | Tokens per second: 3437.52 | Training tokens per second (%): 2.77 | MFU (%): 17.91 | TFLOPs: 177.17 | Global batch size: 16 | Global tokens/sec: 55000.29 | Global MFU (%): 17.91 | Global TFLOPs: 2834.78 | 
2025-05-18 21:09:29,238 - root - INFO - Step: 80 | Loss: 7.21 | Tokens per second: 3580.39 | Training tokens per second (%): 1.76 | MFU (%): 18.66 | TFLOPs: 184.54 | Global batch size: 16 | Global tokens/sec: 57286.32 | Global MFU (%): 18.66 | Global TFLOPs: 2952.61 | 
2025-05-18 21:09:34,947 - root - INFO - Step: 90 | Loss: 7.13 | Tokens per second: 3587.48 | Training tokens per second (%): 2.66 | MFU (%): 18.70 | TFLOPs: 184.90 | Global batch size: 16 | Global tokens/sec: 57399.71 | Global MFU (%): 18.70 | Global TFLOPs: 2958.45 | 
2025-05-18 21:09:40,659 - root - INFO - Step: 100 | Loss: 6.96 | Tokens per second: 3585.99 | Training tokens per second (%): 2.19 | MFU (%): 18.69 | TFLOPs: 184.83 | Global batch size: 16 | Global tokens/sec: 57375.79 | Global MFU (%): 18.69 | Global TFLOPs: 2957.22 | 
2025-05-18 21:09:46,388 - root - INFO - Step: 110 | Loss: 7.07 | Tokens per second: 3575.56 | Training tokens per second (%): 3.52 | MFU (%): 18.63 | TFLOPs: 184.29 | Global batch size: 16 | Global tokens/sec: 57209.01 | Global MFU (%): 18.63 | Global TFLOPs: 2948.62 | 
2025-05-18 21:09:52,102 - root - INFO - Step: 120 | Loss: 6.86 | Tokens per second: 3584.60 | Training tokens per second (%): 3.83 | MFU (%): 18.68 | TFLOPs: 184.75 | Global batch size: 16 | Global tokens/sec: 57353.62 | Global MFU (%): 18.68 | Global TFLOPs: 2956.07 | 
2025-05-18 21:09:57,822 - root - INFO - Step: 130 | Loss: 6.57 | Tokens per second: 3581.14 | Training tokens per second (%): 1.69 | MFU (%): 18.66 | TFLOPs: 184.58 | Global batch size: 16 | Global tokens/sec: 57298.22 | Global MFU (%): 18.66 | Global TFLOPs: 2953.22 | 
2025-05-18 21:10:03,536 - root - INFO - Step: 140 | Loss: 6.41 | Tokens per second: 3584.96 | Training tokens per second (%): 2.49 | MFU (%): 18.68 | TFLOPs: 184.77 | Global batch size: 16 | Global tokens/sec: 57359.37 | Global MFU (%): 18.68 | Global TFLOPs: 2956.37 | 
2025-05-18 21:10:09,253 - root - INFO - Step: 150 | Loss: 6.40 | Tokens per second: 3582.66 | Training tokens per second (%): 1.77 | MFU (%): 18.67 | TFLOPs: 184.65 | Global batch size: 16 | Global tokens/sec: 57322.61 | Global MFU (%): 18.67 | Global TFLOPs: 2954.48 | 
2025-05-18 21:10:14,983 - root - INFO - Step: 160 | Loss: 6.41 | Tokens per second: 3574.88 | Training tokens per second (%): 1.65 | MFU (%): 18.63 | TFLOPs: 184.25 | Global batch size: 16 | Global tokens/sec: 57198.11 | Global MFU (%): 18.63 | Global TFLOPs: 2948.06 | 
2025-05-18 21:10:20,705 - root - INFO - Step: 170 | Loss: 6.47 | Tokens per second: 3579.59 | Training tokens per second (%): 2.81 | MFU (%): 18.65 | TFLOPs: 184.50 | Global batch size: 16 | Global tokens/sec: 57273.41 | Global MFU (%): 18.65 | Global TFLOPs: 2951.94 | 
2025-05-18 21:10:26,417 - root - INFO - Step: 180 | Loss: 6.36 | Tokens per second: 3585.82 | Training tokens per second (%): 2.37 | MFU (%): 18.69 | TFLOPs: 184.82 | Global batch size: 16 | Global tokens/sec: 57373.16 | Global MFU (%): 18.69 | Global TFLOPs: 2957.08 | 
2025-05-18 21:10:32,162 - root - INFO - Step: 190 | Loss: 5.54 | Tokens per second: 3565.62 | Training tokens per second (%): 3.15 | MFU (%): 18.58 | TFLOPs: 183.78 | Global batch size: 16 | Global tokens/sec: 57049.91 | Global MFU (%): 18.58 | Global TFLOPs: 2940.42 | 
2025-05-18 21:10:37,890 - root - INFO - Step: 200 | Loss: 5.69 | Tokens per second: 3576.09 | Training tokens per second (%): 2.27 | MFU (%): 18.64 | TFLOPs: 184.32 | Global batch size: 16 | Global tokens/sec: 57217.39 | Global MFU (%): 18.64 | Global TFLOPs: 2949.05 | 
2025-05-18 21:10:43,628 - root - INFO - Step: 210 | Loss: 5.59 | Tokens per second: 3569.63 | Training tokens per second (%): 2.94 | MFU (%): 18.60 | TFLOPs: 183.98 | Global batch size: 16 | Global tokens/sec: 57114.05 | Global MFU (%): 18.60 | Global TFLOPs: 2943.73 | 
2025-05-18 21:10:49,343 - root - INFO - Step: 220 | Loss: 5.62 | Tokens per second: 3584.01 | Training tokens per second (%): 2.67 | MFU (%): 18.68 | TFLOPs: 184.72 | Global batch size: 16 | Global tokens/sec: 57344.13 | Global MFU (%): 18.68 | Global TFLOPs: 2955.59 | 
2025-05-18 21:10:55,070 - root - INFO - Step: 230 | Loss: 5.45 | Tokens per second: 3576.45 | Training tokens per second (%): 2.83 | MFU (%): 18.64 | TFLOPs: 184.33 | Global batch size: 16 | Global tokens/sec: 57223.20 | Global MFU (%): 18.64 | Global TFLOPs: 2949.35 | 
2025-05-18 21:11:00,815 - root - INFO - Step: 240 | Loss: 5.56 | Tokens per second: 3565.67 | Training tokens per second (%): 2.06 | MFU (%): 18.58 | TFLOPs: 183.78 | Global batch size: 16 | Global tokens/sec: 57050.67 | Global MFU (%): 18.58 | Global TFLOPs: 2940.46 | 
2025-05-18 21:11:06,533 - root - INFO - Step: 250 | Loss: 5.31 | Tokens per second: 3582.14 | Training tokens per second (%): 1.71 | MFU (%): 18.67 | TFLOPs: 184.63 | Global batch size: 16 | Global tokens/sec: 57314.31 | Global MFU (%): 18.67 | Global TFLOPs: 2954.05 | 
2025-05-18 21:11:12,254 - root - INFO - Step: 260 | Loss: 5.10 | Tokens per second: 3580.09 | Training tokens per second (%): 1.59 | MFU (%): 18.66 | TFLOPs: 184.52 | Global batch size: 16 | Global tokens/sec: 57281.39 | Global MFU (%): 18.66 | Global TFLOPs: 2952.35 | 
2025-05-18 21:11:17,982 - root - INFO - Step: 270 | Loss: 4.74 | Tokens per second: 3576.25 | Training tokens per second (%): 2.54 | MFU (%): 18.64 | TFLOPs: 184.32 | Global batch size: 16 | Global tokens/sec: 57219.95 | Global MFU (%): 18.64 | Global TFLOPs: 2949.19 | 
2025-05-18 21:11:23,703 - root - INFO - Step: 280 | Loss: 4.81 | Tokens per second: 3580.34 | Training tokens per second (%): 2.45 | MFU (%): 18.66 | TFLOPs: 184.53 | Global batch size: 16 | Global tokens/sec: 57285.39 | Global MFU (%): 18.66 | Global TFLOPs: 2952.56 | 
2025-05-18 21:11:29,433 - root - INFO - Step: 290 | Loss: 5.21 | Tokens per second: 3574.87 | Training tokens per second (%): 1.86 | MFU (%): 18.63 | TFLOPs: 184.25 | Global batch size: 16 | Global tokens/sec: 57197.90 | Global MFU (%): 18.63 | Global TFLOPs: 2948.05 | 
2025-05-18 21:11:35,156 - root - INFO - Step: 300 | Loss: 5.18 | Tokens per second: 3578.86 | Training tokens per second (%): 2.45 | MFU (%): 18.65 | TFLOPs: 184.46 | Global batch size: 16 | Global tokens/sec: 57261.76 | Global MFU (%): 18.65 | Global TFLOPs: 2951.34 | 
2025-05-18 21:11:40,880 - root - INFO - Step: 310 | Loss: 4.76 | Tokens per second: 3578.81 | Training tokens per second (%): 2.37 | MFU (%): 18.65 | TFLOPs: 184.46 | Global batch size: 16 | Global tokens/sec: 57260.97 | Global MFU (%): 18.65 | Global TFLOPs: 2951.30 | 
2025-05-18 21:11:46,607 - root - INFO - Step: 320 | Loss: 4.38 | Tokens per second: 3576.51 | Training tokens per second (%): 2.69 | MFU (%): 18.64 | TFLOPs: 184.34 | Global batch size: 16 | Global tokens/sec: 57224.18 | Global MFU (%): 18.64 | Global TFLOPs: 2949.40 | 
2025-05-18 21:11:52,330 - root - INFO - Step: 330 | Loss: 4.20 | Tokens per second: 3579.15 | Training tokens per second (%): 3.68 | MFU (%): 18.65 | TFLOPs: 184.47 | Global batch size: 16 | Global tokens/sec: 57266.42 | Global MFU (%): 18.65 | Global TFLOPs: 2951.58 | 
2025-05-18 21:11:58,056 - root - INFO - Step: 340 | Loss: 4.05 | Tokens per second: 3576.81 | Training tokens per second (%): 3.04 | MFU (%): 18.64 | TFLOPs: 184.35 | Global batch size: 16 | Global tokens/sec: 57228.93 | Global MFU (%): 18.64 | Global TFLOPs: 2949.65 | 
2025-05-18 21:12:03,771 - root - INFO - Step: 350 | Loss: 4.52 | Tokens per second: 3584.28 | Training tokens per second (%): 2.69 | MFU (%): 18.68 | TFLOPs: 184.74 | Global batch size: 16 | Global tokens/sec: 57348.50 | Global MFU (%): 18.68 | Global TFLOPs: 2955.81 | 
2025-05-18 21:12:09,496 - root - INFO - Step: 360 | Loss: 4.70 | Tokens per second: 3578.11 | Training tokens per second (%): 2.84 | MFU (%): 18.65 | TFLOPs: 184.42 | Global batch size: 16 | Global tokens/sec: 57249.82 | Global MFU (%): 18.65 | Global TFLOPs: 2950.72 | 
2025-05-18 21:12:15,217 - root - INFO - Step: 370 | Loss: 4.81 | Tokens per second: 3580.17 | Training tokens per second (%): 2.49 | MFU (%): 18.66 | TFLOPs: 184.53 | Global batch size: 16 | Global tokens/sec: 57282.64 | Global MFU (%): 18.66 | Global TFLOPs: 2952.42 | 
2025-05-18 21:12:20,938 - root - INFO - Step: 380 | Loss: 4.17 | Tokens per second: 3580.27 | Training tokens per second (%): 2.48 | MFU (%): 18.66 | TFLOPs: 184.53 | Global batch size: 16 | Global tokens/sec: 57284.28 | Global MFU (%): 18.66 | Global TFLOPs: 2952.50 | 
2025-05-18 21:12:26,656 - root - INFO - Step: 390 | Loss: 4.43 | Tokens per second: 3582.46 | Training tokens per second (%): 1.97 | MFU (%): 18.67 | TFLOPs: 184.64 | Global batch size: 16 | Global tokens/sec: 57319.39 | Global MFU (%): 18.67 | Global TFLOPs: 2954.31 | 
2025-05-18 21:12:32,393 - root - INFO - Step: 400 | Loss: 3.56 | Tokens per second: 3570.28 | Training tokens per second (%): 1.50 | MFU (%): 18.61 | TFLOPs: 184.02 | Global batch size: 16 | Global tokens/sec: 57124.55 | Global MFU (%): 18.61 | Global TFLOPs: 2944.27 | 
2025-05-18 21:12:38,126 - root - INFO - Step: 410 | Loss: 4.05 | Tokens per second: 3572.93 | Training tokens per second (%): 2.35 | MFU (%): 18.62 | TFLOPs: 184.15 | Global batch size: 16 | Global tokens/sec: 57166.89 | Global MFU (%): 18.62 | Global TFLOPs: 2946.45 | 
2025-05-18 21:12:43,846 - root - INFO - Step: 420 | Loss: 4.30 | Tokens per second: 3580.75 | Training tokens per second (%): 2.93 | MFU (%): 18.66 | TFLOPs: 184.56 | Global batch size: 16 | Global tokens/sec: 57291.99 | Global MFU (%): 18.66 | Global TFLOPs: 2952.90 | 
2025-05-18 21:12:49,587 - root - INFO - Step: 430 | Loss: 4.05 | Tokens per second: 3568.05 | Training tokens per second (%): 2.30 | MFU (%): 18.59 | TFLOPs: 183.90 | Global batch size: 16 | Global tokens/sec: 57088.84 | Global MFU (%): 18.59 | Global TFLOPs: 2942.43 | 
2025-05-18 21:12:55,300 - root - INFO - Step: 440 | Loss: 3.25 | Tokens per second: 3585.31 | Training tokens per second (%): 1.98 | MFU (%): 18.68 | TFLOPs: 184.79 | Global batch size: 16 | Global tokens/sec: 57365.02 | Global MFU (%): 18.68 | Global TFLOPs: 2956.66 | 
2025-05-18 21:13:01,017 - root - INFO - Step: 450 | Loss: 3.17 | Tokens per second: 3582.63 | Training tokens per second (%): 1.70 | MFU (%): 18.67 | TFLOPs: 184.65 | Global batch size: 16 | Global tokens/sec: 57322.04 | Global MFU (%): 18.67 | Global TFLOPs: 2954.45 | 
2025-05-18 21:13:06,752 - root - INFO - Step: 460 | Loss: 3.19 | Tokens per second: 3571.68 | Training tokens per second (%): 3.43 | MFU (%): 18.61 | TFLOPs: 184.09 | Global batch size: 16 | Global tokens/sec: 57146.94 | Global MFU (%): 18.61 | Global TFLOPs: 2945.42 | 
2025-05-18 21:13:12,467 - root - INFO - Step: 470 | Loss: 3.35 | Tokens per second: 3584.33 | Training tokens per second (%): 3.02 | MFU (%): 18.68 | TFLOPs: 184.74 | Global batch size: 16 | Global tokens/sec: 57349.25 | Global MFU (%): 18.68 | Global TFLOPs: 2955.85 | 
2025-05-18 21:13:18,194 - root - INFO - Step: 480 | Loss: 3.51 | Tokens per second: 3576.75 | Training tokens per second (%): 2.31 | MFU (%): 18.64 | TFLOPs: 184.35 | Global batch size: 16 | Global tokens/sec: 57227.96 | Global MFU (%): 18.64 | Global TFLOPs: 2949.60 | 
2025-05-18 21:13:23,908 - root - INFO - Step: 490 | Loss: 3.43 | Tokens per second: 3584.22 | Training tokens per second (%): 2.67 | MFU (%): 18.68 | TFLOPs: 184.73 | Global batch size: 16 | Global tokens/sec: 57347.51 | Global MFU (%): 18.68 | Global TFLOPs: 2955.76 | 
2025-05-18 21:13:29,633 - root - INFO - Step: 500 | Loss: 3.24 | Tokens per second: 3578.34 | Training tokens per second (%): 2.65 | MFU (%): 18.65 | TFLOPs: 184.43 | Global batch size: 16 | Global tokens/sec: 57253.40 | Global MFU (%): 18.65 | Global TFLOPs: 2950.91 | 
2025-05-18 21:13:35,380 - root - INFO - Step: 510 | Loss: 2.84 | Tokens per second: 3563.81 | Training tokens per second (%): 2.56 | MFU (%): 18.57 | TFLOPs: 183.68 | Global batch size: 16 | Global tokens/sec: 57020.98 | Global MFU (%): 18.57 | Global TFLOPs: 2938.93 | 
2025-05-18 21:13:41,110 - root - INFO - Step: 520 | Loss: 2.98 | Tokens per second: 3574.97 | Training tokens per second (%): 2.63 | MFU (%): 18.63 | TFLOPs: 184.26 | Global batch size: 16 | Global tokens/sec: 57199.45 | Global MFU (%): 18.63 | Global TFLOPs: 2948.13 | 
2025-05-18 21:13:46,837 - root - INFO - Step: 530 | Loss: 2.59 | Tokens per second: 3576.18 | Training tokens per second (%): 2.70 | MFU (%): 18.64 | TFLOPs: 184.32 | Global batch size: 16 | Global tokens/sec: 57218.94 | Global MFU (%): 18.64 | Global TFLOPs: 2949.13 | 
2025-05-18 21:13:52,550 - root - INFO - Step: 540 | Loss: 2.94 | Tokens per second: 3585.69 | Training tokens per second (%): 4.15 | MFU (%): 18.69 | TFLOPs: 184.81 | Global batch size: 16 | Global tokens/sec: 57371.00 | Global MFU (%): 18.69 | Global TFLOPs: 2956.97 | 
2025-05-18 21:13:58,253 - root - INFO - Step: 550 | Loss: 3.37 | Tokens per second: 3591.85 | Training tokens per second (%): 2.08 | MFU (%): 18.72 | TFLOPs: 185.13 | Global batch size: 16 | Global tokens/sec: 57469.55 | Global MFU (%): 18.72 | Global TFLOPs: 2962.05 | 
2025-05-18 21:14:03,987 - root - INFO - Step: 560 | Loss: 2.75 | Tokens per second: 3572.02 | Training tokens per second (%): 2.66 | MFU (%): 18.62 | TFLOPs: 184.11 | Global batch size: 16 | Global tokens/sec: 57152.26 | Global MFU (%): 18.62 | Global TFLOPs: 2945.70 | 
2025-05-18 21:14:09,716 - root - INFO - Step: 570 | Loss: 2.40 | Tokens per second: 3575.34 | Training tokens per second (%): 3.55 | MFU (%): 18.63 | TFLOPs: 184.28 | Global batch size: 16 | Global tokens/sec: 57205.48 | Global MFU (%): 18.63 | Global TFLOPs: 2948.44 | 
2025-05-18 21:14:15,436 - root - INFO - Step: 580 | Loss: 1.97 | Tokens per second: 3580.74 | Training tokens per second (%): 1.80 | MFU (%): 18.66 | TFLOPs: 184.56 | Global batch size: 16 | Global tokens/sec: 57291.81 | Global MFU (%): 18.66 | Global TFLOPs: 2952.89 | 
2025-05-18 21:14:21,161 - root - INFO - Step: 590 | Loss: 2.32 | Tokens per second: 3577.90 | Training tokens per second (%): 2.14 | MFU (%): 18.65 | TFLOPs: 184.41 | Global batch size: 16 | Global tokens/sec: 57246.46 | Global MFU (%): 18.65 | Global TFLOPs: 2950.55 | 
2025-05-18 21:14:26,877 - root - INFO - Step: 600 | Loss: 1.98 | Tokens per second: 3583.65 | Training tokens per second (%): 2.83 | MFU (%): 18.68 | TFLOPs: 184.71 | Global batch size: 16 | Global tokens/sec: 57338.33 | Global MFU (%): 18.68 | Global TFLOPs: 2955.29 | 
2025-05-18 21:14:32,611 - root - INFO - Step: 610 | Loss: 2.14 | Tokens per second: 3572.01 | Training tokens per second (%): 2.80 | MFU (%): 18.62 | TFLOPs: 184.11 | Global batch size: 16 | Global tokens/sec: 57152.12 | Global MFU (%): 18.62 | Global TFLOPs: 2945.69 | 
2025-05-18 21:14:38,353 - root - INFO - Step: 620 | Loss: 2.23 | Tokens per second: 3567.70 | Training tokens per second (%): 2.87 | MFU (%): 18.59 | TFLOPs: 183.88 | Global batch size: 16 | Global tokens/sec: 57083.27 | Global MFU (%): 18.59 | Global TFLOPs: 2942.14 | 
2025-05-18 21:14:44,073 - root - INFO - Step: 630 | Loss: 2.29 | Tokens per second: 3580.92 | Training tokens per second (%): 3.12 | MFU (%): 18.66 | TFLOPs: 184.56 | Global batch size: 16 | Global tokens/sec: 57294.71 | Global MFU (%): 18.66 | Global TFLOPs: 2953.04 | 
2025-05-18 21:14:49,801 - root - INFO - Step: 640 | Loss: 2.23 | Tokens per second: 3575.93 | Training tokens per second (%): 3.26 | MFU (%): 18.64 | TFLOPs: 184.31 | Global batch size: 16 | Global tokens/sec: 57214.93 | Global MFU (%): 18.64 | Global TFLOPs: 2948.93 | 
2025-05-18 21:14:55,538 - root - INFO - Step: 650 | Loss: 1.76 | Tokens per second: 3570.47 | Training tokens per second (%): 1.63 | MFU (%): 18.61 | TFLOPs: 184.03 | Global batch size: 16 | Global tokens/sec: 57127.46 | Global MFU (%): 18.61 | Global TFLOPs: 2944.42 | 
2025-05-18 21:15:01,266 - root - INFO - Step: 660 | Loss: 2.28 | Tokens per second: 3575.96 | Training tokens per second (%): 1.64 | MFU (%): 18.64 | TFLOPs: 184.31 | Global batch size: 16 | Global tokens/sec: 57215.42 | Global MFU (%): 18.64 | Global TFLOPs: 2948.95 | 
2025-05-18 21:15:06,990 - root - INFO - Step: 670 | Loss: 2.03 | Tokens per second: 3577.95 | Training tokens per second (%): 2.59 | MFU (%): 18.65 | TFLOPs: 184.41 | Global batch size: 16 | Global tokens/sec: 57247.20 | Global MFU (%): 18.65 | Global TFLOPs: 2950.59 | 
2025-05-18 21:15:12,718 - root - INFO - Step: 680 | Loss: 1.73 | Tokens per second: 3576.10 | Training tokens per second (%): 2.68 | MFU (%): 18.64 | TFLOPs: 184.32 | Global batch size: 16 | Global tokens/sec: 57217.60 | Global MFU (%): 18.64 | Global TFLOPs: 2949.06 | 
2025-05-18 21:15:18,466 - root - INFO - Step: 690 | Loss: 2.18 | Tokens per second: 3563.51 | Training tokens per second (%): 3.43 | MFU (%): 18.57 | TFLOPs: 183.67 | Global batch size: 16 | Global tokens/sec: 57016.14 | Global MFU (%): 18.57 | Global TFLOPs: 2938.68 | 
2025-05-18 21:15:24,207 - root - INFO - Step: 700 | Loss: 1.18 | Tokens per second: 3567.88 | Training tokens per second (%): 3.08 | MFU (%): 18.59 | TFLOPs: 183.89 | Global batch size: 16 | Global tokens/sec: 57086.09 | Global MFU (%): 18.59 | Global TFLOPs: 2942.29 | 
2025-05-18 21:15:29,936 - root - INFO - Step: 710 | Loss: 1.56 | Tokens per second: 3575.65 | Training tokens per second (%): 2.36 | MFU (%): 18.63 | TFLOPs: 184.29 | Global batch size: 16 | Global tokens/sec: 57210.34 | Global MFU (%): 18.63 | Global TFLOPs: 2948.69 | 
2025-05-18 21:15:35,673 - root - INFO - Step: 720 | Loss: 1.02 | Tokens per second: 3570.47 | Training tokens per second (%): 2.29 | MFU (%): 18.61 | TFLOPs: 184.03 | Global batch size: 16 | Global tokens/sec: 57127.56 | Global MFU (%): 18.61 | Global TFLOPs: 2944.42 | 
2025-05-18 21:15:41,415 - root - INFO - Step: 730 | Loss: 1.26 | Tokens per second: 3567.11 | Training tokens per second (%): 2.65 | MFU (%): 18.59 | TFLOPs: 183.85 | Global batch size: 16 | Global tokens/sec: 57073.75 | Global MFU (%): 18.59 | Global TFLOPs: 2941.65 | 
2025-05-18 21:15:47,146 - root - INFO - Step: 740 | Loss: 1.02 | Tokens per second: 3573.83 | Training tokens per second (%): 2.54 | MFU (%): 18.62 | TFLOPs: 184.20 | Global batch size: 16 | Global tokens/sec: 57181.27 | Global MFU (%): 18.62 | Global TFLOPs: 2947.19 | 
2025-05-18 21:15:52,868 - root - INFO - Step: 750 | Loss: 1.18 | Tokens per second: 3579.66 | Training tokens per second (%): 2.13 | MFU (%): 18.66 | TFLOPs: 184.50 | Global batch size: 16 | Global tokens/sec: 57274.61 | Global MFU (%): 18.66 | Global TFLOPs: 2952.00 | 
2025-05-18 21:15:58,587 - root - INFO - Step: 760 | Loss: 1.19 | Tokens per second: 3581.78 | Training tokens per second (%): 2.33 | MFU (%): 18.67 | TFLOPs: 184.61 | Global batch size: 16 | Global tokens/sec: 57308.42 | Global MFU (%): 18.67 | Global TFLOPs: 2953.74 | 
2025-05-18 21:16:04,334 - root - INFO - Step: 770 | Loss: 0.92 | Tokens per second: 3564.45 | Training tokens per second (%): 2.39 | MFU (%): 18.58 | TFLOPs: 183.72 | Global batch size: 16 | Global tokens/sec: 57031.14 | Global MFU (%): 18.58 | Global TFLOPs: 2939.45 | 
2025-05-18 21:16:10,056 - root - INFO - Step: 780 | Loss: 0.82 | Tokens per second: 3579.59 | Training tokens per second (%): 2.80 | MFU (%): 18.65 | TFLOPs: 184.50 | Global batch size: 16 | Global tokens/sec: 57273.48 | Global MFU (%): 18.65 | Global TFLOPs: 2951.94 | 
2025-05-18 21:16:15,789 - root - INFO - Step: 790 | Loss: 1.16 | Tokens per second: 3572.94 | Training tokens per second (%): 2.78 | MFU (%): 18.62 | TFLOPs: 184.15 | Global batch size: 16 | Global tokens/sec: 57167.03 | Global MFU (%): 18.62 | Global TFLOPs: 2946.46 | 
2025-05-18 21:16:21,532 - root - INFO - Step: 800 | Loss: 0.97 | Tokens per second: 3566.19 | Training tokens per second (%): 3.28 | MFU (%): 18.58 | TFLOPs: 183.81 | Global batch size: 16 | Global tokens/sec: 57058.98 | Global MFU (%): 18.58 | Global TFLOPs: 2940.89 | 
2025-05-18 21:16:27,254 - root - INFO - Step: 810 | Loss: 0.95 | Tokens per second: 3579.80 | Training tokens per second (%): 3.22 | MFU (%): 18.66 | TFLOPs: 184.51 | Global batch size: 16 | Global tokens/sec: 57276.84 | Global MFU (%): 18.66 | Global TFLOPs: 2952.12 | 
2025-05-18 21:16:33,002 - root - INFO - Step: 820 | Loss: 0.64 | Tokens per second: 3564.03 | Training tokens per second (%): 2.10 | MFU (%): 18.57 | TFLOPs: 183.69 | Global batch size: 16 | Global tokens/sec: 57024.45 | Global MFU (%): 18.57 | Global TFLOPs: 2939.11 | 
2025-05-18 21:16:38,725 - root - INFO - Step: 830 | Loss: 0.52 | Tokens per second: 3578.90 | Training tokens per second (%): 2.09 | MFU (%): 18.65 | TFLOPs: 184.46 | Global batch size: 16 | Global tokens/sec: 57262.32 | Global MFU (%): 18.65 | Global TFLOPs: 2951.37 | 
2025-05-18 21:16:44,479 - root - INFO - Step: 840 | Loss: 0.59 | Tokens per second: 3559.58 | Training tokens per second (%): 2.28 | MFU (%): 18.55 | TFLOPs: 183.46 | Global batch size: 16 | Global tokens/sec: 56953.25 | Global MFU (%): 18.55 | Global TFLOPs: 2935.44 | 
2025-05-18 21:16:50,211 - root - INFO - Step: 850 | Loss: 0.67 | Tokens per second: 3573.54 | Training tokens per second (%): 2.06 | MFU (%): 18.62 | TFLOPs: 184.18 | Global batch size: 16 | Global tokens/sec: 57176.64 | Global MFU (%): 18.62 | Global TFLOPs: 2946.95 | 
2025-05-18 21:16:55,950 - root - INFO - Step: 860 | Loss: 0.88 | Tokens per second: 3569.35 | Training tokens per second (%): 1.39 | MFU (%): 18.60 | TFLOPs: 183.97 | Global batch size: 16 | Global tokens/sec: 57109.62 | Global MFU (%): 18.60 | Global TFLOPs: 2943.50 | 
2025-05-18 21:17:01,672 - root - INFO - Step: 870 | Loss: 0.69 | Tokens per second: 3579.73 | Training tokens per second (%): 2.66 | MFU (%): 18.66 | TFLOPs: 184.50 | Global batch size: 16 | Global tokens/sec: 57275.74 | Global MFU (%): 18.66 | Global TFLOPs: 2952.06 | 
2025-05-18 21:17:07,424 - root - INFO - Step: 880 | Loss: 0.77 | Tokens per second: 3561.13 | Training tokens per second (%): 1.18 | MFU (%): 18.56 | TFLOPs: 183.54 | Global batch size: 16 | Global tokens/sec: 56978.05 | Global MFU (%): 18.56 | Global TFLOPs: 2936.72 | 
2025-05-18 21:17:13,143 - root - INFO - Step: 890 | Loss: 0.66 | Tokens per second: 3581.17 | Training tokens per second (%): 2.59 | MFU (%): 18.66 | TFLOPs: 184.58 | Global batch size: 16 | Global tokens/sec: 57298.74 | Global MFU (%): 18.66 | Global TFLOPs: 2953.25 | 
2025-05-18 21:17:18,888 - root - INFO - Step: 900 | Loss: 0.37 | Tokens per second: 3565.52 | Training tokens per second (%): 2.35 | MFU (%): 18.58 | TFLOPs: 183.77 | Global batch size: 16 | Global tokens/sec: 57048.26 | Global MFU (%): 18.58 | Global TFLOPs: 2940.34 | 
2025-05-18 21:17:24,615 - root - INFO - Step: 910 | Loss: 0.34 | Tokens per second: 3576.51 | Training tokens per second (%): 2.61 | MFU (%): 18.64 | TFLOPs: 184.34 | Global batch size: 16 | Global tokens/sec: 57224.16 | Global MFU (%): 18.64 | Global TFLOPs: 2949.40 | 
2025-05-18 21:17:30,360 - root - INFO - Step: 920 | Loss: 0.58 | Tokens per second: 3565.34 | Training tokens per second (%): 2.87 | MFU (%): 18.58 | TFLOPs: 183.76 | Global batch size: 16 | Global tokens/sec: 57045.42 | Global MFU (%): 18.58 | Global TFLOPs: 2940.19 | 
2025-05-18 21:17:36,098 - root - INFO - Step: 930 | Loss: 0.32 | Tokens per second: 3570.16 | Training tokens per second (%): 2.76 | MFU (%): 18.61 | TFLOPs: 184.01 | Global batch size: 16 | Global tokens/sec: 57122.60 | Global MFU (%): 18.61 | Global TFLOPs: 2944.17 | 
2025-05-18 21:17:41,831 - root - INFO - Step: 940 | Loss: 0.64 | Tokens per second: 3572.66 | Training tokens per second (%): 1.79 | MFU (%): 18.62 | TFLOPs: 184.14 | Global batch size: 16 | Global tokens/sec: 57162.64 | Global MFU (%): 18.62 | Global TFLOPs: 2946.23 | 
2025-05-18 21:17:47,575 - root - INFO - Step: 950 | Loss: 0.46 | Tokens per second: 3566.06 | Training tokens per second (%): 2.75 | MFU (%): 18.58 | TFLOPs: 183.80 | Global batch size: 16 | Global tokens/sec: 57056.95 | Global MFU (%): 18.58 | Global TFLOPs: 2940.78 | 
2025-05-18 21:17:53,309 - root - INFO - Step: 960 | Loss: 0.79 | Tokens per second: 3572.10 | Training tokens per second (%): 3.24 | MFU (%): 18.62 | TFLOPs: 184.11 | Global batch size: 16 | Global tokens/sec: 57153.63 | Global MFU (%): 18.62 | Global TFLOPs: 2945.77 | 
2025-05-18 21:17:59,060 - root - INFO - Step: 970 | Loss: 0.42 | Tokens per second: 3561.78 | Training tokens per second (%): 2.11 | MFU (%): 18.56 | TFLOPs: 183.58 | Global batch size: 16 | Global tokens/sec: 56988.47 | Global MFU (%): 18.56 | Global TFLOPs: 2937.25 | 
2025-05-18 21:18:04,787 - root - INFO - Step: 980 | Loss: 0.54 | Tokens per second: 3576.48 | Training tokens per second (%): 2.26 | MFU (%): 18.64 | TFLOPs: 184.34 | Global batch size: 16 | Global tokens/sec: 57223.66 | Global MFU (%): 18.64 | Global TFLOPs: 2949.38 | 
2025-05-18 21:18:10,524 - root - INFO - Step: 990 | Loss: 0.21 | Tokens per second: 3570.58 | Training tokens per second (%): 2.51 | MFU (%): 18.61 | TFLOPs: 184.03 | Global batch size: 16 | Global tokens/sec: 57129.22 | Global MFU (%): 18.61 | Global TFLOPs: 2944.51 | 
2025-05-18 21:18:16,256 - root - INFO - Step: 1000 | Loss: 0.43 | Tokens per second: 3573.38 | Training tokens per second (%): 1.86 | MFU (%): 18.62 | TFLOPs: 184.18 | Global batch size: 16 | Global tokens/sec: 57174.13 | Global MFU (%): 18.62 | Global TFLOPs: 2946.82 | 
2025-05-18 21:18:16,256 - root - INFO - Training completed
[sbatch-master] task finished

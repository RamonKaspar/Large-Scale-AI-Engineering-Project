[sbatch-master] running on nid006548
[sbatch-master] SLURM_NODELIST: nid006548
[sbatch-master] SLURM_NNODES: 1
[sbatch-master] SLURM_NODEID: 0
[Master] Master node: nid006548
[Master] World size: 4
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
[srun] rank=0 host=nid006548 noderank=0 localrank=0
W0518 21:52:11.686000 286606 torch/distributed/run.py:792] 
W0518 21:52:11.686000 286606 torch/distributed/run.py:792] *****************************************
W0518 21:52:11.686000 286606 torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0518 21:52:11.686000 286606 torch/distributed/run.py:792] *****************************************
2025-05-18 21:52:26,202 - root - INFO - [Distributed Init] Rank 0 initialized on node 0 on GPU 0.
[rank0]:[W518 21:52:26.511899724 ProcessGroupNCCL.cpp:4454] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
2025-05-18 21:52:26,752 - root - INFO - [Distributed Init] Rank 3 initialized on node 0 on GPU 3.
[rank3]:[W518 21:52:26.593333693 ProcessGroupNCCL.cpp:4454] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
2025-05-18 21:52:26,831 - root - INFO - [Distributed Init] Rank 2 initialized on node 0 on GPU 2.
2025-05-18 21:52:26,831 - root - INFO - [Distributed Init] Rank 1 initialized on node 0 on GPU 1.
[rank2]:[W518 21:52:26.672983941 ProcessGroupNCCL.cpp:4454] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank1]:[W518 21:52:26.673266940 ProcessGroupNCCL.cpp:4454] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
2025-05-18 21:52:33,871 - root - INFO - [Rank 0] All ranks ready!
2025-05-18 21:52:33,872 - root - INFO - Distributed training enabled: 4 processes
2025-05-18 21:52:33,872 - root - INFO - Master process: 0 on cuda:0
2025-05-18 21:52:33,872 - root - INFO - Experiment args: Namespace(dataset='/capstor/scratch/cscs/kasparr/project/train_data_tokenized_padded_snappy.parquet', dataset_type='padded', pretokenized=True, tokenizer_name_or_path='unsloth/Mistral-Nemo-Base-2407-bnb-4bit', sequence_length=2048, batch_size=1, fused_optimizer=False, learning_rate=5e-05, lr_warmup_steps=100, training_steps=1000, logging_frequency=10, profile=False, profile_step_start=10, profile_step_end=10, grad_max_norm=1, model_dtype='bf16', compile=False, distributed=True, backend='nccl', find_unused_parameters=False)
2025-05-18 21:52:33,872 - root - INFO - Setting up Tokenizer...
2025-05-18 21:52:34,431 - root - INFO - Setting up DataLoaders...
2025-05-18 21:52:34,432 - root - INFO - Using pretokenized data: /capstor/scratch/cscs/kasparr/project/train_data_tokenized_padded_snappy.parquet
Loaded pretokenized dataset with 785906 samples
Loaded pretokenized dataset with 785906 samples
Loaded pretokenized dataset with 785906 samples
2025-05-18 21:53:05,623 - root - INFO - Setting up Model...
Loaded pretokenized dataset with 785906 samples
2025-05-18 21:53:41,048 - root - INFO - Model wrapped with DistributedDataParallel
2025-05-18 21:53:41,049 - root - INFO - Global batch size: 4 (local: 1 Ã— 4 processes)
2025-05-18 21:53:41,050 - root - INFO - Starting training!
/iopsstor/scratch/cscs/kasparr/project/src/train.py:236: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  num_items_tensor = torch.tensor(num_items_in_batch, device=device)
/iopsstor/scratch/cscs/kasparr/project/src/train.py:236: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  num_items_tensor = torch.tensor(num_items_in_batch, device=device)
/iopsstor/scratch/cscs/kasparr/project/src/train.py:236: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  num_items_tensor = torch.tensor(num_items_in_batch, device=device)
/iopsstor/scratch/cscs/kasparr/project/src/train.py:236: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  num_items_tensor = torch.tensor(num_items_in_batch, device=device)
2025-05-18 21:53:42,893 - root - INFO - Step: 1 | Loss: 11.87 | Tokens per second: 1111.79 | Training tokens per second (%): 12.27 | MFU (%): 5.79 | TFLOPs: 57.30 | Global batch size: 4 | Global tokens/sec: 4447.14 | Global MFU (%): 5.79 | Global TFLOPs: 229.21 | 
2025-05-18 21:53:46,404 - root - INFO - Step: 10 | Loss: 11.43 | Tokens per second: 5250.73 | Training tokens per second (%): 12.94 | MFU (%): 27.36 | TFLOPs: 270.63 | Global batch size: 4 | Global tokens/sec: 21002.92 | Global MFU (%): 27.36 | Global TFLOPs: 1082.52 | 
2025-05-18 21:53:50,293 - root - INFO - Step: 20 | Loss: 10.23 | Tokens per second: 5266.85 | Training tokens per second (%): 5.57 | MFU (%): 27.45 | TFLOPs: 271.46 | Global batch size: 4 | Global tokens/sec: 21067.38 | Global MFU (%): 27.45 | Global TFLOPs: 1085.84 | 
2025-05-18 21:53:54,199 - root - INFO - Step: 30 | Loss: 9.47 | Tokens per second: 5244.03 | Training tokens per second (%): 12.05 | MFU (%): 27.33 | TFLOPs: 270.28 | Global batch size: 4 | Global tokens/sec: 20976.13 | Global MFU (%): 27.33 | Global TFLOPs: 1081.14 | 
2025-05-18 21:53:58,089 - root - INFO - Step: 40 | Loss: 9.22 | Tokens per second: 5266.27 | Training tokens per second (%): 11.65 | MFU (%): 27.44 | TFLOPs: 271.43 | Global batch size: 4 | Global tokens/sec: 21065.06 | Global MFU (%): 27.44 | Global TFLOPs: 1085.72 | 
2025-05-18 21:54:01,978 - root - INFO - Step: 50 | Loss: 8.63 | Tokens per second: 5266.79 | Training tokens per second (%): 10.10 | MFU (%): 27.45 | TFLOPs: 271.46 | Global batch size: 4 | Global tokens/sec: 21067.17 | Global MFU (%): 27.45 | Global TFLOPs: 1085.83 | 
2025-05-18 21:54:05,869 - root - INFO - Step: 60 | Loss: 8.52 | Tokens per second: 5264.96 | Training tokens per second (%): 10.66 | MFU (%): 27.44 | TFLOPs: 271.36 | Global batch size: 4 | Global tokens/sec: 21059.83 | Global MFU (%): 27.44 | Global TFLOPs: 1085.45 | 
2025-05-18 21:54:09,772 - root - INFO - Step: 70 | Loss: 8.15 | Tokens per second: 5248.24 | Training tokens per second (%): 8.28 | MFU (%): 27.35 | TFLOPs: 270.50 | Global batch size: 4 | Global tokens/sec: 20992.97 | Global MFU (%): 27.35 | Global TFLOPs: 1082.00 | 
2025-05-18 21:54:13,663 - root - INFO - Step: 80 | Loss: 7.93 | Tokens per second: 5265.21 | Training tokens per second (%): 7.71 | MFU (%): 27.44 | TFLOPs: 271.38 | Global batch size: 4 | Global tokens/sec: 21060.85 | Global MFU (%): 27.44 | Global TFLOPs: 1085.50 | 
2025-05-18 21:54:17,557 - root - INFO - Step: 90 | Loss: 7.33 | Tokens per second: 5259.45 | Training tokens per second (%): 7.24 | MFU (%): 27.41 | TFLOPs: 271.08 | Global batch size: 4 | Global tokens/sec: 21037.82 | Global MFU (%): 27.41 | Global TFLOPs: 1084.31 | 
2025-05-18 21:54:21,454 - root - INFO - Step: 100 | Loss: 7.43 | Tokens per second: 5257.22 | Training tokens per second (%): 11.37 | MFU (%): 27.40 | TFLOPs: 270.96 | Global batch size: 4 | Global tokens/sec: 21028.86 | Global MFU (%): 27.40 | Global TFLOPs: 1083.85 | 
2025-05-18 21:54:25,361 - root - INFO - Step: 110 | Loss: 7.49 | Tokens per second: 5242.63 | Training tokens per second (%): 10.53 | MFU (%): 27.32 | TFLOPs: 270.21 | Global batch size: 4 | Global tokens/sec: 20970.52 | Global MFU (%): 27.32 | Global TFLOPs: 1080.85 | 
2025-05-18 21:54:29,266 - root - INFO - Step: 120 | Loss: 7.86 | Tokens per second: 5245.91 | Training tokens per second (%): 11.78 | MFU (%): 27.34 | TFLOPs: 270.38 | Global batch size: 4 | Global tokens/sec: 20983.62 | Global MFU (%): 27.34 | Global TFLOPs: 1081.52 | 
2025-05-18 21:54:33,172 - root - INFO - Step: 130 | Loss: 7.73 | Tokens per second: 5243.69 | Training tokens per second (%): 5.62 | MFU (%): 27.33 | TFLOPs: 270.27 | Global batch size: 4 | Global tokens/sec: 20974.77 | Global MFU (%): 27.33 | Global TFLOPs: 1081.07 | 
2025-05-18 21:54:37,078 - root - INFO - Step: 140 | Loss: 7.55 | Tokens per second: 5243.75 | Training tokens per second (%): 10.56 | MFU (%): 27.33 | TFLOPs: 270.27 | Global batch size: 4 | Global tokens/sec: 20975.00 | Global MFU (%): 27.33 | Global TFLOPs: 1081.08 | 
2025-05-18 21:54:40,988 - root - INFO - Step: 150 | Loss: 7.12 | Tokens per second: 5238.77 | Training tokens per second (%): 9.20 | MFU (%): 27.30 | TFLOPs: 270.01 | Global batch size: 4 | Global tokens/sec: 20955.07 | Global MFU (%): 27.30 | Global TFLOPs: 1080.05 | 
2025-05-18 21:54:44,889 - root - INFO - Step: 160 | Loss: 6.88 | Tokens per second: 5251.81 | Training tokens per second (%): 10.35 | MFU (%): 27.37 | TFLOPs: 270.68 | Global batch size: 4 | Global tokens/sec: 21007.25 | Global MFU (%): 27.37 | Global TFLOPs: 1082.74 | 
2025-05-18 21:54:48,793 - root - INFO - Step: 170 | Loss: 7.06 | Tokens per second: 5247.24 | Training tokens per second (%): 5.40 | MFU (%): 27.35 | TFLOPs: 270.45 | Global batch size: 4 | Global tokens/sec: 20988.96 | Global MFU (%): 27.35 | Global TFLOPs: 1081.80 | 
2025-05-18 21:54:52,704 - root - INFO - Step: 180 | Loss: 7.10 | Tokens per second: 5237.42 | Training tokens per second (%): 9.34 | MFU (%): 27.29 | TFLOPs: 269.94 | Global batch size: 4 | Global tokens/sec: 20949.66 | Global MFU (%): 27.29 | Global TFLOPs: 1079.77 | 
2025-05-18 21:54:56,612 - root - INFO - Step: 190 | Loss: 7.05 | Tokens per second: 5241.55 | Training tokens per second (%): 6.31 | MFU (%): 27.32 | TFLOPs: 270.16 | Global batch size: 4 | Global tokens/sec: 20966.21 | Global MFU (%): 27.32 | Global TFLOPs: 1080.62 | 
2025-05-18 21:55:00,541 - root - INFO - Step: 200 | Loss: 7.13 | Tokens per second: 5212.88 | Training tokens per second (%): 12.71 | MFU (%): 27.17 | TFLOPs: 268.68 | Global batch size: 4 | Global tokens/sec: 20851.52 | Global MFU (%): 27.17 | Global TFLOPs: 1074.71 | 
2025-05-18 21:55:04,449 - root - INFO - Step: 210 | Loss: 6.97 | Tokens per second: 5242.48 | Training tokens per second (%): 11.43 | MFU (%): 27.32 | TFLOPs: 270.20 | Global batch size: 4 | Global tokens/sec: 20969.90 | Global MFU (%): 27.32 | Global TFLOPs: 1080.81 | 
2025-05-18 21:55:08,362 - root - INFO - Step: 220 | Loss: 6.83 | Tokens per second: 5233.95 | Training tokens per second (%): 9.93 | MFU (%): 27.28 | TFLOPs: 269.76 | Global batch size: 4 | Global tokens/sec: 20935.81 | Global MFU (%): 27.28 | Global TFLOPs: 1079.06 | 
2025-05-18 21:55:12,272 - root - INFO - Step: 230 | Loss: 7.21 | Tokens per second: 5240.07 | Training tokens per second (%): 6.85 | MFU (%): 27.31 | TFLOPs: 270.08 | Global batch size: 4 | Global tokens/sec: 20960.27 | Global MFU (%): 27.31 | Global TFLOPs: 1080.32 | 
2025-05-18 21:55:16,192 - root - INFO - Step: 240 | Loss: 6.66 | Tokens per second: 5224.23 | Training tokens per second (%): 8.75 | MFU (%): 27.23 | TFLOPs: 269.26 | Global batch size: 4 | Global tokens/sec: 20896.94 | Global MFU (%): 27.23 | Global TFLOPs: 1077.05 | 
2025-05-18 21:55:20,102 - root - INFO - Step: 250 | Loss: 6.98 | Tokens per second: 5240.02 | Training tokens per second (%): 8.10 | MFU (%): 27.31 | TFLOPs: 270.08 | Global batch size: 4 | Global tokens/sec: 20960.08 | Global MFU (%): 27.31 | Global TFLOPs: 1080.31 | 
2025-05-18 21:55:24,014 - root - INFO - Step: 260 | Loss: 6.85 | Tokens per second: 5235.05 | Training tokens per second (%): 15.73 | MFU (%): 27.28 | TFLOPs: 269.82 | Global batch size: 4 | Global tokens/sec: 20940.19 | Global MFU (%): 27.28 | Global TFLOPs: 1079.28 | 
2025-05-18 21:55:27,920 - root - INFO - Step: 270 | Loss: 6.49 | Tokens per second: 5244.32 | Training tokens per second (%): 9.74 | MFU (%): 27.33 | TFLOPs: 270.30 | Global batch size: 4 | Global tokens/sec: 20977.26 | Global MFU (%): 27.33 | Global TFLOPs: 1081.19 | 
2025-05-18 21:55:31,843 - root - INFO - Step: 280 | Loss: 5.95 | Tokens per second: 5222.45 | Training tokens per second (%): 6.88 | MFU (%): 27.22 | TFLOPs: 269.17 | Global batch size: 4 | Global tokens/sec: 20889.79 | Global MFU (%): 27.22 | Global TFLOPs: 1076.68 | 
2025-05-18 21:55:35,759 - root - INFO - Step: 290 | Loss: 6.40 | Tokens per second: 5230.68 | Training tokens per second (%): 13.31 | MFU (%): 27.26 | TFLOPs: 269.60 | Global batch size: 4 | Global tokens/sec: 20922.71 | Global MFU (%): 27.26 | Global TFLOPs: 1078.38 | 
2025-05-18 21:55:39,673 - root - INFO - Step: 300 | Loss: 6.30 | Tokens per second: 5233.40 | Training tokens per second (%): 12.94 | MFU (%): 27.27 | TFLOPs: 269.74 | Global batch size: 4 | Global tokens/sec: 20933.62 | Global MFU (%): 27.27 | Global TFLOPs: 1078.94 | 
2025-05-18 21:55:43,587 - root - INFO - Step: 310 | Loss: 6.50 | Tokens per second: 5233.45 | Training tokens per second (%): 10.81 | MFU (%): 27.27 | TFLOPs: 269.74 | Global batch size: 4 | Global tokens/sec: 20933.80 | Global MFU (%): 27.27 | Global TFLOPs: 1078.95 | 
2025-05-18 21:55:47,504 - root - INFO - Step: 320 | Loss: 6.25 | Tokens per second: 5229.11 | Training tokens per second (%): 9.90 | MFU (%): 27.25 | TFLOPs: 269.51 | Global batch size: 4 | Global tokens/sec: 20916.45 | Global MFU (%): 27.25 | Global TFLOPs: 1078.06 | 
2025-05-18 21:55:51,421 - root - INFO - Step: 330 | Loss: 6.31 | Tokens per second: 5230.36 | Training tokens per second (%): 7.55 | MFU (%): 27.26 | TFLOPs: 269.58 | Global batch size: 4 | Global tokens/sec: 20921.46 | Global MFU (%): 27.26 | Global TFLOPs: 1078.32 | 
2025-05-18 21:55:55,337 - root - INFO - Step: 340 | Loss: 6.41 | Tokens per second: 5230.34 | Training tokens per second (%): 8.99 | MFU (%): 27.26 | TFLOPs: 269.58 | Global batch size: 4 | Global tokens/sec: 20921.35 | Global MFU (%): 27.26 | Global TFLOPs: 1078.31 | 
2025-05-18 21:55:59,250 - root - INFO - Step: 350 | Loss: 6.24 | Tokens per second: 5234.96 | Training tokens per second (%): 9.02 | MFU (%): 27.28 | TFLOPs: 269.82 | Global batch size: 4 | Global tokens/sec: 20939.84 | Global MFU (%): 27.28 | Global TFLOPs: 1079.26 | 
2025-05-18 21:56:03,159 - root - INFO - Step: 360 | Loss: 6.17 | Tokens per second: 5240.26 | Training tokens per second (%): 9.67 | MFU (%): 27.31 | TFLOPs: 270.09 | Global batch size: 4 | Global tokens/sec: 20961.04 | Global MFU (%): 27.31 | Global TFLOPs: 1080.36 | 
2025-05-18 21:56:07,077 - root - INFO - Step: 370 | Loss: 6.19 | Tokens per second: 5227.95 | Training tokens per second (%): 8.57 | MFU (%): 27.25 | TFLOPs: 269.45 | Global batch size: 4 | Global tokens/sec: 20911.80 | Global MFU (%): 27.25 | Global TFLOPs: 1077.82 | 
2025-05-18 21:56:10,993 - root - INFO - Step: 380 | Loss: 6.68 | Tokens per second: 5231.80 | Training tokens per second (%): 9.64 | MFU (%): 27.27 | TFLOPs: 269.65 | Global batch size: 4 | Global tokens/sec: 20927.18 | Global MFU (%): 27.27 | Global TFLOPs: 1078.61 | 
2025-05-18 21:56:14,906 - root - INFO - Step: 390 | Loss: 6.50 | Tokens per second: 5233.64 | Training tokens per second (%): 7.53 | MFU (%): 27.27 | TFLOPs: 269.75 | Global batch size: 4 | Global tokens/sec: 20934.54 | Global MFU (%): 27.27 | Global TFLOPs: 1078.99 | 
2025-05-18 21:56:18,818 - root - INFO - Step: 400 | Loss: 6.00 | Tokens per second: 5236.78 | Training tokens per second (%): 8.28 | MFU (%): 27.29 | TFLOPs: 269.91 | Global batch size: 4 | Global tokens/sec: 20947.11 | Global MFU (%): 27.29 | Global TFLOPs: 1079.64 | 
2025-05-18 21:56:22,738 - root - INFO - Step: 410 | Loss: 6.29 | Tokens per second: 5224.82 | Training tokens per second (%): 10.91 | MFU (%): 27.23 | TFLOPs: 269.29 | Global batch size: 4 | Global tokens/sec: 20899.27 | Global MFU (%): 27.23 | Global TFLOPs: 1077.17 | 
2025-05-18 21:56:26,651 - root - INFO - Step: 420 | Loss: 6.58 | Tokens per second: 5235.13 | Training tokens per second (%): 8.83 | MFU (%): 27.28 | TFLOPs: 269.82 | Global batch size: 4 | Global tokens/sec: 20940.51 | Global MFU (%): 27.28 | Global TFLOPs: 1079.30 | 
2025-05-18 21:56:30,571 - root - INFO - Step: 430 | Loss: 6.34 | Tokens per second: 5226.56 | Training tokens per second (%): 6.98 | MFU (%): 27.24 | TFLOPs: 269.38 | Global batch size: 4 | Global tokens/sec: 20906.26 | Global MFU (%): 27.24 | Global TFLOPs: 1077.53 | 
2025-05-18 21:56:34,488 - root - INFO - Step: 440 | Loss: 6.13 | Tokens per second: 5228.93 | Training tokens per second (%): 8.44 | MFU (%): 27.25 | TFLOPs: 269.51 | Global batch size: 4 | Global tokens/sec: 20915.71 | Global MFU (%): 27.25 | Global TFLOPs: 1078.02 | 
2025-05-18 21:56:38,397 - root - INFO - Step: 450 | Loss: 6.23 | Tokens per second: 5240.58 | Training tokens per second (%): 9.96 | MFU (%): 27.31 | TFLOPs: 270.11 | Global batch size: 4 | Global tokens/sec: 20962.30 | Global MFU (%): 27.31 | Global TFLOPs: 1080.42 | 
2025-05-18 21:56:42,311 - root - INFO - Step: 460 | Loss: 6.24 | Tokens per second: 5232.66 | Training tokens per second (%): 7.38 | MFU (%): 27.27 | TFLOPs: 269.70 | Global batch size: 4 | Global tokens/sec: 20930.63 | Global MFU (%): 27.27 | Global TFLOPs: 1078.79 | 
2025-05-18 21:56:46,224 - root - INFO - Step: 470 | Loss: 6.42 | Tokens per second: 5235.58 | Training tokens per second (%): 8.35 | MFU (%): 27.28 | TFLOPs: 269.85 | Global batch size: 4 | Global tokens/sec: 20942.32 | Global MFU (%): 27.28 | Global TFLOPs: 1079.39 | 
2025-05-18 21:56:50,143 - root - INFO - Step: 480 | Loss: 6.01 | Tokens per second: 5226.02 | Training tokens per second (%): 9.75 | MFU (%): 27.24 | TFLOPs: 269.36 | Global batch size: 4 | Global tokens/sec: 20904.09 | Global MFU (%): 27.24 | Global TFLOPs: 1077.42 | 
2025-05-18 21:56:54,060 - root - INFO - Step: 490 | Loss: 6.45 | Tokens per second: 5229.53 | Training tokens per second (%): 10.01 | MFU (%): 27.25 | TFLOPs: 269.54 | Global batch size: 4 | Global tokens/sec: 20918.14 | Global MFU (%): 27.25 | Global TFLOPs: 1078.15 | 
2025-05-18 21:56:57,981 - root - INFO - Step: 500 | Loss: 6.21 | Tokens per second: 5224.49 | Training tokens per second (%): 7.06 | MFU (%): 27.23 | TFLOPs: 269.28 | Global batch size: 4 | Global tokens/sec: 20897.98 | Global MFU (%): 27.23 | Global TFLOPs: 1077.11 | 
2025-05-18 21:57:01,892 - root - INFO - Step: 510 | Loss: 5.48 | Tokens per second: 5238.33 | Training tokens per second (%): 9.59 | MFU (%): 27.30 | TFLOPs: 269.99 | Global batch size: 4 | Global tokens/sec: 20953.31 | Global MFU (%): 27.30 | Global TFLOPs: 1079.96 | 
2025-05-18 21:57:05,798 - root - INFO - Step: 520 | Loss: 4.95 | Tokens per second: 5243.70 | Training tokens per second (%): 5.14 | MFU (%): 27.33 | TFLOPs: 270.27 | Global batch size: 4 | Global tokens/sec: 20974.79 | Global MFU (%): 27.33 | Global TFLOPs: 1081.07 | 
2025-05-18 21:57:09,723 - root - INFO - Step: 530 | Loss: 5.56 | Tokens per second: 5218.78 | Training tokens per second (%): 10.80 | MFU (%): 27.20 | TFLOPs: 268.98 | Global batch size: 4 | Global tokens/sec: 20875.13 | Global MFU (%): 27.20 | Global TFLOPs: 1075.93 | 
2025-05-18 21:57:13,637 - root - INFO - Step: 540 | Loss: 4.39 | Tokens per second: 5233.67 | Training tokens per second (%): 7.95 | MFU (%): 27.28 | TFLOPs: 269.75 | Global batch size: 4 | Global tokens/sec: 20934.70 | Global MFU (%): 27.28 | Global TFLOPs: 1079.00 | 
2025-05-18 21:57:17,555 - root - INFO - Step: 550 | Loss: 5.13 | Tokens per second: 5228.49 | Training tokens per second (%): 7.45 | MFU (%): 27.25 | TFLOPs: 269.48 | Global batch size: 4 | Global tokens/sec: 20913.97 | Global MFU (%): 27.25 | Global TFLOPs: 1077.93 | 
2025-05-18 21:57:21,471 - root - INFO - Step: 560 | Loss: 4.69 | Tokens per second: 5230.03 | Training tokens per second (%): 11.21 | MFU (%): 27.26 | TFLOPs: 269.56 | Global batch size: 4 | Global tokens/sec: 20920.13 | Global MFU (%): 27.26 | Global TFLOPs: 1078.25 | 
2025-05-18 21:57:25,391 - root - INFO - Step: 570 | Loss: 4.98 | Tokens per second: 5225.53 | Training tokens per second (%): 7.75 | MFU (%): 27.23 | TFLOPs: 269.33 | Global batch size: 4 | Global tokens/sec: 20902.13 | Global MFU (%): 27.23 | Global TFLOPs: 1077.32 | 
2025-05-18 21:57:29,304 - root - INFO - Step: 580 | Loss: 4.98 | Tokens per second: 5235.10 | Training tokens per second (%): 10.24 | MFU (%): 27.28 | TFLOPs: 269.82 | Global batch size: 4 | Global tokens/sec: 20940.38 | Global MFU (%): 27.28 | Global TFLOPs: 1079.29 | 
2025-05-18 21:57:33,227 - root - INFO - Step: 590 | Loss: 5.46 | Tokens per second: 5221.91 | Training tokens per second (%): 10.86 | MFU (%): 27.21 | TFLOPs: 269.14 | Global batch size: 4 | Global tokens/sec: 20887.63 | Global MFU (%): 27.21 | Global TFLOPs: 1076.57 | 
2025-05-18 21:57:37,142 - root - INFO - Step: 600 | Loss: 5.88 | Tokens per second: 5231.51 | Training tokens per second (%): 9.95 | MFU (%): 27.26 | TFLOPs: 269.64 | Global batch size: 4 | Global tokens/sec: 20926.06 | Global MFU (%): 27.26 | Global TFLOPs: 1078.55 | 
2025-05-18 21:57:41,055 - root - INFO - Step: 610 | Loss: 5.07 | Tokens per second: 5236.06 | Training tokens per second (%): 10.41 | MFU (%): 27.29 | TFLOPs: 269.87 | Global batch size: 4 | Global tokens/sec: 20944.23 | Global MFU (%): 27.29 | Global TFLOPs: 1079.49 | 
2025-05-18 21:57:44,969 - root - INFO - Step: 620 | Loss: 5.67 | Tokens per second: 5232.33 | Training tokens per second (%): 8.69 | MFU (%): 27.27 | TFLOPs: 269.68 | Global batch size: 4 | Global tokens/sec: 20929.30 | Global MFU (%): 27.27 | Global TFLOPs: 1078.72 | 
2025-05-18 21:57:48,886 - root - INFO - Step: 630 | Loss: 4.94 | Tokens per second: 5230.56 | Training tokens per second (%): 7.56 | MFU (%): 27.26 | TFLOPs: 269.59 | Global batch size: 4 | Global tokens/sec: 20922.25 | Global MFU (%): 27.26 | Global TFLOPs: 1078.36 | 
2025-05-18 21:57:52,802 - root - INFO - Step: 640 | Loss: 5.67 | Tokens per second: 5230.22 | Training tokens per second (%): 11.82 | MFU (%): 27.26 | TFLOPs: 269.57 | Global batch size: 4 | Global tokens/sec: 20920.88 | Global MFU (%): 27.26 | Global TFLOPs: 1078.29 | 
2025-05-18 21:57:56,725 - root - INFO - Step: 650 | Loss: 4.78 | Tokens per second: 5221.12 | Training tokens per second (%): 9.18 | MFU (%): 27.21 | TFLOPs: 269.10 | Global batch size: 4 | Global tokens/sec: 20884.49 | Global MFU (%): 27.21 | Global TFLOPs: 1076.41 | 
2025-05-18 21:58:00,640 - root - INFO - Step: 660 | Loss: 5.93 | Tokens per second: 5232.21 | Training tokens per second (%): 12.84 | MFU (%): 27.27 | TFLOPs: 269.67 | Global batch size: 4 | Global tokens/sec: 20928.86 | Global MFU (%): 27.27 | Global TFLOPs: 1078.70 | 
2025-05-18 21:58:04,559 - root - INFO - Step: 670 | Loss: 4.88 | Tokens per second: 5227.54 | Training tokens per second (%): 9.33 | MFU (%): 27.24 | TFLOPs: 269.43 | Global batch size: 4 | Global tokens/sec: 20910.16 | Global MFU (%): 27.24 | Global TFLOPs: 1077.73 | 
2025-05-18 21:58:08,479 - root - INFO - Step: 680 | Loss: 5.20 | Tokens per second: 5225.87 | Training tokens per second (%): 14.28 | MFU (%): 27.23 | TFLOPs: 269.35 | Global batch size: 4 | Global tokens/sec: 20903.47 | Global MFU (%): 27.23 | Global TFLOPs: 1077.39 | 
2025-05-18 21:58:12,397 - root - INFO - Step: 690 | Loss: 5.57 | Tokens per second: 5228.19 | Training tokens per second (%): 6.18 | MFU (%): 27.25 | TFLOPs: 269.47 | Global batch size: 4 | Global tokens/sec: 20912.77 | Global MFU (%): 27.25 | Global TFLOPs: 1077.87 | 
2025-05-18 21:58:16,314 - root - INFO - Step: 700 | Loss: 4.47 | Tokens per second: 5228.83 | Training tokens per second (%): 8.72 | MFU (%): 27.25 | TFLOPs: 269.50 | Global batch size: 4 | Global tokens/sec: 20915.34 | Global MFU (%): 27.25 | Global TFLOPs: 1078.00 | 
2025-05-18 21:58:20,229 - root - INFO - Step: 710 | Loss: 4.96 | Tokens per second: 5232.35 | Training tokens per second (%): 10.40 | MFU (%): 27.27 | TFLOPs: 269.68 | Global batch size: 4 | Global tokens/sec: 20929.39 | Global MFU (%): 27.27 | Global TFLOPs: 1078.73 | 
2025-05-18 21:58:24,143 - root - INFO - Step: 720 | Loss: 5.67 | Tokens per second: 5233.04 | Training tokens per second (%): 6.30 | MFU (%): 27.27 | TFLOPs: 269.72 | Global batch size: 4 | Global tokens/sec: 20932.15 | Global MFU (%): 27.27 | Global TFLOPs: 1078.87 | 
2025-05-18 21:58:28,062 - root - INFO - Step: 730 | Loss: 5.39 | Tokens per second: 5227.84 | Training tokens per second (%): 5.27 | MFU (%): 27.24 | TFLOPs: 269.45 | Global batch size: 4 | Global tokens/sec: 20911.35 | Global MFU (%): 27.24 | Global TFLOPs: 1077.80 | 
2025-05-18 21:58:31,970 - root - INFO - Step: 740 | Loss: 5.54 | Tokens per second: 5241.62 | Training tokens per second (%): 7.18 | MFU (%): 27.32 | TFLOPs: 270.16 | Global batch size: 4 | Global tokens/sec: 20966.46 | Global MFU (%): 27.32 | Global TFLOPs: 1080.64 | 
2025-05-18 21:58:35,886 - root - INFO - Step: 750 | Loss: 5.66 | Tokens per second: 5229.98 | Training tokens per second (%): 11.15 | MFU (%): 27.26 | TFLOPs: 269.56 | Global batch size: 4 | Global tokens/sec: 20919.91 | Global MFU (%): 27.26 | Global TFLOPs: 1078.24 | 
2025-05-18 21:58:39,808 - root - INFO - Step: 760 | Loss: 4.41 | Tokens per second: 5222.78 | Training tokens per second (%): 9.48 | MFU (%): 27.22 | TFLOPs: 269.19 | Global batch size: 4 | Global tokens/sec: 20891.12 | Global MFU (%): 27.22 | Global TFLOPs: 1076.75 | 
2025-05-18 21:58:43,725 - root - INFO - Step: 770 | Loss: 4.27 | Tokens per second: 5229.50 | Training tokens per second (%): 13.65 | MFU (%): 27.25 | TFLOPs: 269.53 | Global batch size: 4 | Global tokens/sec: 20917.99 | Global MFU (%): 27.25 | Global TFLOPs: 1078.14 | 
2025-05-18 21:58:47,640 - root - INFO - Step: 780 | Loss: 4.32 | Tokens per second: 5232.19 | Training tokens per second (%): 8.25 | MFU (%): 27.27 | TFLOPs: 269.67 | Global batch size: 4 | Global tokens/sec: 20928.78 | Global MFU (%): 27.27 | Global TFLOPs: 1078.69 | 
2025-05-18 21:58:51,550 - root - INFO - Step: 790 | Loss: 4.19 | Tokens per second: 5239.27 | Training tokens per second (%): 9.61 | MFU (%): 27.30 | TFLOPs: 270.04 | Global batch size: 4 | Global tokens/sec: 20957.10 | Global MFU (%): 27.30 | Global TFLOPs: 1080.15 | 
2025-05-18 21:58:55,479 - root - INFO - Step: 800 | Loss: 4.31 | Tokens per second: 5213.70 | Training tokens per second (%): 7.76 | MFU (%): 27.17 | TFLOPs: 268.72 | Global batch size: 4 | Global tokens/sec: 20854.80 | Global MFU (%): 27.17 | Global TFLOPs: 1074.88 | 
2025-05-18 21:58:59,388 - root - INFO - Step: 810 | Loss: 3.63 | Tokens per second: 5239.57 | Training tokens per second (%): 8.59 | MFU (%): 27.31 | TFLOPs: 270.05 | Global batch size: 4 | Global tokens/sec: 20958.27 | Global MFU (%): 27.31 | Global TFLOPs: 1080.21 | 
2025-05-18 21:59:03,301 - root - INFO - Step: 820 | Loss: 4.86 | Tokens per second: 5235.67 | Training tokens per second (%): 9.22 | MFU (%): 27.29 | TFLOPs: 269.85 | Global batch size: 4 | Global tokens/sec: 20942.68 | Global MFU (%): 27.29 | Global TFLOPs: 1079.41 | 
2025-05-18 21:59:07,219 - root - INFO - Step: 830 | Loss: 4.55 | Tokens per second: 5228.20 | Training tokens per second (%): 9.90 | MFU (%): 27.25 | TFLOPs: 269.47 | Global batch size: 4 | Global tokens/sec: 20912.80 | Global MFU (%): 27.25 | Global TFLOPs: 1077.87 | 
2025-05-18 21:59:11,136 - root - INFO - Step: 840 | Loss: 4.39 | Tokens per second: 5229.43 | Training tokens per second (%): 13.03 | MFU (%): 27.25 | TFLOPs: 269.53 | Global batch size: 4 | Global tokens/sec: 20917.71 | Global MFU (%): 27.25 | Global TFLOPs: 1078.12 | 
2025-05-18 21:59:15,052 - root - INFO - Step: 850 | Loss: 4.15 | Tokens per second: 5230.64 | Training tokens per second (%): 10.98 | MFU (%): 27.26 | TFLOPs: 269.59 | Global batch size: 4 | Global tokens/sec: 20922.57 | Global MFU (%): 27.26 | Global TFLOPs: 1078.37 | 
2025-05-18 21:59:18,971 - root - INFO - Step: 860 | Loss: 3.65 | Tokens per second: 5227.38 | Training tokens per second (%): 11.35 | MFU (%): 27.24 | TFLOPs: 269.43 | Global batch size: 4 | Global tokens/sec: 20909.51 | Global MFU (%): 27.24 | Global TFLOPs: 1077.70 | 
2025-05-18 21:59:22,890 - root - INFO - Step: 870 | Loss: 4.32 | Tokens per second: 5226.89 | Training tokens per second (%): 7.68 | MFU (%): 27.24 | TFLOPs: 269.40 | Global batch size: 4 | Global tokens/sec: 20907.58 | Global MFU (%): 27.24 | Global TFLOPs: 1077.60 | 
2025-05-18 21:59:26,809 - root - INFO - Step: 880 | Loss: 3.54 | Tokens per second: 5226.11 | Training tokens per second (%): 11.28 | MFU (%): 27.24 | TFLOPs: 269.36 | Global batch size: 4 | Global tokens/sec: 20904.45 | Global MFU (%): 27.24 | Global TFLOPs: 1077.44 | 
2025-05-18 21:59:30,728 - root - INFO - Step: 890 | Loss: 4.17 | Tokens per second: 5227.17 | Training tokens per second (%): 6.15 | MFU (%): 27.24 | TFLOPs: 269.41 | Global batch size: 4 | Global tokens/sec: 20908.68 | Global MFU (%): 27.24 | Global TFLOPs: 1077.66 | 
2025-05-18 21:59:34,647 - root - INFO - Step: 900 | Loss: 3.99 | Tokens per second: 5226.75 | Training tokens per second (%): 11.79 | MFU (%): 27.24 | TFLOPs: 269.39 | Global batch size: 4 | Global tokens/sec: 20907.01 | Global MFU (%): 27.24 | Global TFLOPs: 1077.57 | 
2025-05-18 21:59:38,557 - root - INFO - Step: 910 | Loss: 3.42 | Tokens per second: 5239.41 | Training tokens per second (%): 9.43 | MFU (%): 27.30 | TFLOPs: 270.05 | Global batch size: 4 | Global tokens/sec: 20957.63 | Global MFU (%): 27.30 | Global TFLOPs: 1080.18 | 
2025-05-18 21:59:42,476 - root - INFO - Step: 920 | Loss: 4.70 | Tokens per second: 5226.69 | Training tokens per second (%): 11.09 | MFU (%): 27.24 | TFLOPs: 269.39 | Global batch size: 4 | Global tokens/sec: 20906.76 | Global MFU (%): 27.24 | Global TFLOPs: 1077.56 | 
2025-05-18 21:59:46,392 - root - INFO - Step: 930 | Loss: 4.42 | Tokens per second: 5230.34 | Training tokens per second (%): 11.92 | MFU (%): 27.26 | TFLOPs: 269.58 | Global batch size: 4 | Global tokens/sec: 20921.35 | Global MFU (%): 27.26 | Global TFLOPs: 1078.31 | 
2025-05-18 21:59:50,311 - root - INFO - Step: 940 | Loss: 4.95 | Tokens per second: 5227.30 | Training tokens per second (%): 12.14 | MFU (%): 27.24 | TFLOPs: 269.42 | Global batch size: 4 | Global tokens/sec: 20909.19 | Global MFU (%): 27.24 | Global TFLOPs: 1077.69 | 
2025-05-18 21:59:54,233 - root - INFO - Step: 950 | Loss: 4.36 | Tokens per second: 5221.96 | Training tokens per second (%): 10.73 | MFU (%): 27.21 | TFLOPs: 269.15 | Global batch size: 4 | Global tokens/sec: 20887.86 | Global MFU (%): 27.21 | Global TFLOPs: 1076.59 | 
2025-05-18 21:59:58,157 - root - INFO - Step: 960 | Loss: 4.27 | Tokens per second: 5220.44 | Training tokens per second (%): 8.68 | MFU (%): 27.21 | TFLOPs: 269.07 | Global batch size: 4 | Global tokens/sec: 20881.78 | Global MFU (%): 27.21 | Global TFLOPs: 1076.27 | 
2025-05-18 22:00:02,078 - root - INFO - Step: 970 | Loss: 3.84 | Tokens per second: 5224.95 | Training tokens per second (%): 7.97 | MFU (%): 27.23 | TFLOPs: 269.30 | Global batch size: 4 | Global tokens/sec: 20899.79 | Global MFU (%): 27.23 | Global TFLOPs: 1077.20 | 
2025-05-18 22:00:05,992 - root - INFO - Step: 980 | Loss: 4.09 | Tokens per second: 5233.32 | Training tokens per second (%): 9.83 | MFU (%): 27.27 | TFLOPs: 269.73 | Global batch size: 4 | Global tokens/sec: 20933.30 | Global MFU (%): 27.27 | Global TFLOPs: 1078.93 | 
2025-05-18 22:00:09,906 - root - INFO - Step: 990 | Loss: 4.79 | Tokens per second: 5233.05 | Training tokens per second (%): 6.68 | MFU (%): 27.27 | TFLOPs: 269.72 | Global batch size: 4 | Global tokens/sec: 20932.18 | Global MFU (%): 27.27 | Global TFLOPs: 1078.87 | 
2025-05-18 22:00:13,821 - root - INFO - Step: 1000 | Loss: 3.62 | Tokens per second: 5231.74 | Training tokens per second (%): 11.28 | MFU (%): 27.26 | TFLOPs: 269.65 | Global batch size: 4 | Global tokens/sec: 20926.97 | Global MFU (%): 27.26 | Global TFLOPs: 1078.60 | 
2025-05-18 22:00:13,822 - root - INFO - Training completed
[sbatch-master] task finished

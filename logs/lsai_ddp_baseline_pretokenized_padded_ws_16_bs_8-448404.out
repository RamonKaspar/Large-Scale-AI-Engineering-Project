[sbatch-master] running on nid006550
[sbatch-master] SLURM_NODELIST: nid[006550-006551,006553-006554]
[sbatch-master] SLURM_NNODES: 4
[sbatch-master] SLURM_NODEID: 0
[Master] Master node: nid006550
[Master] World size: 16
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
[srun] rank=0 host=nid006550 noderank=0 localrank=0
[srun] rank=1 host=nid006551 noderank=1 localrank=0
[srun] rank=2 host=nid006553 noderank=2 localrank=0
[srun] rank=3 host=nid006554 noderank=3 localrank=0
W0519 09:20:46.293000 136218 torch/distributed/run.py:792] 
W0519 09:20:46.293000 136218 torch/distributed/run.py:792] *****************************************
W0519 09:20:46.293000 136218 torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0519 09:20:46.293000 136218 torch/distributed/run.py:792] *****************************************
W0519 09:20:48.138000 115162 torch/distributed/run.py:792] 
W0519 09:20:48.138000 115162 torch/distributed/run.py:792] *****************************************
W0519 09:20:48.138000 115162 torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0519 09:20:48.138000 115162 torch/distributed/run.py:792] *****************************************
W0519 09:20:48.215000 179174 torch/distributed/run.py:792] 
W0519 09:20:48.215000 179174 torch/distributed/run.py:792] *****************************************
W0519 09:20:48.215000 179174 torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0519 09:20:48.215000 179174 torch/distributed/run.py:792] *****************************************
W0519 09:20:48.241000 127065 torch/distributed/run.py:792] 
W0519 09:20:48.241000 127065 torch/distributed/run.py:792] *****************************************
W0519 09:20:48.241000 127065 torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0519 09:20:48.241000 127065 torch/distributed/run.py:792] *****************************************
2025-05-19 09:21:00,988 - root - INFO - [Distributed Init] Rank 8 initialized on node 2 on GPU 0.
2025-05-19 09:21:00,992 - root - INFO - [Distributed Init] Rank 4 initialized on node 1 on GPU 0.
2025-05-19 09:21:01,191 - root - INFO - [Distributed Init] Rank 12 initialized on node 3 on GPU 0.
2025-05-19 09:21:01,238 - root - INFO - [Distributed Init] Rank 0 initialized on node 0 on GPU 0.
[rank4]:[W519 09:21:01.890560944 ProcessGroupNCCL.cpp:4454] [PG ID 0 PG GUID 0 Rank 4]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank8]:[W519 09:21:01.211192346 ProcessGroupNCCL.cpp:4454] [PG ID 0 PG GUID 0 Rank 8]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
2025-05-19 09:21:01,489 - root - INFO - [Distributed Init] Rank 7 initialized on node 1 on GPU 3.
[rank7]:[W519 09:21:01.982289657 ProcessGroupNCCL.cpp:4454] [PG ID 0 PG GUID 0 Rank 7]  using GPU 3 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
2025-05-19 09:21:01,491 - root - INFO - [Distributed Init] Rank 9 initialized on node 2 on GPU 1.
2025-05-19 09:21:01,491 - root - INFO - [Distributed Init] Rank 11 initialized on node 2 on GPU 3.
[rank11]:[W519 09:21:01.302818412 ProcessGroupNCCL.cpp:4454] [PG ID 0 PG GUID 0 Rank 11]  using GPU 3 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank9]:[W519 09:21:01.302818636 ProcessGroupNCCL.cpp:4454] [PG ID 0 PG GUID 0 Rank 9]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
2025-05-19 09:21:01,501 - root - INFO - [Distributed Init] Rank 10 initialized on node 2 on GPU 2.
[rank10]:[W519 09:21:01.312780160 ProcessGroupNCCL.cpp:4454] [PG ID 0 PG GUID 0 Rank 10]  using GPU 2 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
2025-05-19 09:21:01,559 - root - INFO - [Distributed Init] Rank 5 initialized on node 1 on GPU 1.
[rank5]:[W519 09:21:01.052551569 ProcessGroupNCCL.cpp:4454] [PG ID 0 PG GUID 0 Rank 5]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
2025-05-19 09:21:01,569 - root - INFO - [Distributed Init] Rank 6 initialized on node 1 on GPU 2.
[rank6]:[W519 09:21:01.062182492 ProcessGroupNCCL.cpp:4454] [PG ID 0 PG GUID 0 Rank 6]  using GPU 2 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank12]:[W519 09:21:01.338392918 ProcessGroupNCCL.cpp:4454] [PG ID 0 PG GUID 0 Rank 12]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
2025-05-19 09:21:01,697 - root - INFO - [Distributed Init] Rank 13 initialized on node 3 on GPU 1.
[rank13]:[W519 09:21:01.432413745 ProcessGroupNCCL.cpp:4454] [PG ID 0 PG GUID 0 Rank 13]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
2025-05-19 09:21:01,708 - root - INFO - [Distributed Init] Rank 15 initialized on node 3 on GPU 3.
2025-05-19 09:21:01,708 - root - INFO - [Distributed Init] Rank 14 initialized on node 3 on GPU 2.
[rank14]:[W519 09:21:01.442677906 ProcessGroupNCCL.cpp:4454] [PG ID 0 PG GUID 0 Rank 14]  using GPU 2 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank15]:[W519 09:21:01.442678290 ProcessGroupNCCL.cpp:4454] [PG ID 0 PG GUID 0 Rank 15]  using GPU 3 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank0]:[W519 09:21:01.640597330 ProcessGroupNCCL.cpp:4454] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
2025-05-19 09:21:01,832 - root - INFO - [Distributed Init] Rank 1 initialized on node 0 on GPU 1.
[rank1]:[W519 09:21:01.752068863 ProcessGroupNCCL.cpp:4454] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
2025-05-19 09:21:01,842 - root - INFO - [Distributed Init] Rank 3 initialized on node 0 on GPU 3.
[rank3]:[W519 09:21:01.761870057 ProcessGroupNCCL.cpp:4454] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
2025-05-19 09:21:01,863 - root - INFO - [Distributed Init] Rank 2 initialized on node 0 on GPU 2.
[rank2]:[W519 09:21:01.783325760 ProcessGroupNCCL.cpp:4454] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
2025-05-19 09:21:06,865 - root - INFO - [Rank 0] All ranks ready!
2025-05-19 09:21:06,866 - root - INFO - Distributed training enabled: 16 processes
2025-05-19 09:21:06,866 - root - INFO - Master process: 0 on cuda:0
2025-05-19 09:21:06,866 - root - INFO - Experiment args: Namespace(dataset='/capstor/scratch/cscs/kasparr/project/train_data_tokenized_padded_snappy.parquet', dataset_type='padded', pretokenized=True, tokenizer_name_or_path='unsloth/Mistral-Nemo-Base-2407-bnb-4bit', sequence_length=2048, batch_size=8, fused_optimizer=False, learning_rate=5e-05, lr_warmup_steps=100, training_steps=1000, logging_frequency=10, profile=False, profile_step_start=10, profile_step_end=10, grad_max_norm=1, model_dtype='bf16', compile=False, distributed=True, backend='nccl', find_unused_parameters=False)
2025-05-19 09:21:06,866 - root - INFO - Setting up Tokenizer...
2025-05-19 09:21:07,421 - root - INFO - Setting up DataLoaders...
2025-05-19 09:21:07,421 - root - INFO - Using pretokenized data: /capstor/scratch/cscs/kasparr/project/train_data_tokenized_padded_snappy.parquet
Loaded pretokenized dataset with 785906 samples
Loaded pretokenized dataset with 785906 samples
2025-05-19 09:21:38,091 - root - INFO - Setting up Model...
Loaded pretokenized dataset with 785906 samples
Loaded pretokenized dataset with 785906 samples
Loaded pretokenized dataset with 785906 samples
Loaded pretokenized dataset with 785906 samples
Loaded pretokenized dataset with 785906 samples
Loaded pretokenized dataset with 785906 samples
Loaded pretokenized dataset with 785906 samples
Loaded pretokenized dataset with 785906 samples
Loaded pretokenized dataset with 785906 samples
Loaded pretokenized dataset with 785906 samples
Loaded pretokenized dataset with 785906 samples
Loaded pretokenized dataset with 785906 samples
Loaded pretokenized dataset with 785906 samples
Loaded pretokenized dataset with 785906 samples
2025-05-19 09:21:48,725 - root - INFO - Model wrapped with DistributedDataParallel
2025-05-19 09:21:48,726 - root - INFO - Global batch size: 128 (local: 8 Ã— 16 processes)
2025-05-19 09:21:48,726 - root - INFO - Starting training!
/iopsstor/scratch/cscs/kasparr/project/src/train.py:236: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  num_items_tensor = torch.tensor(num_items_in_batch, device=device)
/iopsstor/scratch/cscs/kasparr/project/src/train.py:236: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  num_items_tensor = torch.tensor(num_items_in_batch, device=device)
/iopsstor/scratch/cscs/kasparr/project/src/train.py:236: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  num_items_tensor = torch.tensor(num_items_in_batch, device=device)
/iopsstor/scratch/cscs/kasparr/project/src/train.py:236: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  num_items_tensor = torch.tensor(num_items_in_batch, device=device)
/iopsstor/scratch/cscs/kasparr/project/src/train.py:236: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  num_items_tensor = torch.tensor(num_items_in_batch, device=device)
/iopsstor/scratch/cscs/kasparr/project/src/train.py:236: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  num_items_tensor = torch.tensor(num_items_in_batch, device=device)
/iopsstor/scratch/cscs/kasparr/project/src/train.py:236: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  num_items_tensor = torch.tensor(num_items_in_batch, device=device)
/iopsstor/scratch/cscs/kasparr/project/src/train.py:236: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  num_items_tensor = torch.tensor(num_items_in_batch, device=device)
/iopsstor/scratch/cscs/kasparr/project/src/train.py:236: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  num_items_tensor = torch.tensor(num_items_in_batch, device=device)
/iopsstor/scratch/cscs/kasparr/project/src/train.py:236: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  num_items_tensor = torch.tensor(num_items_in_batch, device=device)
/iopsstor/scratch/cscs/kasparr/project/src/train.py:236: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  num_items_tensor = torch.tensor(num_items_in_batch, device=device)
/iopsstor/scratch/cscs/kasparr/project/src/train.py:236: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  num_items_tensor = torch.tensor(num_items_in_batch, device=device)
/iopsstor/scratch/cscs/kasparr/project/src/train.py:236: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  num_items_tensor = torch.tensor(num_items_in_batch, device=device)
/iopsstor/scratch/cscs/kasparr/project/src/train.py:236: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  num_items_tensor = torch.tensor(num_items_in_batch, device=device)
/iopsstor/scratch/cscs/kasparr/project/src/train.py:236: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  num_items_tensor = torch.tensor(num_items_in_batch, device=device)
/iopsstor/scratch/cscs/kasparr/project/src/train.py:236: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  num_items_tensor = torch.tensor(num_items_in_batch, device=device)
2025-05-19 09:21:50,465 - root - INFO - Step: 1 | Loss: 12.00 | Tokens per second: 9426.42 | Training tokens per second (%): 1.30 | MFU (%): 8.83 | TFLOPs: 87.30 | Global batch size: 128 | Global tokens/sec: 150822.68 | Global MFU (%): 8.83 | Global TFLOPs: 1396.83 | 
2025-05-19 09:21:54,592 - root - INFO - Step: 10 | Loss: 11.92 | Tokens per second: 35735.50 | Training tokens per second (%): 2.05 | MFU (%): 33.46 | TFLOPs: 330.96 | Global batch size: 128 | Global tokens/sec: 571768.04 | Global MFU (%): 33.46 | Global TFLOPs: 5295.39 | 
2025-05-19 09:21:58,777 - root - INFO - Step: 20 | Loss: 11.42 | Tokens per second: 39156.30 | Training tokens per second (%): 2.46 | MFU (%): 36.67 | TFLOPs: 362.64 | Global batch size: 128 | Global tokens/sec: 626500.72 | Global MFU (%): 36.67 | Global TFLOPs: 5802.29 | 
2025-05-19 09:22:03,034 - root - INFO - Step: 30 | Loss: 10.71 | Tokens per second: 38501.16 | Training tokens per second (%): 2.58 | MFU (%): 36.05 | TFLOPs: 356.58 | Global batch size: 128 | Global tokens/sec: 616018.63 | Global MFU (%): 36.05 | Global TFLOPs: 5705.21 | 
2025-05-19 09:22:07,237 - root - INFO - Step: 40 | Loss: 10.10 | Tokens per second: 38986.23 | Training tokens per second (%): 2.24 | MFU (%): 36.51 | TFLOPs: 361.07 | Global batch size: 128 | Global tokens/sec: 623779.66 | Global MFU (%): 36.51 | Global TFLOPs: 5777.09 | 
2025-05-19 09:22:11,444 - root - INFO - Step: 50 | Loss: 9.52 | Tokens per second: 38949.76 | Training tokens per second (%): 2.26 | MFU (%): 36.47 | TFLOPs: 360.73 | Global batch size: 128 | Global tokens/sec: 623196.13 | Global MFU (%): 36.47 | Global TFLOPs: 5771.69 | 
2025-05-19 09:22:15,646 - root - INFO - Step: 60 | Loss: 8.97 | Tokens per second: 39001.02 | Training tokens per second (%): 2.07 | MFU (%): 36.52 | TFLOPs: 361.21 | Global batch size: 128 | Global tokens/sec: 624016.40 | Global MFU (%): 36.52 | Global TFLOPs: 5779.28 | 
2025-05-19 09:22:19,680 - root - INFO - Step: 70 | Loss: 8.48 | Tokens per second: 40618.07 | Training tokens per second (%): 2.13 | MFU (%): 38.04 | TFLOPs: 376.18 | Global batch size: 128 | Global tokens/sec: 649889.07 | Global MFU (%): 38.04 | Global TFLOPs: 6018.90 | 
2025-05-19 09:22:23,895 - root - INFO - Step: 80 | Loss: 7.97 | Tokens per second: 38883.85 | Training tokens per second (%): 2.26 | MFU (%): 36.41 | TFLOPs: 360.12 | Global batch size: 128 | Global tokens/sec: 622141.61 | Global MFU (%): 36.41 | Global TFLOPs: 5761.92 | 
2025-05-19 09:22:28,104 - root - INFO - Step: 90 | Loss: 7.69 | Tokens per second: 38928.11 | Training tokens per second (%): 2.29 | MFU (%): 36.45 | TFLOPs: 360.53 | Global batch size: 128 | Global tokens/sec: 622849.83 | Global MFU (%): 36.45 | Global TFLOPs: 5768.48 | 
2025-05-19 09:22:32,310 - root - INFO - Step: 100 | Loss: 7.45 | Tokens per second: 38964.26 | Training tokens per second (%): 2.40 | MFU (%): 36.49 | TFLOPs: 360.86 | Global batch size: 128 | Global tokens/sec: 623428.22 | Global MFU (%): 36.49 | Global TFLOPs: 5773.84 | 
2025-05-19 09:22:36,528 - root - INFO - Step: 110 | Loss: 7.32 | Tokens per second: 38848.44 | Training tokens per second (%): 2.05 | MFU (%): 36.38 | TFLOPs: 359.79 | Global batch size: 128 | Global tokens/sec: 621575.06 | Global MFU (%): 36.38 | Global TFLOPs: 5756.67 | 
2025-05-19 09:22:40,739 - root - INFO - Step: 120 | Loss: 7.19 | Tokens per second: 38919.10 | Training tokens per second (%): 2.27 | MFU (%): 36.45 | TFLOPs: 360.45 | Global batch size: 128 | Global tokens/sec: 622705.67 | Global MFU (%): 36.45 | Global TFLOPs: 5767.14 | 
2025-05-19 09:22:44,777 - root - INFO - Step: 130 | Loss: 7.09 | Tokens per second: 40573.51 | Training tokens per second (%): 2.69 | MFU (%): 37.99 | TFLOPs: 375.77 | Global batch size: 128 | Global tokens/sec: 649176.14 | Global MFU (%): 37.99 | Global TFLOPs: 6012.30 | 
2025-05-19 09:22:48,982 - root - INFO - Step: 140 | Loss: 7.11 | Tokens per second: 38975.84 | Training tokens per second (%): 2.76 | MFU (%): 36.50 | TFLOPs: 360.97 | Global batch size: 128 | Global tokens/sec: 623613.45 | Global MFU (%): 36.50 | Global TFLOPs: 5775.55 | 
2025-05-19 09:22:53,193 - root - INFO - Step: 150 | Loss: 7.03 | Tokens per second: 38915.93 | Training tokens per second (%): 2.60 | MFU (%): 36.44 | TFLOPs: 360.42 | Global batch size: 128 | Global tokens/sec: 622654.81 | Global MFU (%): 36.44 | Global TFLOPs: 5766.67 | 
2025-05-19 09:22:57,421 - root - INFO - Step: 160 | Loss: 6.96 | Tokens per second: 38753.28 | Training tokens per second (%): 2.46 | MFU (%): 36.29 | TFLOPs: 358.91 | Global batch size: 128 | Global tokens/sec: 620052.49 | Global MFU (%): 36.29 | Global TFLOPs: 5742.57 | 
2025-05-19 09:23:01,633 - root - INFO - Step: 170 | Loss: 6.90 | Tokens per second: 38904.66 | Training tokens per second (%): 2.45 | MFU (%): 36.43 | TFLOPs: 360.31 | Global batch size: 128 | Global tokens/sec: 622474.49 | Global MFU (%): 36.43 | Global TFLOPs: 5765.00 | 
2025-05-19 09:23:05,842 - root - INFO - Step: 180 | Loss: 6.91 | Tokens per second: 38938.47 | Training tokens per second (%): 2.36 | MFU (%): 36.46 | TFLOPs: 360.63 | Global batch size: 128 | Global tokens/sec: 623015.58 | Global MFU (%): 36.46 | Global TFLOPs: 5770.01 | 
2025-05-19 09:23:09,880 - root - INFO - Step: 190 | Loss: 6.84 | Tokens per second: 40578.29 | Training tokens per second (%): 2.02 | MFU (%): 38.00 | TFLOPs: 375.81 | Global batch size: 128 | Global tokens/sec: 649252.67 | Global MFU (%): 38.00 | Global TFLOPs: 6013.01 | 
2025-05-19 09:23:14,096 - root - INFO - Step: 200 | Loss: 6.71 | Tokens per second: 38870.69 | Training tokens per second (%): 2.38 | MFU (%): 36.40 | TFLOPs: 360.00 | Global batch size: 128 | Global tokens/sec: 621931.07 | Global MFU (%): 36.40 | Global TFLOPs: 5759.97 | 
2025-05-19 09:23:18,307 - root - INFO - Step: 210 | Loss: 6.72 | Tokens per second: 38915.83 | Training tokens per second (%): 2.14 | MFU (%): 36.44 | TFLOPs: 360.42 | Global batch size: 128 | Global tokens/sec: 622653.27 | Global MFU (%): 36.44 | Global TFLOPs: 5766.66 | 
2025-05-19 09:23:22,519 - root - INFO - Step: 220 | Loss: 6.62 | Tokens per second: 38906.65 | Training tokens per second (%): 2.40 | MFU (%): 36.43 | TFLOPs: 360.33 | Global batch size: 128 | Global tokens/sec: 622506.39 | Global MFU (%): 36.43 | Global TFLOPs: 5765.30 | 
2025-05-19 09:23:26,733 - root - INFO - Step: 230 | Loss: 6.58 | Tokens per second: 38880.49 | Training tokens per second (%): 2.13 | MFU (%): 36.41 | TFLOPs: 360.09 | Global batch size: 128 | Global tokens/sec: 622087.88 | Global MFU (%): 36.41 | Global TFLOPs: 5761.42 | 
2025-05-19 09:23:30,957 - root - INFO - Step: 240 | Loss: 6.58 | Tokens per second: 38797.67 | Training tokens per second (%): 2.20 | MFU (%): 36.33 | TFLOPs: 359.32 | Global batch size: 128 | Global tokens/sec: 620762.76 | Global MFU (%): 36.33 | Global TFLOPs: 5749.15 | 
2025-05-19 09:23:35,179 - root - INFO - Step: 250 | Loss: 6.54 | Tokens per second: 38810.67 | Training tokens per second (%): 2.59 | MFU (%): 36.34 | TFLOPs: 359.44 | Global batch size: 128 | Global tokens/sec: 620970.79 | Global MFU (%): 36.34 | Global TFLOPs: 5751.08 | 
2025-05-19 09:23:39,222 - root - INFO - Step: 260 | Loss: 6.46 | Tokens per second: 40536.36 | Training tokens per second (%): 2.27 | MFU (%): 37.96 | TFLOPs: 375.42 | Global batch size: 128 | Global tokens/sec: 648581.81 | Global MFU (%): 37.96 | Global TFLOPs: 6006.79 | 
2025-05-19 09:23:43,442 - root - INFO - Step: 270 | Loss: 6.50 | Tokens per second: 38835.98 | Training tokens per second (%): 2.16 | MFU (%): 36.37 | TFLOPs: 359.68 | Global batch size: 128 | Global tokens/sec: 621375.68 | Global MFU (%): 36.37 | Global TFLOPs: 5754.83 | 
2025-05-19 09:23:47,651 - root - INFO - Step: 280 | Loss: 6.46 | Tokens per second: 38926.68 | Training tokens per second (%): 2.38 | MFU (%): 36.45 | TFLOPs: 360.52 | Global batch size: 128 | Global tokens/sec: 622826.83 | Global MFU (%): 36.45 | Global TFLOPs: 5768.27 | 
2025-05-19 09:23:51,856 - root - INFO - Step: 290 | Loss: 6.39 | Tokens per second: 38972.34 | Training tokens per second (%): 2.45 | MFU (%): 36.50 | TFLOPs: 360.94 | Global batch size: 128 | Global tokens/sec: 623557.44 | Global MFU (%): 36.50 | Global TFLOPs: 5775.03 | 
2025-05-19 09:23:56,080 - root - INFO - Step: 300 | Loss: 6.31 | Tokens per second: 38800.39 | Training tokens per second (%): 2.48 | MFU (%): 36.33 | TFLOPs: 359.35 | Global batch size: 128 | Global tokens/sec: 620806.22 | Global MFU (%): 36.33 | Global TFLOPs: 5749.55 | 
2025-05-19 09:24:00,308 - root - INFO - Step: 310 | Loss: 6.39 | Tokens per second: 38751.68 | Training tokens per second (%): 2.54 | MFU (%): 36.29 | TFLOPs: 358.90 | Global batch size: 128 | Global tokens/sec: 620026.91 | Global MFU (%): 36.29 | Global TFLOPs: 5742.34 | 
2025-05-19 09:24:04,337 - root - INFO - Step: 320 | Loss: 6.29 | Tokens per second: 40677.97 | Training tokens per second (%): 2.10 | MFU (%): 38.09 | TFLOPs: 376.74 | Global batch size: 128 | Global tokens/sec: 650847.51 | Global MFU (%): 38.09 | Global TFLOPs: 6027.78 | 
2025-05-19 09:24:08,556 - root - INFO - Step: 330 | Loss: 6.24 | Tokens per second: 38841.56 | Training tokens per second (%): 2.39 | MFU (%): 36.37 | TFLOPs: 359.73 | Global batch size: 128 | Global tokens/sec: 621465.03 | Global MFU (%): 36.37 | Global TFLOPs: 5755.65 | 
2025-05-19 09:24:12,856 - root - INFO - Step: 340 | Loss: 6.15 | Tokens per second: 38108.47 | Training tokens per second (%): 2.47 | MFU (%): 35.69 | TFLOPs: 352.94 | Global batch size: 128 | Global tokens/sec: 609735.60 | Global MFU (%): 35.69 | Global TFLOPs: 5647.02 | 
2025-05-19 09:24:17,133 - root - INFO - Step: 350 | Loss: 6.22 | Tokens per second: 38314.46 | Training tokens per second (%): 2.32 | MFU (%): 35.88 | TFLOPs: 354.85 | Global batch size: 128 | Global tokens/sec: 613031.37 | Global MFU (%): 35.88 | Global TFLOPs: 5677.55 | 
2025-05-19 09:24:21,350 - root - INFO - Step: 360 | Loss: 6.20 | Tokens per second: 38862.24 | Training tokens per second (%): 2.33 | MFU (%): 36.39 | TFLOPs: 359.92 | Global batch size: 128 | Global tokens/sec: 621795.78 | Global MFU (%): 36.39 | Global TFLOPs: 5758.72 | 
2025-05-19 09:24:25,581 - root - INFO - Step: 370 | Loss: 6.19 | Tokens per second: 38726.68 | Training tokens per second (%): 2.37 | MFU (%): 36.27 | TFLOPs: 358.66 | Global batch size: 128 | Global tokens/sec: 619626.87 | Global MFU (%): 36.27 | Global TFLOPs: 5738.63 | 
2025-05-19 09:24:29,624 - root - INFO - Step: 380 | Loss: 6.10 | Tokens per second: 40533.54 | Training tokens per second (%): 2.15 | MFU (%): 37.96 | TFLOPs: 375.40 | Global batch size: 128 | Global tokens/sec: 648536.68 | Global MFU (%): 37.96 | Global TFLOPs: 6006.38 | 
2025-05-19 09:24:33,842 - root - INFO - Step: 390 | Loss: 6.24 | Tokens per second: 38853.44 | Training tokens per second (%): 2.23 | MFU (%): 36.38 | TFLOPs: 359.84 | Global batch size: 128 | Global tokens/sec: 621655.01 | Global MFU (%): 36.38 | Global TFLOPs: 5757.41 | 
2025-05-19 09:24:38,059 - root - INFO - Step: 400 | Loss: 6.17 | Tokens per second: 38853.19 | Training tokens per second (%): 2.28 | MFU (%): 36.38 | TFLOPs: 359.84 | Global batch size: 128 | Global tokens/sec: 621651.09 | Global MFU (%): 36.38 | Global TFLOPs: 5757.38 | 
2025-05-19 09:24:42,273 - root - INFO - Step: 410 | Loss: 6.14 | Tokens per second: 38886.60 | Training tokens per second (%): 2.35 | MFU (%): 36.42 | TFLOPs: 360.15 | Global batch size: 128 | Global tokens/sec: 622185.53 | Global MFU (%): 36.42 | Global TFLOPs: 5762.33 | 
2025-05-19 09:24:46,482 - root - INFO - Step: 420 | Loss: 6.01 | Tokens per second: 38936.22 | Training tokens per second (%): 2.50 | MFU (%): 36.46 | TFLOPs: 360.61 | Global batch size: 128 | Global tokens/sec: 622979.50 | Global MFU (%): 36.46 | Global TFLOPs: 5769.68 | 
2025-05-19 09:24:50,713 - root - INFO - Step: 430 | Loss: 6.14 | Tokens per second: 38731.02 | Training tokens per second (%): 2.85 | MFU (%): 36.27 | TFLOPs: 358.70 | Global batch size: 128 | Global tokens/sec: 619696.33 | Global MFU (%): 36.27 | Global TFLOPs: 5739.27 | 
2025-05-19 09:24:54,933 - root - INFO - Step: 440 | Loss: 6.09 | Tokens per second: 38833.74 | Training tokens per second (%): 2.21 | MFU (%): 36.37 | TFLOPs: 359.66 | Global batch size: 128 | Global tokens/sec: 621339.82 | Global MFU (%): 36.37 | Global TFLOPs: 5754.49 | 
2025-05-19 09:24:58,965 - root - INFO - Step: 450 | Loss: 5.91 | Tokens per second: 40642.44 | Training tokens per second (%): 2.40 | MFU (%): 38.06 | TFLOPs: 376.41 | Global batch size: 128 | Global tokens/sec: 650279.09 | Global MFU (%): 38.06 | Global TFLOPs: 6022.51 | 
2025-05-19 09:25:03,180 - root - INFO - Step: 460 | Loss: 6.00 | Tokens per second: 38870.93 | Training tokens per second (%): 2.41 | MFU (%): 36.40 | TFLOPs: 360.00 | Global batch size: 128 | Global tokens/sec: 621934.84 | Global MFU (%): 36.40 | Global TFLOPs: 5760.01 | 
2025-05-19 09:25:07,398 - root - INFO - Step: 470 | Loss: 6.00 | Tokens per second: 38852.08 | Training tokens per second (%): 2.06 | MFU (%): 36.38 | TFLOPs: 359.83 | Global batch size: 128 | Global tokens/sec: 621633.36 | Global MFU (%): 36.38 | Global TFLOPs: 5757.21 | 
2025-05-19 09:25:11,615 - root - INFO - Step: 480 | Loss: 5.93 | Tokens per second: 38864.36 | Training tokens per second (%): 2.29 | MFU (%): 36.39 | TFLOPs: 359.94 | Global batch size: 128 | Global tokens/sec: 621829.84 | Global MFU (%): 36.39 | Global TFLOPs: 5759.03 | 
2025-05-19 09:25:15,832 - root - INFO - Step: 490 | Loss: 5.97 | Tokens per second: 38852.66 | Training tokens per second (%): 2.45 | MFU (%): 36.38 | TFLOPs: 359.83 | Global batch size: 128 | Global tokens/sec: 621642.58 | Global MFU (%): 36.38 | Global TFLOPs: 5757.30 | 
2025-05-19 09:25:20,044 - root - INFO - Step: 500 | Loss: 5.89 | Tokens per second: 38911.73 | Training tokens per second (%): 2.71 | MFU (%): 36.44 | TFLOPs: 360.38 | Global batch size: 128 | Global tokens/sec: 622587.62 | Global MFU (%): 36.44 | Global TFLOPs: 5766.05 | 
2025-05-19 09:25:24,089 - root - INFO - Step: 510 | Loss: 5.86 | Tokens per second: 40506.92 | Training tokens per second (%): 1.92 | MFU (%): 37.93 | TFLOPs: 375.15 | Global batch size: 128 | Global tokens/sec: 648110.68 | Global MFU (%): 37.93 | Global TFLOPs: 6002.43 | 
2025-05-19 09:25:28,312 - root - INFO - Step: 520 | Loss: 5.93 | Tokens per second: 38808.71 | Training tokens per second (%): 2.42 | MFU (%): 36.34 | TFLOPs: 359.42 | Global batch size: 128 | Global tokens/sec: 620939.37 | Global MFU (%): 36.34 | Global TFLOPs: 5750.79 | 
2025-05-19 09:25:32,538 - root - INFO - Step: 530 | Loss: 5.89 | Tokens per second: 38774.50 | Training tokens per second (%): 2.75 | MFU (%): 36.31 | TFLOPs: 359.11 | Global batch size: 128 | Global tokens/sec: 620392.05 | Global MFU (%): 36.31 | Global TFLOPs: 5745.72 | 
2025-05-19 09:25:36,759 - root - INFO - Step: 540 | Loss: 5.78 | Tokens per second: 38823.14 | Training tokens per second (%): 2.33 | MFU (%): 36.36 | TFLOPs: 359.56 | Global batch size: 128 | Global tokens/sec: 621170.25 | Global MFU (%): 36.36 | Global TFLOPs: 5752.92 | 
2025-05-19 09:25:40,981 - root - INFO - Step: 550 | Loss: 5.81 | Tokens per second: 38810.56 | Training tokens per second (%): 2.45 | MFU (%): 36.34 | TFLOPs: 359.44 | Global batch size: 128 | Global tokens/sec: 620968.90 | Global MFU (%): 36.34 | Global TFLOPs: 5751.06 | 
2025-05-19 09:25:45,197 - root - INFO - Step: 560 | Loss: 5.82 | Tokens per second: 38869.41 | Training tokens per second (%): 2.81 | MFU (%): 36.40 | TFLOPs: 359.99 | Global batch size: 128 | Global tokens/sec: 621910.61 | Global MFU (%): 36.40 | Global TFLOPs: 5759.78 | 
2025-05-19 09:25:49,246 - root - INFO - Step: 570 | Loss: 5.75 | Tokens per second: 40476.67 | Training tokens per second (%): 2.41 | MFU (%): 37.90 | TFLOPs: 374.87 | Global batch size: 128 | Global tokens/sec: 647626.68 | Global MFU (%): 37.90 | Global TFLOPs: 5997.95 | 
2025-05-19 09:25:53,474 - root - INFO - Step: 580 | Loss: 5.73 | Tokens per second: 38755.73 | Training tokens per second (%): 2.54 | MFU (%): 36.29 | TFLOPs: 358.93 | Global batch size: 128 | Global tokens/sec: 620091.65 | Global MFU (%): 36.29 | Global TFLOPs: 5742.93 | 
2025-05-19 09:25:57,691 - root - INFO - Step: 590 | Loss: 5.70 | Tokens per second: 38857.44 | Training tokens per second (%): 1.93 | MFU (%): 36.39 | TFLOPs: 359.88 | Global batch size: 128 | Global tokens/sec: 621719.10 | Global MFU (%): 36.39 | Global TFLOPs: 5758.01 | 
2025-05-19 09:26:01,925 - root - INFO - Step: 600 | Loss: 5.74 | Tokens per second: 38700.73 | Training tokens per second (%): 2.30 | MFU (%): 36.24 | TFLOPs: 358.42 | Global batch size: 128 | Global tokens/sec: 619211.71 | Global MFU (%): 36.24 | Global TFLOPs: 5734.79 | 
2025-05-19 09:26:06,148 - root - INFO - Step: 610 | Loss: 5.72 | Tokens per second: 38806.70 | Training tokens per second (%): 2.43 | MFU (%): 36.34 | TFLOPs: 359.41 | Global batch size: 128 | Global tokens/sec: 620907.13 | Global MFU (%): 36.34 | Global TFLOPs: 5750.49 | 
2025-05-19 09:26:10,375 - root - INFO - Step: 620 | Loss: 5.71 | Tokens per second: 38773.27 | Training tokens per second (%): 2.32 | MFU (%): 36.31 | TFLOPs: 359.10 | Global batch size: 128 | Global tokens/sec: 620372.28 | Global MFU (%): 36.31 | Global TFLOPs: 5745.53 | 
2025-05-19 09:26:14,423 - root - INFO - Step: 630 | Loss: 5.78 | Tokens per second: 40479.93 | Training tokens per second (%): 2.12 | MFU (%): 37.91 | TFLOPs: 374.90 | Global batch size: 128 | Global tokens/sec: 647678.87 | Global MFU (%): 37.91 | Global TFLOPs: 5998.43 | 
2025-05-19 09:26:18,648 - root - INFO - Step: 640 | Loss: 5.73 | Tokens per second: 38782.68 | Training tokens per second (%): 2.71 | MFU (%): 36.32 | TFLOPs: 359.18 | Global batch size: 128 | Global tokens/sec: 620522.95 | Global MFU (%): 36.32 | Global TFLOPs: 5746.93 | 
2025-05-19 09:26:22,865 - root - INFO - Step: 650 | Loss: 5.66 | Tokens per second: 38859.79 | Training tokens per second (%): 1.99 | MFU (%): 36.39 | TFLOPs: 359.90 | Global batch size: 128 | Global tokens/sec: 621756.60 | Global MFU (%): 36.39 | Global TFLOPs: 5758.35 | 
2025-05-19 09:26:27,110 - root - INFO - Step: 660 | Loss: 5.67 | Tokens per second: 38606.27 | Training tokens per second (%): 2.09 | MFU (%): 36.15 | TFLOPs: 357.55 | Global batch size: 128 | Global tokens/sec: 617700.39 | Global MFU (%): 36.15 | Global TFLOPs: 5720.79 | 
2025-05-19 09:26:31,330 - root - INFO - Step: 670 | Loss: 5.67 | Tokens per second: 38832.07 | Training tokens per second (%): 2.11 | MFU (%): 36.36 | TFLOPs: 359.64 | Global batch size: 128 | Global tokens/sec: 621313.16 | Global MFU (%): 36.36 | Global TFLOPs: 5754.25 | 
2025-05-19 09:26:35,558 - root - INFO - Step: 680 | Loss: 5.65 | Tokens per second: 38758.10 | Training tokens per second (%): 2.15 | MFU (%): 36.29 | TFLOPs: 358.96 | Global batch size: 128 | Global tokens/sec: 620129.59 | Global MFU (%): 36.29 | Global TFLOPs: 5743.29 | 
2025-05-19 09:26:39,774 - root - INFO - Step: 690 | Loss: 5.73 | Tokens per second: 38862.55 | Training tokens per second (%): 2.59 | MFU (%): 36.39 | TFLOPs: 359.92 | Global batch size: 128 | Global tokens/sec: 621800.80 | Global MFU (%): 36.39 | Global TFLOPs: 5758.76 | 
2025-05-19 09:26:43,812 - root - INFO - Step: 700 | Loss: 5.56 | Tokens per second: 40587.38 | Training tokens per second (%): 2.33 | MFU (%): 38.01 | TFLOPs: 375.90 | Global batch size: 128 | Global tokens/sec: 649398.16 | Global MFU (%): 38.01 | Global TFLOPs: 6014.35 | 
2025-05-19 09:26:48,039 - root - INFO - Step: 710 | Loss: 5.61 | Tokens per second: 38764.34 | Training tokens per second (%): 2.42 | MFU (%): 36.30 | TFLOPs: 359.01 | Global batch size: 128 | Global tokens/sec: 620229.46 | Global MFU (%): 36.30 | Global TFLOPs: 5744.21 | 
2025-05-19 09:26:52,256 - root - INFO - Step: 720 | Loss: 5.58 | Tokens per second: 38859.33 | Training tokens per second (%): 2.56 | MFU (%): 36.39 | TFLOPs: 359.89 | Global batch size: 128 | Global tokens/sec: 621749.28 | Global MFU (%): 36.39 | Global TFLOPs: 5758.29 | 
2025-05-19 09:26:56,474 - root - INFO - Step: 730 | Loss: 5.55 | Tokens per second: 38847.82 | Training tokens per second (%): 2.38 | MFU (%): 36.38 | TFLOPs: 359.79 | Global batch size: 128 | Global tokens/sec: 621565.06 | Global MFU (%): 36.38 | Global TFLOPs: 5756.58 | 
2025-05-19 09:27:00,711 - root - INFO - Step: 740 | Loss: 5.54 | Tokens per second: 38677.37 | Training tokens per second (%): 2.53 | MFU (%): 36.22 | TFLOPs: 358.21 | Global batch size: 128 | Global tokens/sec: 618837.88 | Global MFU (%): 36.22 | Global TFLOPs: 5731.32 | 
2025-05-19 09:27:04,949 - root - INFO - Step: 750 | Loss: 5.45 | Tokens per second: 38673.83 | Training tokens per second (%): 2.69 | MFU (%): 36.22 | TFLOPs: 358.17 | Global batch size: 128 | Global tokens/sec: 618781.34 | Global MFU (%): 36.22 | Global TFLOPs: 5730.80 | 
2025-05-19 09:27:08,991 - root - INFO - Step: 760 | Loss: 5.53 | Tokens per second: 40539.05 | Training tokens per second (%): 2.36 | MFU (%): 37.96 | TFLOPs: 375.45 | Global batch size: 128 | Global tokens/sec: 648624.84 | Global MFU (%): 37.96 | Global TFLOPs: 6007.19 | 
2025-05-19 09:27:13,207 - root - INFO - Step: 770 | Loss: 5.44 | Tokens per second: 38864.41 | Training tokens per second (%): 2.64 | MFU (%): 36.39 | TFLOPs: 359.94 | Global batch size: 128 | Global tokens/sec: 621830.59 | Global MFU (%): 36.39 | Global TFLOPs: 5759.04 | 
2025-05-19 09:27:17,430 - root - INFO - Step: 780 | Loss: 5.50 | Tokens per second: 38808.94 | Training tokens per second (%): 2.71 | MFU (%): 36.34 | TFLOPs: 359.43 | Global batch size: 128 | Global tokens/sec: 620943.02 | Global MFU (%): 36.34 | Global TFLOPs: 5750.82 | 
2025-05-19 09:27:21,651 - root - INFO - Step: 790 | Loss: 5.48 | Tokens per second: 38819.29 | Training tokens per second (%): 2.63 | MFU (%): 36.35 | TFLOPs: 359.52 | Global batch size: 128 | Global tokens/sec: 621108.66 | Global MFU (%): 36.35 | Global TFLOPs: 5752.35 | 
2025-05-19 09:27:25,872 - root - INFO - Step: 800 | Loss: 5.56 | Tokens per second: 38821.24 | Training tokens per second (%): 2.55 | MFU (%): 36.35 | TFLOPs: 359.54 | Global batch size: 128 | Global tokens/sec: 621139.88 | Global MFU (%): 36.35 | Global TFLOPs: 5752.64 | 
2025-05-19 09:27:30,105 - root - INFO - Step: 810 | Loss: 5.50 | Tokens per second: 38711.27 | Training tokens per second (%): 2.40 | MFU (%): 36.25 | TFLOPs: 358.52 | Global batch size: 128 | Global tokens/sec: 619380.34 | Global MFU (%): 36.25 | Global TFLOPs: 5736.35 | 
2025-05-19 09:27:34,147 - root - INFO - Step: 820 | Loss: 5.41 | Tokens per second: 40541.68 | Training tokens per second (%): 2.38 | MFU (%): 37.96 | TFLOPs: 375.47 | Global batch size: 128 | Global tokens/sec: 648666.81 | Global MFU (%): 37.96 | Global TFLOPs: 6007.58 | 
2025-05-19 09:27:38,366 - root - INFO - Step: 830 | Loss: 5.41 | Tokens per second: 38848.70 | Training tokens per second (%): 2.20 | MFU (%): 36.38 | TFLOPs: 359.79 | Global batch size: 128 | Global tokens/sec: 621579.19 | Global MFU (%): 36.38 | Global TFLOPs: 5756.71 | 
2025-05-19 09:27:42,589 - root - INFO - Step: 840 | Loss: 5.44 | Tokens per second: 38796.52 | Training tokens per second (%): 1.95 | MFU (%): 36.33 | TFLOPs: 359.31 | Global batch size: 128 | Global tokens/sec: 620744.25 | Global MFU (%): 36.33 | Global TFLOPs: 5748.98 | 
2025-05-19 09:27:46,814 - root - INFO - Step: 850 | Loss: 5.51 | Tokens per second: 38791.09 | Training tokens per second (%): 2.60 | MFU (%): 36.33 | TFLOPs: 359.26 | Global batch size: 128 | Global tokens/sec: 620657.47 | Global MFU (%): 36.33 | Global TFLOPs: 5748.17 | 
2025-05-19 09:27:51,050 - root - INFO - Step: 860 | Loss: 5.47 | Tokens per second: 38688.25 | Training tokens per second (%): 2.40 | MFU (%): 36.23 | TFLOPs: 358.31 | Global batch size: 128 | Global tokens/sec: 619012.03 | Global MFU (%): 36.23 | Global TFLOPs: 5732.94 | 
2025-05-19 09:27:55,285 - root - INFO - Step: 870 | Loss: 5.44 | Tokens per second: 38693.27 | Training tokens per second (%): 2.21 | MFU (%): 36.23 | TFLOPs: 358.35 | Global batch size: 128 | Global tokens/sec: 619092.37 | Global MFU (%): 36.23 | Global TFLOPs: 5733.68 | 
2025-05-19 09:27:59,515 - root - INFO - Step: 880 | Loss: 5.46 | Tokens per second: 38733.23 | Training tokens per second (%): 2.15 | MFU (%): 36.27 | TFLOPs: 358.73 | Global batch size: 128 | Global tokens/sec: 619731.71 | Global MFU (%): 36.27 | Global TFLOPs: 5739.60 | 
2025-05-19 09:28:03,577 - root - INFO - Step: 890 | Loss: 5.36 | Tokens per second: 40343.17 | Training tokens per second (%): 2.39 | MFU (%): 37.78 | TFLOPs: 373.64 | Global batch size: 128 | Global tokens/sec: 645490.72 | Global MFU (%): 37.78 | Global TFLOPs: 5978.17 | 
2025-05-19 09:28:07,802 - root - INFO - Step: 900 | Loss: 5.37 | Tokens per second: 38784.60 | Training tokens per second (%): 2.22 | MFU (%): 36.32 | TFLOPs: 359.20 | Global batch size: 128 | Global tokens/sec: 620553.62 | Global MFU (%): 36.32 | Global TFLOPs: 5747.21 | 
2025-05-19 09:28:12,024 - root - INFO - Step: 910 | Loss: 5.23 | Tokens per second: 38816.61 | Training tokens per second (%): 2.26 | MFU (%): 36.35 | TFLOPs: 359.50 | Global batch size: 128 | Global tokens/sec: 621065.69 | Global MFU (%): 36.35 | Global TFLOPs: 5751.96 | 
2025-05-19 09:28:16,244 - root - INFO - Step: 920 | Loss: 5.31 | Tokens per second: 38829.32 | Training tokens per second (%): 2.30 | MFU (%): 36.36 | TFLOPs: 359.61 | Global batch size: 128 | Global tokens/sec: 621269.15 | Global MFU (%): 36.36 | Global TFLOPs: 5753.84 | 
2025-05-19 09:28:20,461 - root - INFO - Step: 930 | Loss: 5.29 | Tokens per second: 38862.68 | Training tokens per second (%): 2.40 | MFU (%): 36.39 | TFLOPs: 359.92 | Global batch size: 128 | Global tokens/sec: 621802.87 | Global MFU (%): 36.39 | Global TFLOPs: 5758.78 | 
2025-05-19 09:28:24,680 - root - INFO - Step: 940 | Loss: 5.37 | Tokens per second: 38838.37 | Training tokens per second (%): 2.50 | MFU (%): 36.37 | TFLOPs: 359.70 | Global batch size: 128 | Global tokens/sec: 621413.98 | Global MFU (%): 36.37 | Global TFLOPs: 5755.18 | 
2025-05-19 09:28:28,715 - root - INFO - Step: 950 | Loss: 5.23 | Tokens per second: 40617.40 | Training tokens per second (%): 2.43 | MFU (%): 38.04 | TFLOPs: 376.18 | Global batch size: 128 | Global tokens/sec: 649878.33 | Global MFU (%): 38.04 | Global TFLOPs: 6018.80 | 
2025-05-19 09:28:32,957 - root - INFO - Step: 960 | Loss: 5.23 | Tokens per second: 38627.27 | Training tokens per second (%): 2.39 | MFU (%): 36.17 | TFLOPs: 357.74 | Global batch size: 128 | Global tokens/sec: 618036.27 | Global MFU (%): 36.17 | Global TFLOPs: 5723.90 | 
2025-05-19 09:28:37,184 - root - INFO - Step: 970 | Loss: 5.27 | Tokens per second: 38770.18 | Training tokens per second (%): 1.83 | MFU (%): 36.31 | TFLOPs: 359.07 | Global batch size: 128 | Global tokens/sec: 620322.83 | Global MFU (%): 36.31 | Global TFLOPs: 5745.08 | 
2025-05-19 09:28:41,408 - root - INFO - Step: 980 | Loss: 5.19 | Tokens per second: 38796.22 | Training tokens per second (%): 2.71 | MFU (%): 36.33 | TFLOPs: 359.31 | Global batch size: 128 | Global tokens/sec: 620739.46 | Global MFU (%): 36.33 | Global TFLOPs: 5748.93 | 
2025-05-19 09:28:45,625 - root - INFO - Step: 990 | Loss: 5.26 | Tokens per second: 38855.43 | Training tokens per second (%): 2.52 | MFU (%): 36.39 | TFLOPs: 359.86 | Global batch size: 128 | Global tokens/sec: 621686.92 | Global MFU (%): 36.39 | Global TFLOPs: 5757.71 | 
2025-05-19 09:28:49,845 - root - INFO - Step: 1000 | Loss: 5.20 | Tokens per second: 38830.52 | Training tokens per second (%): 2.09 | MFU (%): 36.36 | TFLOPs: 359.63 | Global batch size: 128 | Global tokens/sec: 621288.37 | Global MFU (%): 36.36 | Global TFLOPs: 5754.02 | 
2025-05-19 09:28:49,845 - root - INFO - Training completed
[sbatch-master] task finished

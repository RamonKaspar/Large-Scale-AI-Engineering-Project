[sbatch-master] running on nid006592
[sbatch-master] SLURM_NODELIST: nid006592
[sbatch-master] SLURM_NNODES: 1
[sbatch-master] SLURM_NODEID: 0
[Master] Master node: nid006592
[Master] World size: 4
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
[srun] rank=0 host=nid006592 noderank=0 localrank=0
W0519 11:20:11.883000 153146 torch/distributed/run.py:792] 
W0519 11:20:11.883000 153146 torch/distributed/run.py:792] *****************************************
W0519 11:20:11.883000 153146 torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0519 11:20:11.883000 153146 torch/distributed/run.py:792] *****************************************
2025-05-19 11:20:27,229 - root - INFO - [Distributed Init] Rank 0 initialized on node 0 on GPU 0.
[rank0]:[W519 11:20:27.972366182 ProcessGroupNCCL.cpp:4454] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
2025-05-19 11:20:27,766 - root - INFO - [Distributed Init] Rank 1 initialized on node 0 on GPU 1.
[rank1]:[W519 11:20:27.063152370 ProcessGroupNCCL.cpp:4454] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
2025-05-19 11:20:27,825 - root - INFO - [Distributed Init] Rank 2 initialized on node 0 on GPU 2.
2025-05-19 11:20:27,825 - root - INFO - [Distributed Init] Rank 3 initialized on node 0 on GPU 3.
[rank3]:[W519 11:20:27.122411962 ProcessGroupNCCL.cpp:4454] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank2]:[W519 11:20:27.122419130 ProcessGroupNCCL.cpp:4454] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
2025-05-19 11:20:34,785 - root - INFO - [Rank 0] All ranks ready!
2025-05-19 11:20:34,785 - root - INFO - Distributed training enabled: 4 processes
2025-05-19 11:20:34,785 - root - INFO - Master process: 0 on cuda:0
2025-05-19 11:20:34,785 - root - INFO - Experiment args: Namespace(dataset='/capstor/scratch/cscs/kasparr/project/train_data_tokenized_token-list_snappy.parquet', dataset_type='token-list', pretokenized=True, tokenizer_name_or_path='unsloth/Mistral-Nemo-Base-2407-bnb-4bit', sequence_length=2048, batch_size=8, fused_optimizer=False, learning_rate=5e-05, lr_warmup_steps=100, training_steps=1000, logging_frequency=10, profile=False, profile_step_start=10, profile_step_end=10, grad_max_norm=1, model_dtype='bf16', compile=False, distributed=True, backend='nccl', find_unused_parameters=False)
2025-05-19 11:20:34,785 - root - INFO - Setting up Tokenizer...
2025-05-19 11:20:35,303 - root - INFO - Setting up DataLoaders...
2025-05-19 11:20:35,303 - root - INFO - Using pretokenized data: /capstor/scratch/cscs/kasparr/project/train_data_tokenized_token-list_snappy.parquet
2025-05-19 11:20:44,137 - root - INFO - Setting up Model...
2025-05-19 11:20:52,220 - root - INFO - Model wrapped with DistributedDataParallel
2025-05-19 11:20:52,221 - root - INFO - Global batch size: 32 (local: 8 Ã— 4 processes)
2025-05-19 11:20:52,221 - root - INFO - Starting training!
/iopsstor/scratch/cscs/kasparr/project/src/train.py:236: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  num_items_tensor = torch.tensor(num_items_in_batch, device=device)
/iopsstor/scratch/cscs/kasparr/project/src/train.py:236: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  num_items_tensor = torch.tensor(num_items_in_batch, device=device)
/iopsstor/scratch/cscs/kasparr/project/src/train.py:236: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  num_items_tensor = torch.tensor(num_items_in_batch, device=device)
/iopsstor/scratch/cscs/kasparr/project/src/train.py:236: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  num_items_tensor = torch.tensor(num_items_in_batch, device=device)
2025-05-19 11:20:55,495 - root - INFO - Step: 1 | Loss: 11.94 | Tokens per second: 5006.60 | Training tokens per second (%): 24.95 | MFU (%): 4.69 | TFLOPs: 46.37 | Global batch size: 32 | Global tokens/sec: 20026.41 | Global MFU (%): 4.69 | Global TFLOPs: 185.47 | 
2025-05-19 11:20:59,251 - root - INFO - Step: 10 | Loss: 11.91 | Tokens per second: 39266.03 | Training tokens per second (%): 24.94 | MFU (%): 36.77 | TFLOPs: 363.66 | Global batch size: 32 | Global tokens/sec: 157064.13 | Global MFU (%): 36.77 | Global TFLOPs: 1454.64 | 
2025-05-19 11:21:03,304 - root - INFO - Step: 20 | Loss: 11.69 | Tokens per second: 40425.50 | Training tokens per second (%): 24.93 | MFU (%): 37.86 | TFLOPs: 374.40 | Global batch size: 32 | Global tokens/sec: 161701.99 | Global MFU (%): 37.86 | Global TFLOPs: 1497.59 | 
2025-05-19 11:21:07,355 - root - INFO - Step: 30 | Loss: 11.12 | Tokens per second: 40451.26 | Training tokens per second (%): 24.94 | MFU (%): 37.88 | TFLOPs: 374.64 | Global batch size: 32 | Global tokens/sec: 161805.05 | Global MFU (%): 37.88 | Global TFLOPs: 1498.55 | 
2025-05-19 11:21:11,410 - root - INFO - Step: 40 | Loss: 10.11 | Tokens per second: 40412.41 | Training tokens per second (%): 24.94 | MFU (%): 37.84 | TFLOPs: 374.28 | Global batch size: 32 | Global tokens/sec: 161649.65 | Global MFU (%): 37.84 | Global TFLOPs: 1497.11 | 
2025-05-19 11:21:15,463 - root - INFO - Step: 50 | Loss: 9.43 | Tokens per second: 40428.45 | Training tokens per second (%): 24.93 | MFU (%): 37.86 | TFLOPs: 374.43 | Global batch size: 32 | Global tokens/sec: 161713.80 | Global MFU (%): 37.86 | Global TFLOPs: 1497.70 | 
2025-05-19 11:21:19,519 - root - INFO - Step: 60 | Loss: 8.83 | Tokens per second: 40410.63 | Training tokens per second (%): 24.94 | MFU (%): 37.84 | TFLOPs: 374.26 | Global batch size: 32 | Global tokens/sec: 161642.50 | Global MFU (%): 37.84 | Global TFLOPs: 1497.04 | 
2025-05-19 11:21:23,611 - root - INFO - Step: 70 | Loss: 8.27 | Tokens per second: 40047.08 | Training tokens per second (%): 24.94 | MFU (%): 37.50 | TFLOPs: 370.89 | Global batch size: 32 | Global tokens/sec: 160188.31 | Global MFU (%): 37.50 | Global TFLOPs: 1483.57 | 
2025-05-19 11:21:27,659 - root - INFO - Step: 80 | Loss: 7.92 | Tokens per second: 40476.72 | Training tokens per second (%): 24.94 | MFU (%): 37.90 | TFLOPs: 374.87 | Global batch size: 32 | Global tokens/sec: 161906.89 | Global MFU (%): 37.90 | Global TFLOPs: 1499.49 | 
2025-05-19 11:21:31,709 - root - INFO - Step: 90 | Loss: 7.54 | Tokens per second: 40467.13 | Training tokens per second (%): 24.94 | MFU (%): 37.90 | TFLOPs: 374.78 | Global batch size: 32 | Global tokens/sec: 161868.52 | Global MFU (%): 37.90 | Global TFLOPs: 1499.13 | 
2025-05-19 11:21:35,750 - root - INFO - Step: 100 | Loss: 7.43 | Tokens per second: 40544.73 | Training tokens per second (%): 24.94 | MFU (%): 37.97 | TFLOPs: 375.50 | Global batch size: 32 | Global tokens/sec: 162178.91 | Global MFU (%): 37.97 | Global TFLOPs: 1502.01 | 
2025-05-19 11:21:39,801 - root - INFO - Step: 110 | Loss: 7.27 | Tokens per second: 40449.88 | Training tokens per second (%): 24.93 | MFU (%): 37.88 | TFLOPs: 374.62 | Global batch size: 32 | Global tokens/sec: 161799.51 | Global MFU (%): 37.88 | Global TFLOPs: 1498.49 | 
2025-05-19 11:21:43,849 - root - INFO - Step: 120 | Loss: 7.28 | Tokens per second: 40484.63 | Training tokens per second (%): 24.94 | MFU (%): 37.91 | TFLOPs: 374.95 | Global batch size: 32 | Global tokens/sec: 161938.54 | Global MFU (%): 37.91 | Global TFLOPs: 1499.78 | 
2025-05-19 11:21:47,890 - root - INFO - Step: 130 | Loss: 7.20 | Tokens per second: 40550.85 | Training tokens per second (%): 24.93 | MFU (%): 37.97 | TFLOPs: 375.56 | Global batch size: 32 | Global tokens/sec: 162203.39 | Global MFU (%): 37.97 | Global TFLOPs: 1502.24 | 
2025-05-19 11:21:51,931 - root - INFO - Step: 140 | Loss: 7.12 | Tokens per second: 40557.33 | Training tokens per second (%): 24.94 | MFU (%): 37.98 | TFLOPs: 375.62 | Global batch size: 32 | Global tokens/sec: 162229.32 | Global MFU (%): 37.98 | Global TFLOPs: 1502.48 | 
2025-05-19 11:21:55,987 - root - INFO - Step: 150 | Loss: 7.02 | Tokens per second: 40395.14 | Training tokens per second (%): 24.93 | MFU (%): 37.83 | TFLOPs: 374.12 | Global batch size: 32 | Global tokens/sec: 161580.56 | Global MFU (%): 37.83 | Global TFLOPs: 1496.47 | 
2025-05-19 11:22:00,029 - root - INFO - Step: 160 | Loss: 7.00 | Tokens per second: 40549.93 | Training tokens per second (%): 24.94 | MFU (%): 37.97 | TFLOPs: 375.55 | Global batch size: 32 | Global tokens/sec: 162199.71 | Global MFU (%): 37.97 | Global TFLOPs: 1502.20 | 
2025-05-19 11:22:04,091 - root - INFO - Step: 170 | Loss: 6.89 | Tokens per second: 40336.20 | Training tokens per second (%): 24.93 | MFU (%): 37.77 | TFLOPs: 373.57 | Global batch size: 32 | Global tokens/sec: 161344.79 | Global MFU (%): 37.77 | Global TFLOPs: 1494.28 | 
2025-05-19 11:22:08,138 - root - INFO - Step: 180 | Loss: 6.77 | Tokens per second: 40495.22 | Training tokens per second (%): 24.93 | MFU (%): 37.92 | TFLOPs: 375.04 | Global batch size: 32 | Global tokens/sec: 161980.90 | Global MFU (%): 37.92 | Global TFLOPs: 1500.17 | 
2025-05-19 11:22:12,189 - root - INFO - Step: 190 | Loss: 6.84 | Tokens per second: 40451.72 | Training tokens per second (%): 24.93 | MFU (%): 37.88 | TFLOPs: 374.64 | Global batch size: 32 | Global tokens/sec: 161806.87 | Global MFU (%): 37.88 | Global TFLOPs: 1498.56 | 
2025-05-19 11:22:16,242 - root - INFO - Step: 200 | Loss: 6.84 | Tokens per second: 40433.15 | Training tokens per second (%): 24.94 | MFU (%): 37.86 | TFLOPs: 374.47 | Global batch size: 32 | Global tokens/sec: 161732.59 | Global MFU (%): 37.86 | Global TFLOPs: 1497.87 | 
2025-05-19 11:22:20,299 - root - INFO - Step: 210 | Loss: 6.77 | Tokens per second: 40391.01 | Training tokens per second (%): 24.93 | MFU (%): 37.82 | TFLOPs: 374.08 | Global batch size: 32 | Global tokens/sec: 161564.02 | Global MFU (%): 37.82 | Global TFLOPs: 1496.31 | 
2025-05-19 11:22:24,353 - root - INFO - Step: 220 | Loss: 6.69 | Tokens per second: 40415.13 | Training tokens per second (%): 24.94 | MFU (%): 37.85 | TFLOPs: 374.30 | Global batch size: 32 | Global tokens/sec: 161660.53 | Global MFU (%): 37.85 | Global TFLOPs: 1497.21 | 
2025-05-19 11:22:28,431 - root - INFO - Step: 230 | Loss: 6.64 | Tokens per second: 40186.75 | Training tokens per second (%): 24.94 | MFU (%): 37.63 | TFLOPs: 372.19 | Global batch size: 32 | Global tokens/sec: 160747.00 | Global MFU (%): 37.63 | Global TFLOPs: 1488.75 | 
2025-05-19 11:22:32,490 - root - INFO - Step: 240 | Loss: 6.54 | Tokens per second: 40374.21 | Training tokens per second (%): 24.94 | MFU (%): 37.81 | TFLOPs: 373.92 | Global batch size: 32 | Global tokens/sec: 161496.83 | Global MFU (%): 37.81 | Global TFLOPs: 1495.69 | 
2025-05-19 11:22:36,542 - root - INFO - Step: 250 | Loss: 6.56 | Tokens per second: 40446.43 | Training tokens per second (%): 24.93 | MFU (%): 37.88 | TFLOPs: 374.59 | Global batch size: 32 | Global tokens/sec: 161785.71 | Global MFU (%): 37.88 | Global TFLOPs: 1498.37 | 
2025-05-19 11:22:40,602 - root - INFO - Step: 260 | Loss: 6.60 | Tokens per second: 40354.90 | Training tokens per second (%): 24.94 | MFU (%): 37.79 | TFLOPs: 373.74 | Global batch size: 32 | Global tokens/sec: 161419.59 | Global MFU (%): 37.79 | Global TFLOPs: 1494.98 | 
2025-05-19 11:22:44,656 - root - INFO - Step: 270 | Loss: 6.47 | Tokens per second: 40425.95 | Training tokens per second (%): 24.93 | MFU (%): 37.86 | TFLOPs: 374.40 | Global batch size: 32 | Global tokens/sec: 161703.79 | Global MFU (%): 37.86 | Global TFLOPs: 1497.61 | 
2025-05-19 11:22:48,712 - root - INFO - Step: 280 | Loss: 6.53 | Tokens per second: 40402.91 | Training tokens per second (%): 24.93 | MFU (%): 37.84 | TFLOPs: 374.19 | Global batch size: 32 | Global tokens/sec: 161611.63 | Global MFU (%): 37.84 | Global TFLOPs: 1496.75 | 
2025-05-19 11:22:52,769 - root - INFO - Step: 290 | Loss: 6.49 | Tokens per second: 40384.63 | Training tokens per second (%): 24.93 | MFU (%): 37.82 | TFLOPs: 374.02 | Global batch size: 32 | Global tokens/sec: 161538.53 | Global MFU (%): 37.82 | Global TFLOPs: 1496.08 | 
2025-05-19 11:22:56,928 - root - INFO - Step: 300 | Loss: 6.48 | Tokens per second: 39401.34 | Training tokens per second (%): 24.94 | MFU (%): 36.90 | TFLOPs: 364.91 | Global batch size: 32 | Global tokens/sec: 157605.37 | Global MFU (%): 36.90 | Global TFLOPs: 1459.65 | 
2025-05-19 11:23:00,986 - root - INFO - Step: 310 | Loss: 6.46 | Tokens per second: 40388.73 | Training tokens per second (%): 24.94 | MFU (%): 37.82 | TFLOPs: 374.06 | Global batch size: 32 | Global tokens/sec: 161554.93 | Global MFU (%): 37.82 | Global TFLOPs: 1496.23 | 
2025-05-19 11:23:05,045 - root - INFO - Step: 320 | Loss: 6.33 | Tokens per second: 40364.96 | Training tokens per second (%): 24.93 | MFU (%): 37.80 | TFLOPs: 373.84 | Global batch size: 32 | Global tokens/sec: 161459.84 | Global MFU (%): 37.80 | Global TFLOPs: 1495.35 | 
2025-05-19 11:23:09,106 - root - INFO - Step: 330 | Loss: 6.42 | Tokens per second: 40358.76 | Training tokens per second (%): 24.93 | MFU (%): 37.79 | TFLOPs: 373.78 | Global batch size: 32 | Global tokens/sec: 161435.02 | Global MFU (%): 37.79 | Global TFLOPs: 1495.12 | 
2025-05-19 11:23:13,162 - root - INFO - Step: 340 | Loss: 6.39 | Tokens per second: 40398.98 | Training tokens per second (%): 24.94 | MFU (%): 37.83 | TFLOPs: 374.15 | Global batch size: 32 | Global tokens/sec: 161595.93 | Global MFU (%): 37.83 | Global TFLOPs: 1496.61 | 
2025-05-19 11:23:17,219 - root - INFO - Step: 350 | Loss: 6.34 | Tokens per second: 40393.69 | Training tokens per second (%): 24.94 | MFU (%): 37.83 | TFLOPs: 374.10 | Global batch size: 32 | Global tokens/sec: 161574.77 | Global MFU (%): 37.83 | Global TFLOPs: 1496.41 | 
2025-05-19 11:23:21,275 - root - INFO - Step: 360 | Loss: 6.39 | Tokens per second: 40398.67 | Training tokens per second (%): 24.93 | MFU (%): 37.83 | TFLOPs: 374.15 | Global batch size: 32 | Global tokens/sec: 161594.68 | Global MFU (%): 37.83 | Global TFLOPs: 1496.60 | 
2025-05-19 11:23:25,330 - root - INFO - Step: 370 | Loss: 6.28 | Tokens per second: 40405.78 | Training tokens per second (%): 24.94 | MFU (%): 37.84 | TFLOPs: 374.22 | Global batch size: 32 | Global tokens/sec: 161623.12 | Global MFU (%): 37.84 | Global TFLOPs: 1496.86 | 
2025-05-19 11:23:29,395 - root - INFO - Step: 380 | Loss: 6.31 | Tokens per second: 40315.20 | Training tokens per second (%): 24.94 | MFU (%): 37.75 | TFLOPs: 373.38 | Global batch size: 32 | Global tokens/sec: 161260.79 | Global MFU (%): 37.75 | Global TFLOPs: 1493.51 | 
2025-05-19 11:23:33,454 - root - INFO - Step: 390 | Loss: 6.24 | Tokens per second: 40377.62 | Training tokens per second (%): 24.93 | MFU (%): 37.81 | TFLOPs: 373.95 | Global batch size: 32 | Global tokens/sec: 161510.50 | Global MFU (%): 37.81 | Global TFLOPs: 1495.82 | 
2025-05-19 11:23:37,516 - root - INFO - Step: 400 | Loss: 6.19 | Tokens per second: 40338.42 | Training tokens per second (%): 24.94 | MFU (%): 37.77 | TFLOPs: 373.59 | Global batch size: 32 | Global tokens/sec: 161353.67 | Global MFU (%): 37.77 | Global TFLOPs: 1494.37 | 
2025-05-19 11:23:41,573 - root - INFO - Step: 410 | Loss: 6.20 | Tokens per second: 40390.14 | Training tokens per second (%): 24.94 | MFU (%): 37.82 | TFLOPs: 374.07 | Global batch size: 32 | Global tokens/sec: 161560.56 | Global MFU (%): 37.82 | Global TFLOPs: 1496.28 | 
2025-05-19 11:23:45,635 - root - INFO - Step: 420 | Loss: 6.16 | Tokens per second: 40345.42 | Training tokens per second (%): 24.94 | MFU (%): 37.78 | TFLOPs: 373.66 | Global batch size: 32 | Global tokens/sec: 161381.67 | Global MFU (%): 37.78 | Global TFLOPs: 1494.62 | 
2025-05-19 11:23:49,699 - root - INFO - Step: 430 | Loss: 6.20 | Tokens per second: 40320.76 | Training tokens per second (%): 24.94 | MFU (%): 37.76 | TFLOPs: 373.43 | Global batch size: 32 | Global tokens/sec: 161283.04 | Global MFU (%): 37.76 | Global TFLOPs: 1493.71 | 
2025-05-19 11:23:53,758 - root - INFO - Step: 440 | Loss: 6.07 | Tokens per second: 40369.45 | Training tokens per second (%): 24.94 | MFU (%): 37.80 | TFLOPs: 373.88 | Global batch size: 32 | Global tokens/sec: 161477.80 | Global MFU (%): 37.80 | Global TFLOPs: 1495.52 | 
2025-05-19 11:23:57,821 - root - INFO - Step: 450 | Loss: 6.08 | Tokens per second: 40326.03 | Training tokens per second (%): 24.93 | MFU (%): 37.76 | TFLOPs: 373.48 | Global batch size: 32 | Global tokens/sec: 161304.11 | Global MFU (%): 37.76 | Global TFLOPs: 1493.91 | 
2025-05-19 11:24:01,885 - root - INFO - Step: 460 | Loss: 6.08 | Tokens per second: 40321.98 | Training tokens per second (%): 24.94 | MFU (%): 37.76 | TFLOPs: 373.44 | Global batch size: 32 | Global tokens/sec: 161287.92 | Global MFU (%): 37.76 | Global TFLOPs: 1493.76 | 
2025-05-19 11:24:05,945 - root - INFO - Step: 470 | Loss: 6.05 | Tokens per second: 40362.85 | Training tokens per second (%): 24.93 | MFU (%): 37.80 | TFLOPs: 373.82 | Global batch size: 32 | Global tokens/sec: 161451.40 | Global MFU (%): 37.80 | Global TFLOPs: 1495.27 | 
2025-05-19 11:24:10,006 - root - INFO - Step: 480 | Loss: 6.07 | Tokens per second: 40355.26 | Training tokens per second (%): 24.94 | MFU (%): 37.79 | TFLOPs: 373.75 | Global batch size: 32 | Global tokens/sec: 161421.03 | Global MFU (%): 37.79 | Global TFLOPs: 1494.99 | 
2025-05-19 11:24:14,063 - root - INFO - Step: 490 | Loss: 6.09 | Tokens per second: 40388.87 | Training tokens per second (%): 24.94 | MFU (%): 37.82 | TFLOPs: 374.06 | Global batch size: 32 | Global tokens/sec: 161555.49 | Global MFU (%): 37.82 | Global TFLOPs: 1496.23 | 
2025-05-19 11:24:18,128 - root - INFO - Step: 500 | Loss: 6.00 | Tokens per second: 40309.39 | Training tokens per second (%): 24.94 | MFU (%): 37.75 | TFLOPs: 373.32 | Global batch size: 32 | Global tokens/sec: 161237.55 | Global MFU (%): 37.75 | Global TFLOPs: 1493.29 | 
2025-05-19 11:24:22,188 - root - INFO - Step: 510 | Loss: 5.97 | Tokens per second: 40365.66 | Training tokens per second (%): 24.93 | MFU (%): 37.80 | TFLOPs: 373.84 | Global batch size: 32 | Global tokens/sec: 161462.62 | Global MFU (%): 37.80 | Global TFLOPs: 1495.37 | 
2025-05-19 11:24:26,246 - root - INFO - Step: 520 | Loss: 6.09 | Tokens per second: 40377.10 | Training tokens per second (%): 24.94 | MFU (%): 37.81 | TFLOPs: 373.95 | Global batch size: 32 | Global tokens/sec: 161508.40 | Global MFU (%): 37.81 | Global TFLOPs: 1495.80 | 
2025-05-19 11:24:30,309 - root - INFO - Step: 530 | Loss: 5.96 | Tokens per second: 40328.83 | Training tokens per second (%): 24.93 | MFU (%): 37.77 | TFLOPs: 373.50 | Global batch size: 32 | Global tokens/sec: 161315.32 | Global MFU (%): 37.77 | Global TFLOPs: 1494.01 | 
2025-05-19 11:24:34,370 - root - INFO - Step: 540 | Loss: 6.01 | Tokens per second: 40350.86 | Training tokens per second (%): 24.93 | MFU (%): 37.79 | TFLOPs: 373.71 | Global batch size: 32 | Global tokens/sec: 161403.46 | Global MFU (%): 37.79 | Global TFLOPs: 1494.83 | 
2025-05-19 11:24:38,427 - root - INFO - Step: 550 | Loss: 5.97 | Tokens per second: 40391.61 | Training tokens per second (%): 24.93 | MFU (%): 37.82 | TFLOPs: 374.08 | Global batch size: 32 | Global tokens/sec: 161566.46 | Global MFU (%): 37.82 | Global TFLOPs: 1496.34 | 
2025-05-19 11:24:42,491 - root - INFO - Step: 560 | Loss: 5.97 | Tokens per second: 40328.04 | Training tokens per second (%): 24.94 | MFU (%): 37.76 | TFLOPs: 373.50 | Global batch size: 32 | Global tokens/sec: 161312.15 | Global MFU (%): 37.76 | Global TFLOPs: 1493.98 | 
2025-05-19 11:24:46,549 - root - INFO - Step: 570 | Loss: 5.96 | Tokens per second: 40374.48 | Training tokens per second (%): 24.94 | MFU (%): 37.81 | TFLOPs: 373.93 | Global batch size: 32 | Global tokens/sec: 161497.92 | Global MFU (%): 37.81 | Global TFLOPs: 1495.70 | 
2025-05-19 11:24:50,606 - root - INFO - Step: 580 | Loss: 6.02 | Tokens per second: 40395.44 | Training tokens per second (%): 24.94 | MFU (%): 37.83 | TFLOPs: 374.12 | Global batch size: 32 | Global tokens/sec: 161581.76 | Global MFU (%): 37.83 | Global TFLOPs: 1496.48 | 
2025-05-19 11:24:54,664 - root - INFO - Step: 590 | Loss: 5.88 | Tokens per second: 40378.10 | Training tokens per second (%): 24.94 | MFU (%): 37.81 | TFLOPs: 373.96 | Global batch size: 32 | Global tokens/sec: 161512.38 | Global MFU (%): 37.81 | Global TFLOPs: 1495.84 | 
2025-05-19 11:24:58,722 - root - INFO - Step: 600 | Loss: 5.87 | Tokens per second: 40381.97 | Training tokens per second (%): 24.94 | MFU (%): 37.82 | TFLOPs: 373.99 | Global batch size: 32 | Global tokens/sec: 161527.90 | Global MFU (%): 37.82 | Global TFLOPs: 1495.98 | 
2025-05-19 11:25:02,782 - root - INFO - Step: 610 | Loss: 5.90 | Tokens per second: 40363.23 | Training tokens per second (%): 24.93 | MFU (%): 37.80 | TFLOPs: 373.82 | Global batch size: 32 | Global tokens/sec: 161452.94 | Global MFU (%): 37.80 | Global TFLOPs: 1495.28 | 
2025-05-19 11:25:06,844 - root - INFO - Step: 620 | Loss: 5.80 | Tokens per second: 40337.95 | Training tokens per second (%): 24.94 | MFU (%): 37.77 | TFLOPs: 373.59 | Global batch size: 32 | Global tokens/sec: 161351.80 | Global MFU (%): 37.77 | Global TFLOPs: 1494.35 | 
2025-05-19 11:25:10,902 - root - INFO - Step: 630 | Loss: 5.80 | Tokens per second: 40381.10 | Training tokens per second (%): 24.94 | MFU (%): 37.81 | TFLOPs: 373.99 | Global batch size: 32 | Global tokens/sec: 161524.39 | Global MFU (%): 37.81 | Global TFLOPs: 1495.95 | 
2025-05-19 11:25:14,966 - root - INFO - Step: 640 | Loss: 5.88 | Tokens per second: 40326.81 | Training tokens per second (%): 24.94 | MFU (%): 37.76 | TFLOPs: 373.48 | Global batch size: 32 | Global tokens/sec: 161307.25 | Global MFU (%): 37.76 | Global TFLOPs: 1493.94 | 
2025-05-19 11:25:19,030 - root - INFO - Step: 650 | Loss: 5.75 | Tokens per second: 40318.39 | Training tokens per second (%): 24.94 | MFU (%): 37.76 | TFLOPs: 373.41 | Global batch size: 32 | Global tokens/sec: 161273.56 | Global MFU (%): 37.76 | Global TFLOPs: 1493.62 | 
2025-05-19 11:25:23,096 - root - INFO - Step: 660 | Loss: 5.86 | Tokens per second: 40303.90 | Training tokens per second (%): 24.94 | MFU (%): 37.74 | TFLOPs: 373.27 | Global batch size: 32 | Global tokens/sec: 161215.59 | Global MFU (%): 37.74 | Global TFLOPs: 1493.09 | 
2025-05-19 11:25:27,152 - root - INFO - Step: 670 | Loss: 5.88 | Tokens per second: 40396.20 | Training tokens per second (%): 24.94 | MFU (%): 37.83 | TFLOPs: 374.13 | Global batch size: 32 | Global tokens/sec: 161584.80 | Global MFU (%): 37.83 | Global TFLOPs: 1496.51 | 
2025-05-19 11:25:31,215 - root - INFO - Step: 680 | Loss: 5.78 | Tokens per second: 40327.77 | Training tokens per second (%): 24.93 | MFU (%): 37.76 | TFLOPs: 373.49 | Global batch size: 32 | Global tokens/sec: 161311.07 | Global MFU (%): 37.76 | Global TFLOPs: 1493.97 | 
2025-05-19 11:25:35,273 - root - INFO - Step: 690 | Loss: 5.86 | Tokens per second: 40383.48 | Training tokens per second (%): 24.93 | MFU (%): 37.82 | TFLOPs: 374.01 | Global batch size: 32 | Global tokens/sec: 161533.90 | Global MFU (%): 37.82 | Global TFLOPs: 1496.03 | 
2025-05-19 11:25:39,327 - root - INFO - Step: 700 | Loss: 5.74 | Tokens per second: 40423.70 | Training tokens per second (%): 24.93 | MFU (%): 37.85 | TFLOPs: 374.38 | Global batch size: 32 | Global tokens/sec: 161694.78 | Global MFU (%): 37.85 | Global TFLOPs: 1497.52 | 
2025-05-19 11:25:43,391 - root - INFO - Step: 710 | Loss: 5.81 | Tokens per second: 40318.52 | Training tokens per second (%): 24.94 | MFU (%): 37.76 | TFLOPs: 373.41 | Global batch size: 32 | Global tokens/sec: 161274.10 | Global MFU (%): 37.76 | Global TFLOPs: 1493.63 | 
2025-05-19 11:25:47,448 - root - INFO - Step: 720 | Loss: 5.77 | Tokens per second: 40388.24 | Training tokens per second (%): 24.94 | MFU (%): 37.82 | TFLOPs: 374.05 | Global batch size: 32 | Global tokens/sec: 161552.94 | Global MFU (%): 37.82 | Global TFLOPs: 1496.21 | 
2025-05-19 11:25:51,510 - root - INFO - Step: 730 | Loss: 5.77 | Tokens per second: 40344.71 | Training tokens per second (%): 24.93 | MFU (%): 37.78 | TFLOPs: 373.65 | Global batch size: 32 | Global tokens/sec: 161378.86 | Global MFU (%): 37.78 | Global TFLOPs: 1494.60 | 
2025-05-19 11:25:55,576 - root - INFO - Step: 740 | Loss: 5.75 | Tokens per second: 40303.94 | Training tokens per second (%): 24.93 | MFU (%): 37.74 | TFLOPs: 373.27 | Global batch size: 32 | Global tokens/sec: 161215.76 | Global MFU (%): 37.74 | Global TFLOPs: 1493.09 | 
2025-05-19 11:25:59,630 - root - INFO - Step: 750 | Loss: 5.84 | Tokens per second: 40416.46 | Training tokens per second (%): 24.94 | MFU (%): 37.85 | TFLOPs: 374.31 | Global batch size: 32 | Global tokens/sec: 161665.86 | Global MFU (%): 37.85 | Global TFLOPs: 1497.26 | 
2025-05-19 11:26:03,692 - root - INFO - Step: 760 | Loss: 5.75 | Tokens per second: 40343.23 | Training tokens per second (%): 24.94 | MFU (%): 37.78 | TFLOPs: 373.64 | Global batch size: 32 | Global tokens/sec: 161372.91 | Global MFU (%): 37.78 | Global TFLOPs: 1494.54 | 
2025-05-19 11:26:07,757 - root - INFO - Step: 770 | Loss: 5.77 | Tokens per second: 40318.37 | Training tokens per second (%): 24.94 | MFU (%): 37.76 | TFLOPs: 373.41 | Global batch size: 32 | Global tokens/sec: 161273.49 | Global MFU (%): 37.76 | Global TFLOPs: 1493.62 | 
2025-05-19 11:26:11,819 - root - INFO - Step: 780 | Loss: 5.70 | Tokens per second: 40334.25 | Training tokens per second (%): 24.93 | MFU (%): 37.77 | TFLOPs: 373.55 | Global batch size: 32 | Global tokens/sec: 161336.98 | Global MFU (%): 37.77 | Global TFLOPs: 1494.21 | 
2025-05-19 11:26:15,882 - root - INFO - Step: 790 | Loss: 5.73 | Tokens per second: 40337.31 | Training tokens per second (%): 24.93 | MFU (%): 37.77 | TFLOPs: 373.58 | Global batch size: 32 | Global tokens/sec: 161349.23 | Global MFU (%): 37.77 | Global TFLOPs: 1494.32 | 
2025-05-19 11:26:19,941 - root - INFO - Step: 800 | Loss: 5.79 | Tokens per second: 40369.77 | Training tokens per second (%): 24.94 | MFU (%): 37.80 | TFLOPs: 373.88 | Global batch size: 32 | Global tokens/sec: 161479.08 | Global MFU (%): 37.80 | Global TFLOPs: 1495.53 | 
2025-05-19 11:26:24,004 - root - INFO - Step: 810 | Loss: 5.80 | Tokens per second: 40326.12 | Training tokens per second (%): 24.94 | MFU (%): 37.76 | TFLOPs: 373.48 | Global batch size: 32 | Global tokens/sec: 161304.47 | Global MFU (%): 37.76 | Global TFLOPs: 1493.91 | 
2025-05-19 11:26:28,063 - root - INFO - Step: 820 | Loss: 5.76 | Tokens per second: 40370.79 | Training tokens per second (%): 24.93 | MFU (%): 37.80 | TFLOPs: 373.89 | Global batch size: 32 | Global tokens/sec: 161483.17 | Global MFU (%): 37.80 | Global TFLOPs: 1495.56 | 
2025-05-19 11:26:32,122 - root - INFO - Step: 830 | Loss: 5.62 | Tokens per second: 40370.37 | Training tokens per second (%): 24.94 | MFU (%): 37.80 | TFLOPs: 373.89 | Global batch size: 32 | Global tokens/sec: 161481.49 | Global MFU (%): 37.80 | Global TFLOPs: 1495.55 | 
2025-05-19 11:26:36,185 - root - INFO - Step: 840 | Loss: 5.72 | Tokens per second: 40335.60 | Training tokens per second (%): 24.94 | MFU (%): 37.77 | TFLOPs: 373.57 | Global batch size: 32 | Global tokens/sec: 161342.38 | Global MFU (%): 37.77 | Global TFLOPs: 1494.26 | 
2025-05-19 11:26:40,240 - root - INFO - Step: 850 | Loss: 5.63 | Tokens per second: 40407.34 | Training tokens per second (%): 24.93 | MFU (%): 37.84 | TFLOPs: 374.23 | Global batch size: 32 | Global tokens/sec: 161629.35 | Global MFU (%): 37.84 | Global TFLOPs: 1496.92 | 
2025-05-19 11:26:44,305 - root - INFO - Step: 860 | Loss: 5.62 | Tokens per second: 40316.79 | Training tokens per second (%): 24.94 | MFU (%): 37.75 | TFLOPs: 373.39 | Global batch size: 32 | Global tokens/sec: 161267.15 | Global MFU (%): 37.75 | Global TFLOPs: 1493.56 | 
2025-05-19 11:26:48,366 - root - INFO - Step: 870 | Loss: 5.68 | Tokens per second: 40351.53 | Training tokens per second (%): 24.94 | MFU (%): 37.79 | TFLOPs: 373.71 | Global batch size: 32 | Global tokens/sec: 161406.10 | Global MFU (%): 37.79 | Global TFLOPs: 1494.85 | 
2025-05-19 11:26:52,430 - root - INFO - Step: 880 | Loss: 5.61 | Tokens per second: 40322.18 | Training tokens per second (%): 24.94 | MFU (%): 37.76 | TFLOPs: 373.44 | Global batch size: 32 | Global tokens/sec: 161288.73 | Global MFU (%): 37.76 | Global TFLOPs: 1493.76 | 
2025-05-19 11:26:56,494 - root - INFO - Step: 890 | Loss: 5.56 | Tokens per second: 40321.71 | Training tokens per second (%): 24.93 | MFU (%): 37.76 | TFLOPs: 373.44 | Global batch size: 32 | Global tokens/sec: 161286.83 | Global MFU (%): 37.76 | Global TFLOPs: 1493.75 | 
2025-05-19 11:27:00,555 - root - INFO - Step: 900 | Loss: 5.61 | Tokens per second: 40349.78 | Training tokens per second (%): 24.94 | MFU (%): 37.79 | TFLOPs: 373.70 | Global batch size: 32 | Global tokens/sec: 161399.11 | Global MFU (%): 37.79 | Global TFLOPs: 1494.79 | 
2025-05-19 11:27:04,617 - root - INFO - Step: 910 | Loss: 5.62 | Tokens per second: 40338.52 | Training tokens per second (%): 24.94 | MFU (%): 37.77 | TFLOPs: 373.59 | Global batch size: 32 | Global tokens/sec: 161354.09 | Global MFU (%): 37.77 | Global TFLOPs: 1494.37 | 
2025-05-19 11:27:08,681 - root - INFO - Step: 920 | Loss: 5.58 | Tokens per second: 40319.13 | Training tokens per second (%): 24.94 | MFU (%): 37.76 | TFLOPs: 373.41 | Global batch size: 32 | Global tokens/sec: 161276.50 | Global MFU (%): 37.76 | Global TFLOPs: 1493.65 | 
2025-05-19 11:27:12,743 - root - INFO - Step: 930 | Loss: 5.60 | Tokens per second: 40345.15 | Training tokens per second (%): 24.94 | MFU (%): 37.78 | TFLOPs: 373.65 | Global batch size: 32 | Global tokens/sec: 161380.59 | Global MFU (%): 37.78 | Global TFLOPs: 1494.61 | 
2025-05-19 11:27:16,809 - root - INFO - Step: 940 | Loss: 5.55 | Tokens per second: 40304.45 | Training tokens per second (%): 24.94 | MFU (%): 37.74 | TFLOPs: 373.28 | Global batch size: 32 | Global tokens/sec: 161217.80 | Global MFU (%): 37.74 | Global TFLOPs: 1493.11 | 
2025-05-19 11:27:20,873 - root - INFO - Step: 950 | Loss: 5.58 | Tokens per second: 40316.46 | Training tokens per second (%): 24.93 | MFU (%): 37.75 | TFLOPs: 373.39 | Global batch size: 32 | Global tokens/sec: 161265.85 | Global MFU (%): 37.75 | Global TFLOPs: 1493.55 | 
2025-05-19 11:27:24,935 - root - INFO - Step: 960 | Loss: 5.60 | Tokens per second: 40340.64 | Training tokens per second (%): 24.94 | MFU (%): 37.78 | TFLOPs: 373.61 | Global batch size: 32 | Global tokens/sec: 161362.57 | Global MFU (%): 37.78 | Global TFLOPs: 1494.45 | 
2025-05-19 11:27:29,006 - root - INFO - Step: 970 | Loss: 5.60 | Tokens per second: 40255.11 | Training tokens per second (%): 24.93 | MFU (%): 37.70 | TFLOPs: 372.82 | Global batch size: 32 | Global tokens/sec: 161020.44 | Global MFU (%): 37.70 | Global TFLOPs: 1491.28 | 
2025-05-19 11:27:33,068 - root - INFO - Step: 980 | Loss: 5.50 | Tokens per second: 40341.06 | Training tokens per second (%): 24.93 | MFU (%): 37.78 | TFLOPs: 373.62 | Global batch size: 32 | Global tokens/sec: 161364.24 | Global MFU (%): 37.78 | Global TFLOPs: 1494.46 | 
2025-05-19 11:27:37,121 - root - INFO - Step: 990 | Loss: 5.58 | Tokens per second: 40431.32 | Training tokens per second (%): 24.94 | MFU (%): 37.86 | TFLOPs: 374.45 | Global batch size: 32 | Global tokens/sec: 161725.26 | Global MFU (%): 37.86 | Global TFLOPs: 1497.81 | 
2025-05-19 11:27:41,182 - root - INFO - Step: 1000 | Loss: 5.61 | Tokens per second: 40351.71 | Training tokens per second (%): 24.94 | MFU (%): 37.79 | TFLOPs: 373.71 | Global batch size: 32 | Global tokens/sec: 161406.82 | Global MFU (%): 37.79 | Global TFLOPs: 1494.86 | 
2025-05-19 11:27:41,182 - root - INFO - Training completed
[sbatch-master] task finished
